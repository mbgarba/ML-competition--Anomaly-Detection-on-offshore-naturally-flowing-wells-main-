{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbgarba/ML-competition--Anomaly-Detection-on-offshore-naturally-flowing-wells-main-/blob/main/Copy_of_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8s1cEJDhYb6"
      },
      "outputs": [],
      "source": [
        "# 1 P-PDG Pressure at the PDG Pa\n",
        "# 2 P-TPT Pressure at the TPT Pa\n",
        "# 3 T-TPT Temperature at the TPT deg◦C\n",
        "# 4 P-MON-CKP Pressure upstream of the PCK Pa\n",
        "# 5 T-JUS-CKP Temperature downstream of the PCK deg◦C\n",
        "# 6 P-JUS-CKGL Pressure downstream of the GLCK Pa\n",
        "# 7 T-JUS-CKGL Temperature downstream of the GLCK deg◦C\n",
        "# 8 QGL Gas lift flow rate sm^3/s\n",
        "# 9 timestamp\n",
        "# 10 Class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Organization\n",
        "# Data Cleaning\n",
        "# Feature Engineering\n",
        "# Temporal Split"
      ],
      "metadata": {
        "id": "p00UlkZDKXep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MlYnUqbco1O",
        "outputId": "4db0316a-6dca-4eec-a57f-1de1634b4936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFuFhdRelU-m"
      },
      "source": [
        "# **Data Organization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA_EiY1KdePJ",
        "outputId": "6fc2bd9a-f8b2-4700-fc33-583eea18a9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing Folder 0\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.035734\n",
            "P-TPT           0.035734\n",
            "T-TPT           0.035865\n",
            "P-MON-CKP      10.134540\n",
            "T-JUS-CKP      14.785436\n",
            "P-JUS-CKGL     25.627142\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            25.482819\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0    9956791\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing Folder 1\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     98.683956\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            98.683956\n",
            "class           0.011337\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0       803319\n",
            "1.0      2905974\n",
            "101.0    5278295\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/WELL-00001_20140124213136.csv\n",
            "Invalid values: [101.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/WELL-00002_20140126200050.csv\n",
            "Invalid values: [101.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/WELL-00006_20170801063614.csv\n",
            "Invalid values: [101.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/WELL-00006_20170802123000.csv\n",
            "Invalid values: [101.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/WELL-00006_20180618060245.csv\n",
            "Invalid values: [101.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00001.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00002.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00003.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00004.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00005.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00006.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00007.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00008.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00009.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/DRAWN_00010.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00002.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00001.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00003.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00004.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00005.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00006.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00007.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00008.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00009.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00010.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00012.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00011.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00013.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00014.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00015.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00016.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00021.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00022.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00018.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00017.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00023.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00019.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00020.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00024.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00025.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00026.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00027.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00028.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00029.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00030.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00031.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00032.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00033.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00034.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00035.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00036.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00037.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00041.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00038.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00039.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00042.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00043.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00044.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00040.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00045.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00046.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00047.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00049.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00048.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00050.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00051.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00052.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00053.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00054.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00055.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00057.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00056.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00058.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00059.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00060.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00061.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00062.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00063.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00064.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00065.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00069.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00066.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00070.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00067.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00071.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00072.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00068.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00074.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00073.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00075.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00076.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00077.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00078.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00079.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00080.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00081.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00082.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00083.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00085.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00084.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00086.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00087.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00088.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00089.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00090.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00091.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00093.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00092.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00094.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00095.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00096.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00097.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00098.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00099.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00101.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00100.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00102.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00103.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00104.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00105.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00106.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00107.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00108.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00109.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00112.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00110.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00111.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00113.csv\n",
            "Invalid values: [101]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/1/SIMULATED_00114.csv\n",
            "Invalid values: [101]\n",
            "\n",
            "Analyzing Folder 2\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.099441\n",
            "P-TPT           0.099441\n",
            "T-TPT           0.099441\n",
            "P-MON-CKP      17.893695\n",
            "T-JUS-CKP      22.198384\n",
            "P-JUS-CKGL     97.439884\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            96.582691\n",
            "class           0.165627\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0      110251\n",
            "2.0      362199\n",
            "102.0    145988\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00002.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00001.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00003.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00004.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00005.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00006.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00008.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00007.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00010.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00009.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00015.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00014.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00011.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00013.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00012.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/SIMULATED_00016.csv\n",
            "Invalid values: [102]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00009_20170313160804.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00002_20131104014101.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00003_20141122214325.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00003_20180206182917.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00003_20170728150240.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00010_20171218200131.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140515110134.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140606230115.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140530100015.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140720120102.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140824000118.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140726180015.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140928100056.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140921200031.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140929170028.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140916060300.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20141005170056.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20140929220121.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00012_20170320033022.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00011_20141006160121.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00012_20170320143144.csv\n",
            "Invalid values: [102.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/2/WELL-00013_20170329020229.csv\n",
            "Invalid values: [102.]\n",
            "\n",
            "Analyzing Folder 3\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.012019\n",
            "P-TPT           0.012019\n",
            "T-TPT           0.012019\n",
            "P-MON-CKP       0.013943\n",
            "T-JUS-CKP       0.011253\n",
            "P-JUS-CKGL     88.240469\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            88.237739\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "3    4834079\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing Folder 4\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.030787\n",
            "P-TPT           0.043337\n",
            "T-TPT           0.042891\n",
            "P-MON-CKP       0.027294\n",
            "T-JUS-CKP       0.045734\n",
            "P-JUS-CKGL     50.508961\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            23.541475\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "4    2462076\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing Folder 5\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     97.262623\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            97.262623\n",
            "class           0.011048\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0        251732\n",
            "5.0      10550221\n",
            "105.0     2420853\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00001.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00003.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00004.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00002.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00006.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00005.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00008.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00007.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00010.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00009.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00011.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00012.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00013.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00014.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00015.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00016.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00018.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00017.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00020.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00019.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00022.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00021.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00024.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00023.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00025.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00027.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00026.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00029.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00028.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00031.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00030.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00033.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00032.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00036.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00034.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00035.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00038.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00037.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00040.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00039.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00041.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00042.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00044.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00045.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00043.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00046.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00047.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00048.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00049.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00051.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00050.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00053.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00052.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00056.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00054.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00055.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00058.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00057.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00059.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00060.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00062.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00061.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00064.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00065.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00063.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00067.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00066.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00069.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00068.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00071.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00070.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00073.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00072.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00075.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00074.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00077.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00076.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00079.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00078.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00080.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00081.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00082.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00084.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00083.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00085.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00086.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00087.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00088.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00089.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00091.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00090.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00092.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00093.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00095.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00094.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00096.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00097.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00098.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00100.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00099.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00101.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00102.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00103.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00104.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00105.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00106.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00107.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00109.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00108.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00110.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00111.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00113.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00112.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00115.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00114.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00116.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00117.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00119.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00118.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00121.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00122.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00120.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00123.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00124.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00125.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00126.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00128.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00127.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00129.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00130.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00131.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00132.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00133.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00134.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00135.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00137.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00136.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00138.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00139.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00141.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00140.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00143.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00142.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00144.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00145.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00146.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00147.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00149.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00148.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00151.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00150.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00152.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00153.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00154.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00155.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00156.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00157.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00159.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00158.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00160.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00161.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00163.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00162.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00165.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00164.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00167.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00168.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00166.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00169.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00170.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00171.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00172.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00174.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00173.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00175.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00176.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00177.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00179.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00178.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00180.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00181.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00183.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00184.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00182.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00185.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00186.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00187.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00188.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00190.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00189.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00192.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00191.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00193.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00194.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00195.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00196.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00197.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00199.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00198.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00200.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00201.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00202.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00203.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00205.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00204.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00207.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00206.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00208.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00209.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00211.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00210.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00212.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00214.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00213.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00215.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00216.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00218.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00217.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00219.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00220.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00222.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00221.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00223.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00225.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00224.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00226.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00227.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00229.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00228.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00230.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00231.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00233.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00232.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00236.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00234.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00235.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00237.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00238.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00239.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00240.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00242.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00241.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00243.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00244.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00245.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00247.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00246.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00248.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00249.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00250.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00251.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00252.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00253.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00255.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00254.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00257.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00256.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00259.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00258.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00260.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00261.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00262.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00263.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00264.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00265.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00266.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00268.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00267.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00269.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00270.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00272.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00271.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00273.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00275.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00274.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00277.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00276.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00279.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00278.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00280.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00281.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00283.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00282.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00284.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00285.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00287.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00286.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00288.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00289.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00290.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00291.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00292.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00294.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00293.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00296.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00297.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00295.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00298.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00299.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00300.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00301.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00303.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00302.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00305.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00304.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00306.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00308.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00307.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00310.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00309.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00311.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00312.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00313.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00314.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00315.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00316.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00317.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00318.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00319.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00321.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00320.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00322.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00323.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00324.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00326.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00325.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00328.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00327.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00329.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00330.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00332.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00331.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00333.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00334.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00335.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00337.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00336.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00339.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00338.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00340.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00341.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00343.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00342.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00344.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00345.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00346.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00348.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00347.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00349.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00350.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00352.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00351.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00353.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00354.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00355.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00356.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00359.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00357.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00358.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00360.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00361.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00362.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00363.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00364.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00365.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00366.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00367.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00368.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00370.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00369.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00371.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00372.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00373.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00374.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00375.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00376.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00377.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00379.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00378.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00380.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00382.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00381.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00384.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00383.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00385.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00387.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00386.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00388.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00389.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00391.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00390.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00393.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00392.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00395.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00396.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00394.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00398.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00397.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00399.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00400.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00402.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00401.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00405.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00403.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00404.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00406.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00407.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00408.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00409.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00411.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00410.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00412.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00413.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00414.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00415.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00416.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00417.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00418.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00419.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00420.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00422.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00421.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00424.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00423.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00426.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00425.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00429.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00428.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00427.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00430.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00431.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00432.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00433.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00434.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00435.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00437.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00436.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00439.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00015_20170620160349.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/SIMULATED_00438.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00016_20180517222322.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00016_20180426145108.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00016_20180426142005.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00016_20180405020345.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00015_20171013140047.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140314180000.csv\n",
            "Invalid values: [105]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140317151743.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140318023141.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140318160220.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140319040453.csv\n",
            "Invalid values: [105.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/5/WELL-00017_20140319141450.csv\n",
            "Invalid values: [105.]\n",
            "\n",
            "Analyzing Folder 6\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT          99.074723\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     99.182984\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            99.182984\n",
            "class           0.010616\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0       421383\n",
            "6.0      3878749\n",
            "106.0    1558248\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00001.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00002.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00003.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00005.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00004.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00006.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00008.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00009.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00007.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00011.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00010.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00012.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00013.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00014.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00017.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00016.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00015.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00019.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00018.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00021.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00022.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00020.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00025.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00023.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00024.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00027.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00026.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00030.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00029.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00028.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00031.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00032.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00033.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00034.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00035.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00038.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00036.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00037.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00041.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00039.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00040.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00042.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00043.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00045.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00046.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00044.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00048.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00049.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00047.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00052.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00050.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00051.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00053.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00054.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00055.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00056.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00057.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00059.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00058.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00060.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00061.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00062.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00063.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00065.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00064.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00066.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00067.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00068.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00071.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00069.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00070.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00072.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00073.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00074.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00075.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00076.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00077.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00079.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00078.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00080.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00081.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00082.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00083.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00084.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00086.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00087.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00085.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00090.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00088.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00089.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00092.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00091.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00093.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00094.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00095.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00096.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00097.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00098.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00100.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00099.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00103.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00101.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00102.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00105.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00104.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00106.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00108.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00107.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00110.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00109.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00111.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00112.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00114.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00113.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00116.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00115.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00117.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00118.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00120.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00119.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00121.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00122.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00123.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00124.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00126.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00125.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00129.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00127.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00128.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00130.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00131.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00133.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00134.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00132.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00135.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00136.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00137.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00138.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00139.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00142.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00141.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00140.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00143.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00144.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00147.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00145.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00146.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00149.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00148.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00151.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00152.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00150.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00153.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00154.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00155.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00156.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00157.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00158.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00159.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00160.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00161.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00162.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00163.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00164.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00165.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00166.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00167.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00169.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00168.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00170.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00171.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00172.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00174.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00173.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00175.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00177.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00176.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00179.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00178.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00180.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00181.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00182.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00183.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00185.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00184.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00188.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00186.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00187.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00190.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00189.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00191.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00192.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00194.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00193.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00195.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00197.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00196.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00199.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00198.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00200.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00203.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00202.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00201.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00205.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00204.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00206.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00208.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00207.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00209.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00210.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00211.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00212.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00213.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00214.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/SIMULATED_00215.csv\n",
            "Invalid values: [106]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00004_20171031181509.csv\n",
            "Invalid values: [106.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00004_20171031200059.csv\n",
            "Invalid values: [106.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00002_20140325170304.csv\n",
            "Invalid values: [106.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00002_20140301151700.csv\n",
            "Invalid values: [106.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00002_20140212170333.csv\n",
            "Invalid values: [106.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/6/WELL-00004_20171031193025.csv\n",
            "Invalid values: [106.]\n",
            "\n",
            "Analyzing Folder 7\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.013453\n",
            "P-TPT           0.013453\n",
            "T-TPT           0.013453\n",
            "P-MON-CKP       0.013453\n",
            "T-JUS-CKP       0.013453\n",
            "P-JUS-CKGL     89.916229\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            89.916229\n",
            "class           0.023524\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0       280029\n",
            "7.0       108630\n",
            "107.0    2301626\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00001.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00002.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00003.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00004.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00005.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00006.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00007.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00008.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00009.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/DRAWN_00010.csv\n",
            "Invalid values: [107]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/WELL-00001_20170226220309.csv\n",
            "Invalid values: [107.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/WELL-00006_20180618110721.csv\n",
            "Invalid values: [107.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/WELL-00006_20180620181348.csv\n",
            "Invalid values: [107.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/7/WELL-00018_20180611040207.csv\n",
            "Invalid values: [107]\n",
            "\n",
            "Analyzing Folder 8\n",
            "\n",
            "Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.001317\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       3.998708\n",
            "P-JUS-CKGL     96.001292\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            96.001292\n",
            "class           0.016198\n",
            "dtype: float64\n",
            "\n",
            "Class Distribution:\n",
            "class\n",
            "0.0       154367\n",
            "8.0       606041\n",
            "108.0    1517234\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Invalid Classes Found:\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00001.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00002.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00003.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00005.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00004.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00007.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00008.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00006.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00009.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00010.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00011.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00012.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00014.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00013.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00015.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00016.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00017.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00018.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00019.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00022.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00021.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00020.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00023.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00024.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00025.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00026.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00028.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00027.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00029.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00031.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00030.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00032.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00033.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00034.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00035.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00036.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00037.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00040.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00038.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00039.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00041.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00042.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00044.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00043.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00045.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00046.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00047.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00048.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00051.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00050.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00049.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00052.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00053.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00054.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00055.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00056.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00058.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00057.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00060.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00059.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00062.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00061.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00064.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00063.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00065.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00066.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00067.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00069.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00068.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00071.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00070.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00072.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00074.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00073.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00075.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00076.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00077.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00078.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00079.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00080.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/SIMULATED_00081.csv\n",
            "Invalid values: [108]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/WELL-00019_20170301182317.csv\n",
            "Invalid values: [108.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/WELL-00020_20120410192326.csv\n",
            "Invalid values: [108.]\n",
            "File: /content/drive/My Drive/Colab Notebooks/KFUPM/data/data/8/WELL-00021_20170509013517.csv\n",
            "Invalid values: [108.]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "def analyze_folder(folder_path):\n",
        "    all_dfs = []\n",
        "    invalid_classes = []\n",
        "\n",
        "    # Get all CSV files in the folder\n",
        "    files = glob(os.path.join(folder_path, '*.csv'))\n",
        "\n",
        "    for file in files:\n",
        "        df = pd.read_csv(file)\n",
        "        all_dfs.append(df)\n",
        "\n",
        "        # Check for invalid classes (not between 0-8)\n",
        "        if 'class' in df.columns:\n",
        "            invalid = df[~df['class'].between(0, 8) & df['class'].notna()]\n",
        "            if len(invalid) > 0:\n",
        "                invalid_classes.append((file, invalid['class'].unique()))\n",
        "\n",
        "    # Combine all DataFrames\n",
        "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "    # Calculate missing values\n",
        "    missing_vals = (combined_df.isnull().sum() / len(combined_df)) * 100\n",
        "\n",
        "    # Count unique values in class (excluding missing)\n",
        "    class_counts = combined_df['class'].value_counts().sort_index()\n",
        "\n",
        "    return missing_vals, class_counts, invalid_classes\n",
        "\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/KFUPM/data/data'\n",
        "folders = range(9)  # folders 0 to 8\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_path, str(folder))\n",
        "    print(f\"\\nAnalyzing Folder {folder}\")\n",
        "    missing_vals, class_counts, invalid_classes = analyze_folder(folder_path)\n",
        "\n",
        "    print(\"\\nMissing Values (%):\")\n",
        "    print(missing_vals)\n",
        "\n",
        "    print(\"\\nClass Distribution:\")\n",
        "    print(class_counts)\n",
        "\n",
        "    if invalid_classes:\n",
        "        print(\"\\nInvalid Classes Found:\")\n",
        "        for file, classes in invalid_classes:\n",
        "            print(f\"File: {file}\")\n",
        "            print(f\"Invalid values: {classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMCt9zflwUQ",
        "outputId": "b5efc0a0-de9c-4a94-f8fc-5a4f58e2bde9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Folder 0 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.035734\n",
            "P-TPT           0.035734\n",
            "T-TPT           0.035865\n",
            "P-MON-CKP      10.134540\n",
            "T-JUS-CKP      14.785436\n",
            "P-JUS-CKGL     25.627142\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            25.482819\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Folder 1 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     98.683956\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            98.683956\n",
            "class           0.011337\n",
            "dtype: float64\n",
            "\n",
            "Folder 2 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.099441\n",
            "P-TPT           0.099441\n",
            "T-TPT           0.099441\n",
            "P-MON-CKP      17.893695\n",
            "T-JUS-CKP      22.198384\n",
            "P-JUS-CKGL     97.439884\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            96.582691\n",
            "class           0.165627\n",
            "dtype: float64\n",
            "\n",
            "Folder 3 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.012019\n",
            "P-TPT           0.012019\n",
            "T-TPT           0.012019\n",
            "P-MON-CKP       0.013943\n",
            "T-JUS-CKP       0.011253\n",
            "P-JUS-CKGL     88.240469\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            88.237739\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Folder 4 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.030787\n",
            "P-TPT           0.043337\n",
            "T-TPT           0.042891\n",
            "P-MON-CKP       0.027294\n",
            "T-JUS-CKP       0.045734\n",
            "P-JUS-CKGL     50.508961\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            23.541475\n",
            "class           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Folder 5 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     97.262623\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            97.262623\n",
            "class           0.011048\n",
            "dtype: float64\n",
            "\n",
            "Folder 6 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.000000\n",
            "P-TPT           0.000000\n",
            "T-TPT          99.074723\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       0.000000\n",
            "P-JUS-CKGL     99.182984\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            99.182984\n",
            "class           0.010616\n",
            "dtype: float64\n",
            "\n",
            "Folder 7 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.013453\n",
            "P-TPT           0.013453\n",
            "T-TPT           0.013453\n",
            "P-MON-CKP       0.013453\n",
            "T-JUS-CKP       0.013453\n",
            "P-JUS-CKGL     89.916229\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            89.916229\n",
            "class           0.023524\n",
            "dtype: float64\n",
            "\n",
            "Folder 8 Missing Values (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.001317\n",
            "P-TPT           0.000000\n",
            "T-TPT           0.000000\n",
            "P-MON-CKP       0.000000\n",
            "T-JUS-CKP       3.998708\n",
            "P-JUS-CKGL     96.001292\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            96.001292\n",
            "class           0.016198\n",
            "dtype: float64\n",
            "\n",
            "Average Missing Values Across All Folders (%):\n",
            "timestamp       0.000000\n",
            "P-PDG           0.021417\n",
            "P-TPT           0.022665\n",
            "T-TPT          11.030932\n",
            "P-MON-CKP       3.120325\n",
            "T-JUS-CKP       4.561441\n",
            "P-JUS-CKGL     82.540393\n",
            "T-JUS-CKGL    100.000000\n",
            "QGL            79.432423\n",
            "class           0.026483\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "def clean_class_values(value):\n",
        "   if pd.isna(value):\n",
        "       return value\n",
        "\n",
        "   # Convert to string to handle decimal points\n",
        "   str_val = str(value)\n",
        "   if str_val.startswith('101'):\n",
        "       return 1\n",
        "   elif str_val.startswith('102'):\n",
        "       return 2\n",
        "   elif str_val.startswith('103'):\n",
        "       return 3\n",
        "   elif str_val.startswith('104'):\n",
        "       return 4\n",
        "   elif str_val.startswith('105'):\n",
        "       return 5\n",
        "   elif str_val.startswith('106'):\n",
        "       return 6\n",
        "   elif str_val.startswith('107'):\n",
        "       return 7\n",
        "   elif str_val.startswith('108'):\n",
        "       return 8\n",
        "   return value\n",
        "\n",
        "def analyze_folder(folder_path):\n",
        "   all_dfs = []\n",
        "\n",
        "   files = glob(os.path.join(folder_path, '*.csv'))\n",
        "\n",
        "   for file in files:\n",
        "       df = pd.read_csv(file)\n",
        "       if 'class' in df.columns:\n",
        "           df['class'] = df['class'].apply(clean_class_values)\n",
        "       all_dfs.append(df)\n",
        "\n",
        "   combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "   missing_vals = (combined_df.isnull().sum() / len(combined_df)) * 100\n",
        "\n",
        "   return missing_vals\n",
        "\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/KFUPM/data/data'\n",
        "all_missing_vals = []\n",
        "\n",
        "# Analyze each folder\n",
        "for folder in range(9):\n",
        "   folder_path = os.path.join(base_path, str(folder))\n",
        "   print(f\"\\nFolder {folder} Missing Values (%):\")\n",
        "   missing_vals = analyze_folder(folder_path)\n",
        "   print(missing_vals)\n",
        "   all_missing_vals.append(missing_vals)\n",
        "\n",
        "# Calculate average missing values across all folders\n",
        "avg_missing_vals = pd.concat(all_missing_vals, axis=1).mean(axis=1)\n",
        "print(\"\\nAverage Missing Values Across All Folders (%):\")\n",
        "print(avg_missing_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGz-owrasMUP"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYeRBvIXmSrR",
        "outputId": "8c315370-74a4-4178-ea5e-b5c9754bdcd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution after cleaning:\n",
            "class\n",
            "0.0    11977872\n",
            "1.0     8184269\n",
            "2.0      508187\n",
            "3.0     4834079\n",
            "4.0     2462076\n",
            "5.0    12971074\n",
            "6.0     5436997\n",
            "7.0     2410256\n",
            "8.0     2123275\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remaining Missing Values (%):\n",
            "timestamp    0.0\n",
            "P-PDG        0.0\n",
            "P-TPT        0.0\n",
            "T-TPT        0.0\n",
            "P-MON-CKP    0.0\n",
            "T-JUS-CKP    0.0\n",
            "class        0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "def clean_class_values(value):\n",
        "   if pd.isna(value):\n",
        "       return value\n",
        "\n",
        "   str_val = str(value)\n",
        "   if str_val.startswith('10'):\n",
        "       return int(str_val[2])\n",
        "   return value if 0 <= value <= 8 else np.nan\n",
        "\n",
        "def clean_data(folder_path):\n",
        "    files = glob(os.path.join(folder_path, '*.csv'))\n",
        "    all_dfs = []\n",
        "\n",
        "    for file in files:\n",
        "        df = pd.read_csv(file)\n",
        "        if 'class' in df.columns:\n",
        "            df['class'] = df['class'].apply(lambda x: int(str(x)[2]) if str(x).startswith('10') else x if 0 <= float(x) <= 8 else np.nan)\n",
        "        all_dfs.append(df)\n",
        "\n",
        "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    combined_df = combined_df.drop(['T-JUS-CKGL', 'P-JUS-CKGL', 'QGL'], axis=1)\n",
        "    combined_df = combined_df.dropna(subset=['class'])\n",
        "\n",
        "    # Forward fill then backward fill for T-TPT\n",
        "    combined_df['T-TPT'] = combined_df['T-TPT'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    # Linear interpolation for remaining columns\n",
        "    numerical_cols = ['P-PDG', 'P-TPT', 'P-MON-CKP', 'T-JUS-CKP']\n",
        "    combined_df[numerical_cols] = combined_df[numerical_cols].interpolate(method='linear')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/KFUPM/data/data'\n",
        "cleaned_dfs = []\n",
        "\n",
        "for folder in range(9):\n",
        "   folder_path = os.path.join(base_path, str(folder))\n",
        "   cleaned_df = clean_data(folder_path)\n",
        "   cleaned_dfs.append(cleaned_df)\n",
        "\n",
        "final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
        "\n",
        "# Verify class distribution after cleaning\n",
        "class_dist = final_df['class'].value_counts().sort_index()\n",
        "print(\"\\nClass Distribution after cleaning:\")\n",
        "print(class_dist)\n",
        "\n",
        "# Verify remaining missing values\n",
        "missing_vals = (final_df.isnull().sum() / len(final_df)) * 100\n",
        "print(\"\\nRemaining Missing Values (%):\")\n",
        "print(missing_vals)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "\n",
        "    final_df['class'] = final_df['class'].astype('int8')\n",
        "    final_df['timestamp'] = pd.to_datetime(final_df['timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify format for faster processing\n",
        "\n",
        "\n",
        "final_df = reduce_mem_usage(final_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKSuUdo7xpYI",
        "outputId": "326bb477-c984-4638-984d-776d46e0110c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to 1456.49 Mb (46.4% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2wWfMqa0fGD"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Al1tZsMH0c90",
        "outputId": "68d91309-fc87-4482-c214-8288fd5cbc8d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "No matching signature found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-ed15183e339e>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Apply feature engineering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengineer_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Show new features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-ed15183e339e>\u001b[0m in \u001b[0;36mengineer_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Fill NaN from rolling calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bfill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   7311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7313\u001b[0;31m             return self._pad_or_backfill(\n\u001b[0m\u001b[1;32m   7314\u001b[0m                 \u001b[0;31m# error: Argument 1 to \"_pad_or_backfill\" of \"NDFrame\" has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7315\u001b[0m                 \u001b[0;31m# incompatible type \"Optional[Literal['backfill', 'bfill', 'ffill',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_pad_or_backfill\u001b[0;34m(self, method, axis, inplace, limit, limit_area, downcast)\u001b[0m\n\u001b[1;32m   7087\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7089\u001b[0;31m         new_mgr = self._mgr.pad_or_backfill(\n\u001b[0m\u001b[1;32m   7090\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7091\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36mpad_or_backfill\u001b[0;34m(self, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpad_or_backfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         return self.apply_with_block(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;34m\"pad_or_backfill\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mpad_or_backfill\u001b[0;34m(self, method, axis, inplace, limit, limit_area, downcast, using_cow, already_warned)\u001b[0m\n\u001b[1;32m   1729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m         new_values = vals._pad_or_backfill(\n\u001b[0m\u001b[1;32m   1732\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m_pad_or_backfill\u001b[0;34m(self, method, limit, limit_area, copy)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         missing.pad_or_backfill_inplace(\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/missing.py\u001b[0m in \u001b[0;36mpad_or_backfill_inplace\u001b[0;34m(values, method, axis, limit, limit_area)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fill_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;31m# _pad_2d and _backfill_2d both modify tvalues inplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_area\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/missing.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, limit, limit_area, mask)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_area\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/missing.py\u001b[0m in \u001b[0;36m_backfill_2d\u001b[0;34m(values, limit, limit_area, mask)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m         \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackfill_2d_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# for test coverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32malgos.pyx\u001b[0m in \u001b[0;36mpandas._libs.algos.__pyx_fused_cpdef\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: No matching signature found"
          ]
        }
      ],
      "source": [
        "def engineer_features(df):\n",
        "    # Pressure differentials\n",
        "    df['P_DIFF_PDG_TPT'] = df['P-PDG'] - df['P-TPT']\n",
        "    df['P_DIFF_TPT_CKP'] = df['P-TPT'] - df['P-MON-CKP']\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "    # Time-based features\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['day'] = df['timestamp'].dt.day\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "\n",
        "    # Rolling statistics (10-minute windows)\n",
        "    sensors = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP']\n",
        "    for sensor in sensors:\n",
        "        df[f'{sensor}_rolling_mean'] = df[sensor].rolling(window=10).mean()\n",
        "        df[f'{sensor}_rolling_std'] = df[sensor].rolling(window=10).std()\n",
        "        df[f'{sensor}_rate_change'] = df[sensor].diff()\n",
        "\n",
        "    # Replace infinite values with NaN before filling\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Fill NaN from rolling calculations\n",
        "    df = df.fillna(method='bfill')\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "final_df = engineer_features(final_df)\n",
        "\n",
        "# Show new features\n",
        "print(\"New Features Created:\")\n",
        "print(final_df.columns.tolist())\n",
        "\n",
        "# Basic statistics of new features\n",
        "print(\"\\nFeature Statistics:\")\n",
        "print(final_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVa-blPERtf"
      },
      "source": [
        "# **Temporal Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riBWLB_qkVCN",
        "outputId": "724a3a6d-4021-487f-b401-bd28518af0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set length: 35635659\n",
            "Validation set length: 7636212\n",
            "Test set length: 7636214\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Sort by timestamp to maintain temporal order\n",
        "final_df = final_df.sort_values('timestamp')\n",
        "\n",
        "# Calculate split points\n",
        "n_samples = len(final_df)\n",
        "train_size = int(0.7 * n_samples)\n",
        "val_size = int(0.15 * n_samples)\n",
        "\n",
        "# Split data into train, validation, and test sets while maintaining temporal order\n",
        "train_df = final_df[:train_size]\n",
        "val_df = final_df[train_size:train_size + val_size]\n",
        "test_df = final_df[train_size + val_size:]\n",
        "\n",
        "# Separate features and target for each split\n",
        "X_train = train_df.drop(['timestamp', 'class'], axis=1)\n",
        "y_train = train_df['class']\n",
        "\n",
        "X_val = val_df.drop(['timestamp', 'class'], axis=1)\n",
        "y_val = val_df['class']\n",
        "\n",
        "X_test = test_df.drop(['timestamp', 'class'], axis=1)\n",
        "y_test = test_df['class']\n",
        "\n",
        "\n",
        "# Fit scaler only on training data and transform all sets\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # # Convert back to DataFrames if needed\n",
        "# # X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "# # X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
        "# # X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# # Store timestamps for reference (optional)\n",
        "# train_timestamps = train_df['timestamp']\n",
        "# val_timestamps = val_df['timestamp']\n",
        "# test_timestamps = test_df['timestamp']\n",
        "\n",
        "# Print length of train,val and test sets\n",
        "print(f\"Train set length: {len(train_df)}\")\n",
        "print(f\"Validation set length: {len(val_df)}\")\n",
        "print(f\"Test set length: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Reshape data for 1D CNN (adding channel dimension)\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], X_val_scaled.shape[1], 1)\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Build 1D CNN Model\n",
        "def create_1d_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        # First Convolutional Block\n",
        "        Conv1D(64, kernel_size=3, activation='relu',\n",
        "               input_shape=input_shape,\n",
        "               padding='same'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Flatten and Dense Layers\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Output Layer\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "\n",
        "# Create and train the model\n",
        "num_classes = len(np.unique(y_train))\n",
        "model = create_1d_cnn_model(\n",
        "    input_shape=(X_train_reshaped.shape[1], 1),\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train,\n",
        "    validation_data=(X_val_reshaped, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=256,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    X_test_reshaped, y_test, verbose=0\n",
        ")\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Learning Curve Visualization\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9X6mnuV5nPi",
        "outputId": "0d3d0069-f300-4d53-af4c-f7b6d35c28e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1246 - val_accuracy: 0.2154 - val_loss: inf - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2191 - val_accuracy: 0.2181 - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2913 - val_accuracy: 0.2224 - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2936 - val_accuracy: 0.2168 - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.3261 - val_accuracy: 0.1974 - val_loss: nan - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.2123 - val_accuracy: 0.2010 - val_loss: nan - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1676 - val_accuracy: 0.2212 - val_loss: nan - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1596 - val_accuracy: 0.2120 - val_loss: nan - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1588 - val_accuracy: 0.2168 - val_loss: nan - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m139202/139202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1629 - val_accuracy: 0.2070 - val_loss: nan - learning_rate: 2.0000e-04\n",
            "\n",
            "Test Accuracy: 0.0495\n",
            "\u001b[1m238632/238632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.88      0.15    427760\n",
            "         1.0       0.00      0.00      0.00   7208454\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.00      0.00      0.00         0\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         8.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.05   7636214\n",
            "   macro avg       0.01      0.11      0.02   7636214\n",
            "weighted avg       0.00      0.05      0.01   7636214\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmp2H-ij0mLA",
        "outputId": "89b7c307-badb-40f9-d134-3511b4116857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shapes:\n",
            "Training: (30544851, 25)\n",
            "Validation: (10181617, 25)\n",
            "Test: (10181617, 25)\n",
            "\n",
            "Class distribution:\n",
            "Training: [10638212    73930   105003  4834079  1869856  7465802  5436997    38817\n",
            "    82155]\n",
            "Validation: [ 569932    9754  403184       0  592220 5505272       0 1060135 2041120]\n",
            "Test: [ 769728 8100585       0       0       0       0       0 1311304]\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# # Sort by timestamp to maintain temporal order\n",
        "# final_df = final_df.sort_values('timestamp')\n",
        "\n",
        "# # Remove timestamp from features but keep for reference\n",
        "# timestamp = final_df['timestamp']\n",
        "# features = final_df.drop(['timestamp', 'class'], axis=1)\n",
        "# target = final_df['class']\n",
        "\n",
        "\n",
        "# # Scale features\n",
        "# scaler = StandardScaler()\n",
        "# scaled_features = scaler.fit_transform(features)\n",
        "# scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "\n",
        "# # # Split into train, validation, test (60%, 20%, 20%)\n",
        "# # X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "# #    scaled_df, target, test_size=0.2, shuffle=False\n",
        "# # )\n",
        "\n",
        "# # X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "# #    X_train_val, y_train_val, test_size=0.25, shuffle=False\n",
        "# # )\n",
        "\n",
        "# # print(\"Dataset shapes:\")\n",
        "# # print(f\"Training: {X_train.shape}\")\n",
        "# # print(f\"Validation: {X_valid.shape}\")\n",
        "# # print(f\"Test: {X_test.shape}\")\n",
        "\n",
        "# # # Class distribution in splits\n",
        "# # print(\"\\nClass distribution:\")\n",
        "# # print(\"Training:\", np.bincount(y_train.astype(int)))\n",
        "# # print(\"Validation:\", np.bincount(y_valid.astype(int)))\n",
        "# # print(\"Test:\", np.bincount(y_test.astype(int)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5esJxUCGWIcu"
      },
      "outputs": [],
      "source": [
        "# prompt: generate an optimized Temporal Convolutional Networks with training data of about 35m rows and 25 features. the data are in X_train, X_val and X_test. It should use gpu\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Separate features and target for each split\n",
        "X_train = train_df.drop(['class'], axis=1)\n",
        "y_train = train_df['class']\n",
        "\n",
        "X_val = val_df.drop(['class'], axis=1)\n",
        "y_val = val_df['class']\n",
        "\n",
        "X_test = test_df.drop(['class'], axis=1)\n",
        "y_test = test_df['class']\n",
        "\n",
        "\n",
        "\n",
        "# Reshape input data for TCN (samples, timesteps, features)\n",
        "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Define the TCN model\n",
        "model = Sequential()\n",
        "\n",
        "# Layer 1\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Layer 2\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Layer 3\n",
        "model.add(Conv1D(filters=256, kernel_size=3, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Flatten and dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Add dropout for regularization\n",
        "model.add(Dense(9, activation='softmax')) # Output layer\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with GPU acceleration\n",
        "with tf.device('/GPU:0'): # Specify GPU device\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcF07F0wqncR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGxGEeVjQsY"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KgdCgXidgtLK",
        "outputId": "11024ac4-236a-41b6-e93c-aecafcca55cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-626d54140bdd>:27: RuntimeWarning: divide by zero encountered in divide\n",
            "  self.class_weights = total_samples / (len(class_counts) * class_counts)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Invalid dtype: object",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-626d54140bdd>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_improved_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "# Separate features and target for each split\n",
        "X_train = train_df.drop(['class'], axis=1)\n",
        "y_train = train_df['class']\n",
        "\n",
        "X_valid = val_df.drop(['class'], axis=1)\n",
        "y_valid = val_df['class']\n",
        "\n",
        "X_test = test_df.drop(['class'], axis=1)\n",
        "y_test = test_df['class']\n",
        "\n",
        "class WeightedSequenceGenerator:\n",
        "    def __init__(self, X, y, sequence_length, batch_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Calculate class weights inside the generator\n",
        "        class_counts = np.bincount(y.astype(int))\n",
        "        total_samples = len(y)\n",
        "        self.class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            for i in range(0, len(self.X) - self.sequence_length, self.batch_size):\n",
        "                X_batch = []\n",
        "                y_batch = []\n",
        "                sample_weights = []\n",
        "\n",
        "                for j in range(i, min(i + self.batch_size, len(self.X) - self.sequence_length)):\n",
        "                    X_batch.append(self.X[j:(j + self.sequence_length)])\n",
        "                    label = self.y[j + self.sequence_length]\n",
        "                    y_batch.append(label)\n",
        "                    # Add sample weight based on class\n",
        "                    sample_weights.append(self.class_weights[int(label)])\n",
        "\n",
        "                yield np.array(X_batch), np.array(y_batch), np.array(sample_weights)\n",
        "\n",
        "def build_improved_lstm_model(input_shape, num_classes=9):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=input_shape, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        LSTM(16),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(16, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        clipnorm=.5\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set parameters\n",
        "sequence_length = 30\n",
        "batch_size = 256\n",
        "\n",
        "# Create generators with sample weights\n",
        "train_gen = WeightedSequenceGenerator(\n",
        "    X_train.values,\n",
        "    y_train.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "val_gen = WeightedSequenceGenerator(\n",
        "    X_valid.values,\n",
        "    y_valid.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "test_gen = WeightedSequenceGenerator(\n",
        "    X_test.values,\n",
        "    y_test.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "# Calculate steps\n",
        "steps_per_epoch = (len(X_train) - sequence_length) // batch_size\n",
        "validation_steps = (len(X_valid) - sequence_length) // batch_size\n",
        "test_steps = (len(X_test) - sequence_length) // batch_size\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        'best_lstm_model.keras',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "# Build and train model\n",
        "model = build_improved_lstm_model(input_shape=(sequence_length, X_train.shape[1]))\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen.generate(),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen.generate(),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_results = model.evaluate(\n",
        "    test_gen.generate(),\n",
        "    steps=test_steps\n",
        ")\n",
        "\n",
        "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_8V5W9Fg6rt",
        "outputId": "9a7863d3-771f-4374-8ee5-73d7975c8318"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c73f04ea-0833-4f35-84b9-a7c965f50c16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>P-PDG</th>\n",
              "      <th>P-TPT</th>\n",
              "      <th>T-TPT</th>\n",
              "      <th>P-MON-CKP</th>\n",
              "      <th>T-JUS-CKP</th>\n",
              "      <th>P_DIFF_PDG_TPT</th>\n",
              "      <th>P_DIFF_TPT_CKP</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>...</th>\n",
              "      <th>P-TPT_rate_change</th>\n",
              "      <th>T-TPT_rolling_mean</th>\n",
              "      <th>T-TPT_rolling_std</th>\n",
              "      <th>T-TPT_rate_change</th>\n",
              "      <th>P-MON-CKP_rolling_mean</th>\n",
              "      <th>P-MON-CKP_rolling_std</th>\n",
              "      <th>P-MON-CKP_rate_change</th>\n",
              "      <th>T-JUS-CKP_rolling_mean</th>\n",
              "      <th>T-JUS-CKP_rolling_std</th>\n",
              "      <th>T-JUS-CKP_rate_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50868395</th>\n",
              "      <td>2012-04-10 19:23:27</td>\n",
              "      <td>2.157074e+09</td>\n",
              "      <td>684189700.0</td>\n",
              "      <td>59.27158</td>\n",
              "      <td>1623155.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.472884e+09</td>\n",
              "      <td>682566545.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-145700.0</td>\n",
              "      <td>11.851696</td>\n",
              "      <td>24.985570</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1084589.96</td>\n",
              "      <td>284373.256727</td>\n",
              "      <td>-1989.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868396</th>\n",
              "      <td>2012-04-10 19:23:28</td>\n",
              "      <td>2.157094e+09</td>\n",
              "      <td>684043900.0</td>\n",
              "      <td>59.29778</td>\n",
              "      <td>1621166.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473050e+09</td>\n",
              "      <td>682422734.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-145800.0</td>\n",
              "      <td>17.781474</td>\n",
              "      <td>28.630896</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1151755.38</td>\n",
              "      <td>325298.007514</td>\n",
              "      <td>-1989.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868397</th>\n",
              "      <td>2012-04-10 19:23:29</td>\n",
              "      <td>2.157114e+09</td>\n",
              "      <td>683898200.0</td>\n",
              "      <td>59.32397</td>\n",
              "      <td>1619176.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473216e+09</td>\n",
              "      <td>682279024.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-145700.0</td>\n",
              "      <td>23.713871</td>\n",
              "      <td>30.614482</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1218716.42</td>\n",
              "      <td>347232.337097</td>\n",
              "      <td>-1990.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868398</th>\n",
              "      <td>2012-04-10 19:23:30</td>\n",
              "      <td>2.157134e+09</td>\n",
              "      <td>683752500.0</td>\n",
              "      <td>59.35017</td>\n",
              "      <td>1617187.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473382e+09</td>\n",
              "      <td>682135313.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-145700.0</td>\n",
              "      <td>29.648888</td>\n",
              "      <td>31.252684</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1285473.18</td>\n",
              "      <td>353857.097684</td>\n",
              "      <td>-1989.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868399</th>\n",
              "      <td>2012-04-10 19:23:31</td>\n",
              "      <td>2.157154e+09</td>\n",
              "      <td>683639600.0</td>\n",
              "      <td>59.37636</td>\n",
              "      <td>1616547.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473514e+09</td>\n",
              "      <td>682023053.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>35.586524</td>\n",
              "      <td>30.628025</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1352160.56</td>\n",
              "      <td>346299.451575</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868400</th>\n",
              "      <td>2012-04-10 19:23:32</td>\n",
              "      <td>2.157174e+09</td>\n",
              "      <td>683526700.0</td>\n",
              "      <td>59.40256</td>\n",
              "      <td>1615907.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473647e+09</td>\n",
              "      <td>681910793.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>41.526780</td>\n",
              "      <td>28.656238</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1418778.56</td>\n",
              "      <td>323614.933493</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868401</th>\n",
              "      <td>2012-04-10 19:23:33</td>\n",
              "      <td>2.157194e+09</td>\n",
              "      <td>683413800.0</td>\n",
              "      <td>59.42875</td>\n",
              "      <td>1615267.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473780e+09</td>\n",
              "      <td>681798533.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>47.469655</td>\n",
              "      <td>25.018769</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1485327.18</td>\n",
              "      <td>282233.403519</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868402</th>\n",
              "      <td>2012-04-10 19:23:34</td>\n",
              "      <td>2.157214e+09</td>\n",
              "      <td>683300900.0</td>\n",
              "      <td>59.45495</td>\n",
              "      <td>1614626.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.473913e+09</td>\n",
              "      <td>681686274.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>53.415150</td>\n",
              "      <td>18.768292</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1551806.33</td>\n",
              "      <td>211521.537447</td>\n",
              "      <td>-641.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868403</th>\n",
              "      <td>2012-04-10 19:23:35</td>\n",
              "      <td>2.157234e+09</td>\n",
              "      <td>683188000.0</td>\n",
              "      <td>59.48114</td>\n",
              "      <td>1613986.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474046e+09</td>\n",
              "      <td>681574014.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.363264</td>\n",
              "      <td>0.079311</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1618216.10</td>\n",
              "      <td>3810.340483</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868404</th>\n",
              "      <td>2012-04-10 19:23:36</td>\n",
              "      <td>2.157254e+09</td>\n",
              "      <td>683075100.0</td>\n",
              "      <td>59.50734</td>\n",
              "      <td>1613346.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474179e+09</td>\n",
              "      <td>681461754.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.389460</td>\n",
              "      <td>0.079310</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1617036.30</td>\n",
              "      <td>3205.395563</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868405</th>\n",
              "      <td>2012-04-10 19:23:37</td>\n",
              "      <td>2.157274e+09</td>\n",
              "      <td>682962300.0</td>\n",
              "      <td>59.53354</td>\n",
              "      <td>1612706.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474312e+09</td>\n",
              "      <td>681349594.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112800.0</td>\n",
              "      <td>59.415656</td>\n",
              "      <td>0.079311</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1615991.40</td>\n",
              "      <td>2642.933862</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868406</th>\n",
              "      <td>2012-04-10 19:23:38</td>\n",
              "      <td>2.157294e+09</td>\n",
              "      <td>682849400.0</td>\n",
              "      <td>59.55973</td>\n",
              "      <td>1612066.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474445e+09</td>\n",
              "      <td>681237334.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.441851</td>\n",
              "      <td>0.079311</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1615081.40</td>\n",
              "      <td>2191.325689</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868407</th>\n",
              "      <td>2012-04-10 19:23:39</td>\n",
              "      <td>2.157313e+09</td>\n",
              "      <td>682736500.0</td>\n",
              "      <td>59.58593</td>\n",
              "      <td>1611426.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474576e+09</td>\n",
              "      <td>681125074.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.468047</td>\n",
              "      <td>0.079311</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1614306.40</td>\n",
              "      <td>1938.129808</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868408</th>\n",
              "      <td>2012-04-10 19:23:40</td>\n",
              "      <td>2.157334e+09</td>\n",
              "      <td>682623600.0</td>\n",
              "      <td>59.61213</td>\n",
              "      <td>1610786.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474710e+09</td>\n",
              "      <td>681012814.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.494243</td>\n",
              "      <td>0.079313</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1613666.30</td>\n",
              "      <td>1938.074761</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868409</th>\n",
              "      <td>2012-04-10 19:23:41</td>\n",
              "      <td>2.157354e+09</td>\n",
              "      <td>682510700.0</td>\n",
              "      <td>59.63832</td>\n",
              "      <td>1610146.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474843e+09</td>\n",
              "      <td>680900554.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.520439</td>\n",
              "      <td>0.079313</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1613026.20</td>\n",
              "      <td>1937.983013</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868410</th>\n",
              "      <td>2012-04-10 19:23:42</td>\n",
              "      <td>2.157373e+09</td>\n",
              "      <td>682397800.0</td>\n",
              "      <td>59.66452</td>\n",
              "      <td>1609506.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.474975e+09</td>\n",
              "      <td>680788294.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.546635</td>\n",
              "      <td>0.079314</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1612386.10</td>\n",
              "      <td>1937.854560</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868411</th>\n",
              "      <td>2012-04-10 19:23:43</td>\n",
              "      <td>2.157393e+09</td>\n",
              "      <td>682284900.0</td>\n",
              "      <td>59.69071</td>\n",
              "      <td>1608866.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.475108e+09</td>\n",
              "      <td>680676034.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.572831</td>\n",
              "      <td>0.079313</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1611746.00</td>\n",
              "      <td>1937.689393</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868412</th>\n",
              "      <td>2012-04-10 19:23:44</td>\n",
              "      <td>2.157413e+09</td>\n",
              "      <td>682172000.0</td>\n",
              "      <td>59.71691</td>\n",
              "      <td>1608226.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.475241e+09</td>\n",
              "      <td>680563774.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.599027</td>\n",
              "      <td>0.079313</td>\n",
              "      <td>0.02620</td>\n",
              "      <td>1611106.00</td>\n",
              "      <td>1937.689391</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50868413</th>\n",
              "      <td>2012-04-10 19:23:45</td>\n",
              "      <td>2.157433e+09</td>\n",
              "      <td>682059100.0</td>\n",
              "      <td>59.74310</td>\n",
              "      <td>1607586.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>1.475374e+09</td>\n",
              "      <td>680451514.0</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>-112900.0</td>\n",
              "      <td>59.625223</td>\n",
              "      <td>0.079311</td>\n",
              "      <td>0.02619</td>\n",
              "      <td>1610466.00</td>\n",
              "      <td>1937.689389</td>\n",
              "      <td>-640.0</td>\n",
              "      <td>39.83253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c73f04ea-0833-4f35-84b9-a7c965f50c16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c73f04ea-0833-4f35-84b9-a7c965f50c16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c73f04ea-0833-4f35-84b9-a7c965f50c16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d8b4e4d-9c65-46fd-b3db-339ea6017156\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d8b4e4d-9c65-46fd-b3db-339ea6017156')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d8b4e4d-9c65-46fd-b3db-339ea6017156 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                   timestamp         P-PDG        P-TPT     T-TPT  P-MON-CKP  \\\n",
              "50868395 2012-04-10 19:23:27  2.157074e+09  684189700.0  59.27158  1623155.0   \n",
              "50868396 2012-04-10 19:23:28  2.157094e+09  684043900.0  59.29778  1621166.0   \n",
              "50868397 2012-04-10 19:23:29  2.157114e+09  683898200.0  59.32397  1619176.0   \n",
              "50868398 2012-04-10 19:23:30  2.157134e+09  683752500.0  59.35017  1617187.0   \n",
              "50868399 2012-04-10 19:23:31  2.157154e+09  683639600.0  59.37636  1616547.0   \n",
              "50868400 2012-04-10 19:23:32  2.157174e+09  683526700.0  59.40256  1615907.0   \n",
              "50868401 2012-04-10 19:23:33  2.157194e+09  683413800.0  59.42875  1615267.0   \n",
              "50868402 2012-04-10 19:23:34  2.157214e+09  683300900.0  59.45495  1614626.0   \n",
              "50868403 2012-04-10 19:23:35  2.157234e+09  683188000.0  59.48114  1613986.0   \n",
              "50868404 2012-04-10 19:23:36  2.157254e+09  683075100.0  59.50734  1613346.0   \n",
              "50868405 2012-04-10 19:23:37  2.157274e+09  682962300.0  59.53354  1612706.0   \n",
              "50868406 2012-04-10 19:23:38  2.157294e+09  682849400.0  59.55973  1612066.0   \n",
              "50868407 2012-04-10 19:23:39  2.157313e+09  682736500.0  59.58593  1611426.0   \n",
              "50868408 2012-04-10 19:23:40  2.157334e+09  682623600.0  59.61213  1610786.0   \n",
              "50868409 2012-04-10 19:23:41  2.157354e+09  682510700.0  59.63832  1610146.0   \n",
              "50868410 2012-04-10 19:23:42  2.157373e+09  682397800.0  59.66452  1609506.0   \n",
              "50868411 2012-04-10 19:23:43  2.157393e+09  682284900.0  59.69071  1608866.0   \n",
              "50868412 2012-04-10 19:23:44  2.157413e+09  682172000.0  59.71691  1608226.0   \n",
              "50868413 2012-04-10 19:23:45  2.157433e+09  682059100.0  59.74310  1607586.0   \n",
              "\n",
              "          T-JUS-CKP  P_DIFF_PDG_TPT  P_DIFF_TPT_CKP  hour  day  ...  \\\n",
              "50868395   39.83253    1.472884e+09     682566545.0    19   10  ...   \n",
              "50868396   39.83253    1.473050e+09     682422734.0    19   10  ...   \n",
              "50868397   39.83253    1.473216e+09     682279024.0    19   10  ...   \n",
              "50868398   39.83253    1.473382e+09     682135313.0    19   10  ...   \n",
              "50868399   39.83253    1.473514e+09     682023053.0    19   10  ...   \n",
              "50868400   39.83253    1.473647e+09     681910793.0    19   10  ...   \n",
              "50868401   39.83253    1.473780e+09     681798533.0    19   10  ...   \n",
              "50868402   39.83253    1.473913e+09     681686274.0    19   10  ...   \n",
              "50868403   39.83253    1.474046e+09     681574014.0    19   10  ...   \n",
              "50868404   39.83253    1.474179e+09     681461754.0    19   10  ...   \n",
              "50868405   39.83253    1.474312e+09     681349594.0    19   10  ...   \n",
              "50868406   39.83253    1.474445e+09     681237334.0    19   10  ...   \n",
              "50868407   39.83253    1.474576e+09     681125074.0    19   10  ...   \n",
              "50868408   39.83253    1.474710e+09     681012814.0    19   10  ...   \n",
              "50868409   39.83253    1.474843e+09     680900554.0    19   10  ...   \n",
              "50868410   39.83253    1.474975e+09     680788294.0    19   10  ...   \n",
              "50868411   39.83253    1.475108e+09     680676034.0    19   10  ...   \n",
              "50868412   39.83253    1.475241e+09     680563774.0    19   10  ...   \n",
              "50868413   39.83253    1.475374e+09     680451514.0    19   10  ...   \n",
              "\n",
              "          P-TPT_rate_change  T-TPT_rolling_mean  T-TPT_rolling_std  \\\n",
              "50868395          -145700.0           11.851696          24.985570   \n",
              "50868396          -145800.0           17.781474          28.630896   \n",
              "50868397          -145700.0           23.713871          30.614482   \n",
              "50868398          -145700.0           29.648888          31.252684   \n",
              "50868399          -112900.0           35.586524          30.628025   \n",
              "50868400          -112900.0           41.526780          28.656238   \n",
              "50868401          -112900.0           47.469655          25.018769   \n",
              "50868402          -112900.0           53.415150          18.768292   \n",
              "50868403          -112900.0           59.363264           0.079311   \n",
              "50868404          -112900.0           59.389460           0.079310   \n",
              "50868405          -112800.0           59.415656           0.079311   \n",
              "50868406          -112900.0           59.441851           0.079311   \n",
              "50868407          -112900.0           59.468047           0.079311   \n",
              "50868408          -112900.0           59.494243           0.079313   \n",
              "50868409          -112900.0           59.520439           0.079313   \n",
              "50868410          -112900.0           59.546635           0.079314   \n",
              "50868411          -112900.0           59.572831           0.079313   \n",
              "50868412          -112900.0           59.599027           0.079313   \n",
              "50868413          -112900.0           59.625223           0.079311   \n",
              "\n",
              "          T-TPT_rate_change  P-MON-CKP_rolling_mean  P-MON-CKP_rolling_std  \\\n",
              "50868395            0.02620              1084589.96          284373.256727   \n",
              "50868396            0.02620              1151755.38          325298.007514   \n",
              "50868397            0.02619              1218716.42          347232.337097   \n",
              "50868398            0.02620              1285473.18          353857.097684   \n",
              "50868399            0.02619              1352160.56          346299.451575   \n",
              "50868400            0.02620              1418778.56          323614.933493   \n",
              "50868401            0.02619              1485327.18          282233.403519   \n",
              "50868402            0.02620              1551806.33          211521.537447   \n",
              "50868403            0.02619              1618216.10            3810.340483   \n",
              "50868404            0.02620              1617036.30            3205.395563   \n",
              "50868405            0.02620              1615991.40            2642.933862   \n",
              "50868406            0.02619              1615081.40            2191.325689   \n",
              "50868407            0.02620              1614306.40            1938.129808   \n",
              "50868408            0.02620              1613666.30            1938.074761   \n",
              "50868409            0.02619              1613026.20            1937.983013   \n",
              "50868410            0.02620              1612386.10            1937.854560   \n",
              "50868411            0.02619              1611746.00            1937.689393   \n",
              "50868412            0.02620              1611106.00            1937.689391   \n",
              "50868413            0.02619              1610466.00            1937.689389   \n",
              "\n",
              "          P-MON-CKP_rate_change  T-JUS-CKP_rolling_mean  \\\n",
              "50868395                -1989.0                39.83253   \n",
              "50868396                -1989.0                39.83253   \n",
              "50868397                -1990.0                39.83253   \n",
              "50868398                -1989.0                39.83253   \n",
              "50868399                 -640.0                39.83253   \n",
              "50868400                 -640.0                39.83253   \n",
              "50868401                 -640.0                39.83253   \n",
              "50868402                 -641.0                39.83253   \n",
              "50868403                 -640.0                39.83253   \n",
              "50868404                 -640.0                39.83253   \n",
              "50868405                 -640.0                39.83253   \n",
              "50868406                 -640.0                39.83253   \n",
              "50868407                 -640.0                39.83253   \n",
              "50868408                 -640.0                39.83253   \n",
              "50868409                 -640.0                39.83253   \n",
              "50868410                 -640.0                39.83253   \n",
              "50868411                 -640.0                39.83253   \n",
              "50868412                 -640.0                39.83253   \n",
              "50868413                 -640.0                39.83253   \n",
              "\n",
              "          T-JUS-CKP_rolling_std  T-JUS-CKP_rate_change  \n",
              "50868395                    0.0                    0.0  \n",
              "50868396                    0.0                    0.0  \n",
              "50868397                    0.0                    0.0  \n",
              "50868398                    0.0                    0.0  \n",
              "50868399                    0.0                    0.0  \n",
              "50868400                    0.0                    0.0  \n",
              "50868401                    0.0                    0.0  \n",
              "50868402                    0.0                    0.0  \n",
              "50868403                    0.0                    0.0  \n",
              "50868404                    0.0                    0.0  \n",
              "50868405                    0.0                    0.0  \n",
              "50868406                    0.0                    0.0  \n",
              "50868407                    0.0                    0.0  \n",
              "50868408                    0.0                    0.0  \n",
              "50868409                    0.0                    0.0  \n",
              "50868410                    0.0                    0.0  \n",
              "50868411                    0.0                    0.0  \n",
              "50868412                    0.0                    0.0  \n",
              "50868413                    0.0                    0.0  \n",
              "\n",
              "[19 rows x 26 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.iloc[1:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad04-KxdjONj"
      },
      "source": [
        "# **RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS7HWhnRoHg3",
        "outputId": "fc6f61d3-b7f0-4c15-a95a-70b89bb93b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m477263/477263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2340s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.8394 - val_accuracy: 0.0453 - val_loss: 7.9564 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m477263/477263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2339s\u001b[0m 5ms/step - accuracy: 0.7667 - loss: 0.6192 - val_accuracy: 0.4442 - val_loss: 9.2341 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m477263/477263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2340s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.6251 - val_accuracy: 9.8263e-08 - val_loss: 8.0214 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m477263/477263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2336s\u001b[0m 5ms/step - accuracy: 0.6680 - loss: 0.7604 - val_accuracy: 0.0650 - val_loss: 19.5027 - learning_rate: 5.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m477263/477263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2333s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.7411 - val_accuracy: 0.3270 - val_loss: 8.9954 - learning_rate: 5.0000e-05\n",
            "\u001b[1m159087/159087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 2ms/step - accuracy: 0.0020 - loss: 5.9072\n",
            "Test Loss: 5.8004\n",
            "Test Accuracy: 0.0009\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, BatchNormalization, Dropout\n",
        "import numpy as np\n",
        "\n",
        "class BasicSequenceGenerator:\n",
        "    def __init__(self, X, y, sequence_length, batch_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Calculate balanced class weights with clipping to prevent extreme values\n",
        "        class_counts = np.bincount(y.astype(int))\n",
        "        total_samples = len(y)\n",
        "        weights = total_samples / (len(class_counts) * class_counts)\n",
        "        # Clip weights between 0.1 and 5.0 to maintain stability\n",
        "        self.class_weights = np.clip(weights, 0.1, 5.0)\n",
        "\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            # Create smaller chunks for efficient processing\n",
        "            chunk_size = min(100000, len(self.X) - self.sequence_length)\n",
        "            start_idx = np.random.randint(0, len(self.X) - chunk_size - self.sequence_length)\n",
        "\n",
        "            # Work with a chunk of data at a time\n",
        "            X_chunk = self.X[start_idx:start_idx + chunk_size]\n",
        "            y_chunk = self.y[start_idx:start_idx + chunk_size]\n",
        "\n",
        "            # Shuffle indices within the chunk\n",
        "            indices = np.arange(len(X_chunk) - self.sequence_length)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for i in range(0, len(indices), self.batch_size):\n",
        "                batch_indices = indices[i:min(i + self.batch_size, len(indices))]\n",
        "                X_batch = []\n",
        "                y_batch = []\n",
        "                sample_weights = []\n",
        "\n",
        "                for j in batch_indices:\n",
        "                    X_batch.append(X_chunk[j:j + self.sequence_length])\n",
        "                    label = y_chunk[j + self.sequence_length]\n",
        "                    y_batch.append(label)\n",
        "                    sample_weights.append(self.class_weights[int(label)])\n",
        "\n",
        "                yield np.array(X_batch), np.array(y_batch), np.array(sample_weights)\n",
        "\n",
        "def build_simple_rnn_model(input_shape, num_classes=9):\n",
        "    \"\"\"\n",
        "    A simplified RNN model focused on stable training and basic pattern recognition.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # Single RNN layer with moderate units\n",
        "        SimpleRNN(32, input_shape=input_shape,\n",
        "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),  # Light dropout to maintain signal\n",
        "\n",
        "        # Simple dense classifier\n",
        "        Dense(16, activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Conservative optimizer settings for stability\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Training parameters optimized for stability\n",
        "sequence_length = 15  # Shorter sequences for simpler patterns\n",
        "batch_size = 64      # Smaller batches for better generalization\n",
        "\n",
        "# Create data generators\n",
        "train_gen = BasicSequenceGenerator(\n",
        "    X_train.values,\n",
        "    y_train.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "val_gen = BasicSequenceGenerator(\n",
        "    X_valid.values,\n",
        "    y_valid.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "test_gen = BasicSequenceGenerator(\n",
        "    X_test.values,\n",
        "    y_test.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "# Calculate steps\n",
        "steps_per_epoch = (len(X_train) - sequence_length) // batch_size\n",
        "validation_steps = (len(X_valid) - sequence_length) // batch_size\n",
        "test_steps = (len(X_test) - sequence_length) // batch_size\n",
        "\n",
        "# Training callbacks for monitoring and early stopping\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.01  # Minimum improvement required\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "]\n",
        "\n",
        "# Build and train model\n",
        "model = build_simple_rnn_model(input_shape=(sequence_length, X_train.shape[1]))\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen.generate(),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen.generate(),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = model.evaluate(\n",
        "    test_gen.generate(),\n",
        "    steps=test_steps\n",
        ")\n",
        "\n",
        "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6pHQjeZ1pme"
      },
      "source": [
        "# **1D CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb41Cci-jawK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "import numpy as np\n",
        "\n",
        "# Separate features and target for each split\n",
        "X_train = train_df.drop(['class'], axis=1)\n",
        "y_train = train_df['class']\n",
        "\n",
        "X_valid = val_df.drop(['class'], axis=1)\n",
        "y_valid = val_df['class']\n",
        "\n",
        "X_test = test_df.drop(['class'], axis=1)\n",
        "y_test = test_df['class']\n",
        "\n",
        "\n",
        "class CNNSequenceGenerator:\n",
        "    def __init__(self, X, y, sequence_length, batch_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        class_counts = np.bincount(y.astype(int))\n",
        "        weights = len(y) / (len(class_counts) * class_counts)\n",
        "        self.class_weights = np.clip(weights, 0.1, 3.0)\n",
        "\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            chunk_size = min(50000, len(self.X) - self.sequence_length)\n",
        "            start_idx = np.random.randint(0, len(self.X) - chunk_size - self.sequence_length)\n",
        "            X_chunk = self.X[start_idx:start_idx + chunk_size]\n",
        "            y_chunk = self.y[start_idx:start_idx + chunk_size]\n",
        "            indices = np.arange(len(X_chunk) - self.sequence_length)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for i in range(0, len(indices), self.batch_size):\n",
        "                batch_indices = indices[i:min(i + self.batch_size, len(indices))]\n",
        "                X_batch = np.array([X_chunk[j:j + self.sequence_length] for j in batch_indices])\n",
        "                y_batch = np.array([y_chunk[j + self.sequence_length - 1] for j in batch_indices])\n",
        "                sample_weights = np.array([self.class_weights[int(label)] for label in y_batch])\n",
        "                yield X_batch, y_batch, sample_weights\n",
        "\n",
        "def build_cnn_model(input_shape, num_classes=9):\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv1D(32, 3, activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        Conv1D(64, 3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        GlobalAveragePooling1D(),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "sequence_length = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Create data generators\n",
        "train_gen = CNNSequenceGenerator(\n",
        "    X_train.values,\n",
        "    y_train.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "val_gen = CNNSequenceGenerator(\n",
        "    X_valid.values,\n",
        "    y_valid.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "test_gen = CNNSequenceGenerator(\n",
        "    X_test.values,\n",
        "    y_test.values,\n",
        "    sequence_length,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "# Calculate steps\n",
        "steps_per_epoch = (len(X_train) - sequence_length) // batch_size\n",
        "validation_steps = (len(X_valid) - sequence_length) // batch_size\n",
        "test_steps = (len(X_test) - sequence_length) // batch_size\n",
        "\n",
        "# Training callbacks for monitoring and early stopping\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.01  # Minimum improvement required\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "]\n",
        "\n",
        "model = build_cnn_model(input_shape=(sequence_length, X_train.shape[1]))\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen.generate(),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen.generate(),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = model.evaluate(\n",
        "    test_gen.generate(),\n",
        "    steps=test_steps\n",
        ")\n",
        "\n",
        "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKG0Th7B0uSV"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "X_train = pd.DataFrame(X_train_scaled)\n",
        "X_valid = pd.DataFrame(X_val_scaled)\n",
        "X_test = pd.DataFrame(X_test_scaled)\n",
        "\n",
        "y_valid = pd.DataFrame(y_valid)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "class AutoencoderGenerator:\n",
        "    def __init__(self, X, y, batch_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Calculate and clip class weights\n",
        "        class_counts = np.bincount(y.astype(int))\n",
        "        weights = len(y) / (len(class_counts) * class_counts)\n",
        "        self.class_weights = np.clip(weights, 0.1, 3.0)\n",
        "\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            # Process data in chunks\n",
        "            chunk_size = min(50000, len(self.X))\n",
        "            start_idx = np.random.randint(0, len(self.X) - chunk_size)\n",
        "\n",
        "            X_chunk = self.X[start_idx:start_idx + chunk_size]\n",
        "            y_chunk = self.y[start_idx:start_idx + chunk_size]\n",
        "\n",
        "            indices = np.arange(len(X_chunk))\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for i in range(0, len(indices), self.batch_size):\n",
        "                batch_indices = indices[i:min(i + self.batch_size, len(indices))]\n",
        "                # Use .iloc to access rows by integer position\n",
        "                X_batch = X_chunk.iloc[batch_indices].values # Access rows using .iloc and get NumPy array\n",
        "                y_batch = y_chunk.iloc[batch_indices].values # Access rows using .iloc and get NumPy array\n",
        "                sample_weights = np.array([self.class_weights[int(label)] for label in y_batch])\n",
        "\n",
        "                yield X_batch, y_batch, sample_weights\n",
        "\n",
        "def build_autoencoder(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(16, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(9, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Create generators\n",
        "class_counts = np.bincount(y_train.astype(int))\n",
        "class_weights = dict(enumerate(len(y_train) / (len(class_counts) * class_counts)))\n",
        "\n",
        "train_gen = AutoencoderGenerator(X_train, y_train, batch_size=512)\n",
        "val_gen = AutoencoderGenerator(X_valid, y_valid, batch_size=512)\n",
        "test_gen = AutoencoderGenerator(X_test, y_test, batch_size=512)\n",
        "\n",
        "# Calculate steps\n",
        "steps_per_epoch = len(X_train) // 512\n",
        "validation_steps = len(X_valid) // 512\n",
        "\n",
        "\n",
        "# Build and train autoencoder model\n",
        "model = build_autoencoder(X_train.shape[1])\n",
        "\n",
        "# Callbacks for training\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train model using generator\n",
        "history = model.fit(\n",
        "   train_gen.generate(),\n",
        "   steps_per_epoch=steps_per_epoch,\n",
        "   validation_data=val_gen.generate(),\n",
        "   validation_steps=validation_steps,\n",
        "   epochs=10,\n",
        "   callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEAumtoCZLXB"
      },
      "source": [
        "# **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cF-i8QvSk0l",
        "outputId": "648a22c0-e93f-4ca2-b36e-fddf169c43f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n",
        "import xgboost\n",
        "print(xgboost.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "z38Cnqn4ObK4",
        "outputId": "6ba89176-3415-4f31-d5d2-38b185093434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: {0: 10712409, 1: 73930, 2: 105003, 3: 4834079, 4: 2292363, 5: 12059906, 6: 5436997, 7: 38817, 8: 82155}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-69b7d8874350>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Train XGBoost with balanced batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbalanced_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
          ]
        }
      ],
      "source": [
        "\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train = pd.DataFrame(X_train_scaled)\n",
        "X_val = pd.DataFrame(X_val_scaled)\n",
        "X_test = pd.DataFrame(X_test_scaled)\n",
        "\n",
        "# convert y to int\n",
        "y_train = y_train.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "X_train.dropna(inplace=True)\n",
        "X_val.dropna(inplace=True)\n",
        "X_test.dropna(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def balanced_batch_generator(X, y, batch_size=1000000):\n",
        "    unique_classes = np.unique(y)\n",
        "    indices_by_class = {cls: np.where(y == cls)[0] for cls in unique_classes}\n",
        "    min_samples = min(len(indices) for indices in indices_by_class.values())\n",
        "\n",
        "    # Inspect class distribution\n",
        "    class_counts = {cls: len(np.where(y_train == cls)[0]) for cls in np.unique(y_train)}\n",
        "    print(\"Class counts:\", class_counts)\n",
        "\n",
        "\n",
        "    # Ensure batch size does not exceed the available number of samples in any class\n",
        "    batch_size_per_class = min(batch_size // len(unique_classes), min_samples)\n",
        "\n",
        "    while True:\n",
        "        batch_indices = []\n",
        "        for cls in unique_classes:\n",
        "            # Handle the case where a class has fewer than batch_size_per_class samples\n",
        "            sampled_indices = np.random.choice(\n",
        "                indices_by_class[cls],\n",
        "                size=batch_size_per_class if len(indices_by_class[cls]) >= batch_size_per_class else len(indices_by_class[cls]),\n",
        "                replace=False\n",
        "            )\n",
        "            batch_indices.extend(sampled_indices)\n",
        "\n",
        "        np.random.shuffle(batch_indices)\n",
        "        yield X.iloc[batch_indices], y.iloc[batch_indices]  # Access rows using .iloc\n",
        "\n",
        "\n",
        "# Define early stopping\n",
        "es = xgboost.callback.EarlyStopping(\n",
        "    rounds=10,  # Allow patience\n",
        "    min_delta=1e-3,\n",
        "    save_best=True,\n",
        "    maximize=False,\n",
        "    data_name=\"validation_0\",\n",
        "    metric_name=\"mlogloss\",\n",
        ")\n",
        "\n",
        "\n",
        "# Train without sequence generation since XGBoost handles tabular data directly\n",
        "model = XGBClassifier(\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    objective='multi:softprob',\n",
        "    num_class=9,\n",
        "    # tree_method='gpu_hist',  # GPU acceleration\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=1,\n",
        "    callbacks = [es]\n",
        ")\n",
        "\n",
        "# Use eval_set and early_stopping_rounds for early stopping\n",
        "eval_set = [(X_val, y_val)]  # Validation set for early stopping\n",
        "\n",
        "# Train XGBoost with balanced batches\n",
        "for X_batch, y_batch in balanced_batch_generator(X_train, y_train):\n",
        "    model.fit(\n",
        "        X_batch, y_batch,\n",
        "        eval_set=eval_set,\n",
        "        # eval_metric=\"mlogloss\",\n",
        "        verbose=True,\n",
        "        early_stopping_rounds=2  # Early stopping specified here\n",
        "    )\n",
        "\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# # Incremental training with balanced batches\n",
        "# n_batches = 10  # Number of batches to process\n",
        "# for i, (X_batch, y_batch) in enumerate(balanced_batch_generator(X_train, y_train)):\n",
        "#     print(f\"Training on batch {i+1}/{n_batches}...\")\n",
        "\n",
        "#     # Incrementally fit the model on each batch\n",
        "#     model.fit(\n",
        "#         X_batch, y_batch,\n",
        "#         eval_set=[(X_val, y_val)],\n",
        "#         verbose=True,\n",
        "#         xgb_model=model if i > 0 else None  # Resume training from previous iteration\n",
        "#     )\n",
        "\n",
        "#     if i + 1 >= n_batches:  # Stop after 'n_batches'\n",
        "#         break\n",
        "\n",
        "# # Evaluate\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to generate balanced batches\n",
        "def balanced_batch_generator(X, y, batch_size=10000):\n",
        "    unique_classes = np.unique(y)\n",
        "    indices_by_class = {cls: np.where(y == cls)[0] for cls in unique_classes}\n",
        "    min_samples = min(len(indices) for indices in indices_by_class.values())\n",
        "\n",
        "    while True:\n",
        "        batch_indices = []\n",
        "        for cls in unique_classes:\n",
        "            # Sample equally from each class\n",
        "            sampled_indices = np.random.choice(\n",
        "                indices_by_class[cls],\n",
        "                size=min(min_samples, batch_size // len(unique_classes)),\n",
        "                replace=False\n",
        "            )\n",
        "            batch_indices.extend(sampled_indices)\n",
        "\n",
        "        np.random.shuffle(batch_indices)\n",
        "        yield X.iloc[batch_indices], y.iloc[batch_indices]  # Access rows using .iloc\n",
        "\n",
        "\n",
        "# Prepare data (ensure y is a column vector for LightGBM)\n",
        "y_train = y_train.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "# Create the LightGBM dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "# Hyperparameters for LightGBM\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(np.unique(y_train)),  # number of unique classes\n",
        "    'metric': 'multi_logloss',  # Logloss for multiclass classification\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "\n",
        "}\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_callback = lgb.callback.early_stopping(stopping_rounds=10,\n",
        "                                                      verbose=True)\n",
        "\n",
        "# Train LightGBM model with early stopping callback\n",
        "model = lgb.LGBMClassifier(\n",
        "    **params,\n",
        "    boosting_type='gbdt',\n",
        "    num_leaves=50,\n",
        "    n_estimators=1000,\n",
        "    max_depth=-1,\n",
        "    min_data_in_leaf=10\n",
        ")\n",
        "\n",
        "# Train using the balanced batch generator, updating the model at each batch\n",
        "for X_batch, y_batch in balanced_batch_generator(X_train, y_train, batch_size=10000):\n",
        "    # print(pd.DataFrame(y_batch).value_counts())\n",
        "    model.fit(\n",
        "        X_batch, y_batch,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='multi_logloss',\n",
        "        callbacks=[early_stopping_callback],  # Add early stopping callback here\n",
        "    )\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9M2M_aSm8ZWC",
        "outputId": "9617db47-db77-4fbd-ca8f-c9e7ba2afc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20513\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22764\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21912\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23776\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20256\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23689\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22369\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22185\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22011\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22798\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21154\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21039\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21219\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20338\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20434\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19929\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21296\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19726\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20849\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20253\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20389\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.24053\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21755\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21473\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23207\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21681\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22553\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22958\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22593\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21525\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's multi_logloss: 2.19876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21654\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21394\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20148\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2276\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2262\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.17434\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23608\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21966\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23411\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22067\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23058\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23634\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21587\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21326\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21162\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20351\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22374\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20164\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21559\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19973\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20582\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2004\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22523\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23273\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.1952\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20635\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20996\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23404\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22418\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20529\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.19308\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.19871\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2226\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23305\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21879\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20239\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23191\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20115\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.19128\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20354\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21079\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2304\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21853\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21851\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's multi_logloss: 2.19411\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20211\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20098\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20623\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19913\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22666\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22915\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20346\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.18819\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22185\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21891\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21433\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21716\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21548\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22704\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20794\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22528\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20957\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21382\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20663\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid_0's multi_logloss: 2.18195\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21195\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20935\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23097\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23708\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22157\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21646\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23328\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20697\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21737\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21565\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22459\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22971\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20499\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22778\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2183\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22979\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21289\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21567\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22591\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22065\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21889\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2182\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid_0's multi_logloss: 2.20239\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23404\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.24484\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22035\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21262\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23027\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20797\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21139\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21106\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21644\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21325\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22926\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20158\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23076\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21967\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2358\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22276\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21964\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23151\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20391\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21528\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22654\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22267\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20079\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19592\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23563\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.21773\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2266\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21221\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid_0's multi_logloss: 2.18116\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22016\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2276\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23206\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21202\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21952\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22471\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19954\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22177\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20564\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2184\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20888\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20202\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22148\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid_0's multi_logloss: 2.1838\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2352\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23843\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22577\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid_0's multi_logloss: 2.19592\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20015\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22716\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21646\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2189\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22187\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22295\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23433\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.19435\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20244\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23999\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21586\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21522\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21038\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22234\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21279\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19876\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22598\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20255\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19481\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21333\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22624\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.24691\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20719\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2106\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20899\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21091\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2237\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2085\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.18654\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23261\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22953\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22016\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22989\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23681\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20991\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21343\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21662\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21974\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20775\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22967\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19973\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23304\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20788\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21633\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22844\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20788\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20874\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23208\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20896\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19839\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23377\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.19156\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22946\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20192\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20892\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21629\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20766\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2174\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22579\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's multi_logloss: 2.1819\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21559\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23636\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22163\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20715\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2306\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's multi_logloss: 2.22017\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22118\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22846\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22486\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19762\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21555\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23708\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19716\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22181\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2119\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2213\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20231\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20594\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2098\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.20724\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22454\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20513\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22669\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19396\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2091\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20052\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19938\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22009\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20372\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.226\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21022\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21989\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20017\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2214\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19759\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20184\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23475\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21622\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20074\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21971\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's multi_logloss: 2.21129\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22733\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21576\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2066\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2219\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22249\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21952\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2194\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21314\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22057\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20553\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22958\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19729\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22431\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21729\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20315\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22095\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21199\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22016\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22187\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20293\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21969\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21984\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23195\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22445\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21685\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2055\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19951\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.227\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23198\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22213\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21382\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21593\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22779\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21658\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23272\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23188\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20207\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's multi_logloss: 2.18931\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21485\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20099\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22226\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23318\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21308\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19886\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21144\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20561\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.2281\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23964\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21744\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20968\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20552\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22228\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23052\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22106\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22899\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20078\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23778\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22224\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20082\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20837\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20684\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22828\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.1988\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20199\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22165\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20312\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20748\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21746\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22136\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22369\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22593\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21451\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21927\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.19852\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21648\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.2094\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20209\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21078\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[6]\tvalid_0's multi_logloss: 2.1642\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20484\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23678\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21451\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[4]\tvalid_0's multi_logloss: 2.20799\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20928\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22417\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22039\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21399\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22833\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21206\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23239\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.22642\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21784\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21719\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.24325\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.23519\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20238\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.21426\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's multi_logloss: 2.20227\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-cce6ee273dc2>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train using the balanced batch generator, updating the model at each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbalanced_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(pd.DataFrame(y_batch).value_counts())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     model.fit(\n",
            "\u001b[0;32m<ipython-input-126-cce6ee273dc2>\u001b[0m in \u001b[0;36mbalanced_batch_generator\u001b[0;34m(X, y, batch_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Access rows using .iloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dur4HQg0Z2Qk",
        "outputId": "7536f97e-e8eb-42fe-cc68-f52cdd90569a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[1]\tvalidation_0-mlogloss:2.21324\n",
            "[2]\tvalidation_0-mlogloss:2.23559\n",
            "[3]\tvalidation_0-mlogloss:2.25970\n",
            "[4]\tvalidation_0-mlogloss:2.28148\n",
            "[5]\tvalidation_0-mlogloss:2.31100\n",
            "[6]\tvalidation_0-mlogloss:2.34365\n",
            "[7]\tvalidation_0-mlogloss:2.37794\n",
            "[8]\tvalidation_0-mlogloss:2.40169\n",
            "[9]\tvalidation_0-mlogloss:2.42254\n",
            "[10]\tvalidation_0-mlogloss:2.45581\n",
            "[11]\tvalidation_0-mlogloss:2.47990\n",
            "[12]\tvalidation_0-mlogloss:2.51220\n",
            "[13]\tvalidation_0-mlogloss:2.54444\n",
            "[14]\tvalidation_0-mlogloss:2.57951\n",
            "[15]\tvalidation_0-mlogloss:2.61052\n",
            "[16]\tvalidation_0-mlogloss:2.64569\n",
            "[17]\tvalidation_0-mlogloss:2.67969\n",
            "[18]\tvalidation_0-mlogloss:2.71161\n",
            "[19]\tvalidation_0-mlogloss:2.74385\n",
            "[20]\tvalidation_0-mlogloss:2.77645\n",
            "[21]\tvalidation_0-mlogloss:2.80748\n",
            "[22]\tvalidation_0-mlogloss:2.84427\n",
            "[23]\tvalidation_0-mlogloss:2.86761\n",
            "[24]\tvalidation_0-mlogloss:2.90006\n",
            "[25]\tvalidation_0-mlogloss:2.93045\n",
            "[26]\tvalidation_0-mlogloss:2.96426\n",
            "[27]\tvalidation_0-mlogloss:2.99854\n",
            "[28]\tvalidation_0-mlogloss:3.02774\n",
            "[29]\tvalidation_0-mlogloss:3.06199\n",
            "[30]\tvalidation_0-mlogloss:3.09536\n",
            "[31]\tvalidation_0-mlogloss:3.12814\n",
            "[32]\tvalidation_0-mlogloss:3.15851\n",
            "[33]\tvalidation_0-mlogloss:3.18959\n",
            "[34]\tvalidation_0-mlogloss:3.21636\n",
            "[35]\tvalidation_0-mlogloss:3.23772\n",
            "[36]\tvalidation_0-mlogloss:3.27061\n",
            "[37]\tvalidation_0-mlogloss:3.28866\n",
            "[38]\tvalidation_0-mlogloss:3.32859\n",
            "[39]\tvalidation_0-mlogloss:3.35117\n",
            "[40]\tvalidation_0-mlogloss:3.38769\n",
            "[41]\tvalidation_0-mlogloss:3.42367\n",
            "[42]\tvalidation_0-mlogloss:3.44237\n",
            "[43]\tvalidation_0-mlogloss:3.46633\n",
            "[44]\tvalidation_0-mlogloss:3.48674\n",
            "[45]\tvalidation_0-mlogloss:3.51863\n",
            "[46]\tvalidation_0-mlogloss:3.54417\n",
            "[47]\tvalidation_0-mlogloss:3.56746\n",
            "[48]\tvalidation_0-mlogloss:3.60450\n",
            "[49]\tvalidation_0-mlogloss:3.61694\n",
            "[50]\tvalidation_0-mlogloss:3.64647\n",
            "[51]\tvalidation_0-mlogloss:3.67105\n",
            "[52]\tvalidation_0-mlogloss:3.69530\n",
            "[53]\tvalidation_0-mlogloss:3.71355\n",
            "[54]\tvalidation_0-mlogloss:3.73736\n",
            "[55]\tvalidation_0-mlogloss:3.76142\n",
            "[56]\tvalidation_0-mlogloss:3.78380\n",
            "[57]\tvalidation_0-mlogloss:3.80944\n",
            "[58]\tvalidation_0-mlogloss:3.82879\n",
            "[59]\tvalidation_0-mlogloss:3.84016\n",
            "[60]\tvalidation_0-mlogloss:3.87091\n",
            "[61]\tvalidation_0-mlogloss:3.88456\n",
            "[62]\tvalidation_0-mlogloss:3.90832\n",
            "[63]\tvalidation_0-mlogloss:3.93119\n",
            "[64]\tvalidation_0-mlogloss:3.94149\n",
            "[65]\tvalidation_0-mlogloss:3.96602\n",
            "[66]\tvalidation_0-mlogloss:3.96770\n",
            "[67]\tvalidation_0-mlogloss:3.99137\n",
            "[68]\tvalidation_0-mlogloss:4.00033\n",
            "[69]\tvalidation_0-mlogloss:4.01853\n",
            "[70]\tvalidation_0-mlogloss:4.03503\n",
            "[71]\tvalidation_0-mlogloss:4.05568\n",
            "[72]\tvalidation_0-mlogloss:4.06370\n",
            "[73]\tvalidation_0-mlogloss:4.07588\n",
            "[74]\tvalidation_0-mlogloss:4.08260\n",
            "[75]\tvalidation_0-mlogloss:4.09580\n",
            "[76]\tvalidation_0-mlogloss:4.10539\n",
            "[77]\tvalidation_0-mlogloss:4.11704\n",
            "[78]\tvalidation_0-mlogloss:4.11685\n",
            "[79]\tvalidation_0-mlogloss:4.12075\n",
            "[80]\tvalidation_0-mlogloss:4.13191\n",
            "[81]\tvalidation_0-mlogloss:4.13578\n",
            "[82]\tvalidation_0-mlogloss:4.12230\n",
            "[83]\tvalidation_0-mlogloss:4.10097\n",
            "[84]\tvalidation_0-mlogloss:4.08415\n",
            "[85]\tvalidation_0-mlogloss:4.06580\n",
            "[86]\tvalidation_0-mlogloss:4.04991\n",
            "[87]\tvalidation_0-mlogloss:4.04365\n",
            "[88]\tvalidation_0-mlogloss:4.02809\n",
            "[89]\tvalidation_0-mlogloss:4.00390\n",
            "[90]\tvalidation_0-mlogloss:3.99035\n",
            "[91]\tvalidation_0-mlogloss:3.97558\n",
            "[92]\tvalidation_0-mlogloss:3.95654\n",
            "[93]\tvalidation_0-mlogloss:3.93014\n",
            "[94]\tvalidation_0-mlogloss:3.90775\n",
            "[95]\tvalidation_0-mlogloss:3.89034\n",
            "[96]\tvalidation_0-mlogloss:3.87051\n",
            "[97]\tvalidation_0-mlogloss:3.85441\n",
            "[98]\tvalidation_0-mlogloss:3.83756\n",
            "[99]\tvalidation_0-mlogloss:3.81989\n",
            "[0]\tvalidation_0-mlogloss:2.20680\n",
            "[1]\tvalidation_0-mlogloss:2.21083\n",
            "[2]\tvalidation_0-mlogloss:2.22938\n",
            "[3]\tvalidation_0-mlogloss:2.25043\n",
            "[4]\tvalidation_0-mlogloss:2.27568\n",
            "[5]\tvalidation_0-mlogloss:2.29918\n",
            "[6]\tvalidation_0-mlogloss:2.32272\n",
            "[7]\tvalidation_0-mlogloss:2.34669\n",
            "[8]\tvalidation_0-mlogloss:2.37254\n",
            "[9]\tvalidation_0-mlogloss:2.40114\n",
            "[10]\tvalidation_0-mlogloss:2.42985\n",
            "[11]\tvalidation_0-mlogloss:2.45954\n",
            "[12]\tvalidation_0-mlogloss:2.49191\n",
            "[13]\tvalidation_0-mlogloss:2.52625\n",
            "[14]\tvalidation_0-mlogloss:2.55816\n",
            "[15]\tvalidation_0-mlogloss:2.59409\n",
            "[16]\tvalidation_0-mlogloss:2.62638\n",
            "[17]\tvalidation_0-mlogloss:2.65648\n",
            "[18]\tvalidation_0-mlogloss:2.68755\n",
            "[19]\tvalidation_0-mlogloss:2.71939\n",
            "[20]\tvalidation_0-mlogloss:2.75120\n",
            "[21]\tvalidation_0-mlogloss:2.78273\n",
            "[22]\tvalidation_0-mlogloss:2.81500\n",
            "[23]\tvalidation_0-mlogloss:2.84046\n",
            "[24]\tvalidation_0-mlogloss:2.86540\n",
            "[25]\tvalidation_0-mlogloss:2.89257\n",
            "[26]\tvalidation_0-mlogloss:2.92563\n",
            "[27]\tvalidation_0-mlogloss:2.95594\n",
            "[28]\tvalidation_0-mlogloss:2.98687\n",
            "[29]\tvalidation_0-mlogloss:3.02141\n",
            "[30]\tvalidation_0-mlogloss:3.05529\n",
            "[31]\tvalidation_0-mlogloss:3.09096\n",
            "[32]\tvalidation_0-mlogloss:3.12663\n",
            "[33]\tvalidation_0-mlogloss:3.16239\n",
            "[34]\tvalidation_0-mlogloss:3.18471\n",
            "[35]\tvalidation_0-mlogloss:3.21622\n",
            "[36]\tvalidation_0-mlogloss:3.23209\n",
            "[37]\tvalidation_0-mlogloss:3.25967\n",
            "[38]\tvalidation_0-mlogloss:3.27858\n",
            "[39]\tvalidation_0-mlogloss:3.31307\n",
            "[40]\tvalidation_0-mlogloss:3.33379\n",
            "[41]\tvalidation_0-mlogloss:3.35555\n",
            "[42]\tvalidation_0-mlogloss:3.38701\n",
            "[43]\tvalidation_0-mlogloss:3.40772\n",
            "[44]\tvalidation_0-mlogloss:3.44180\n",
            "[45]\tvalidation_0-mlogloss:3.46379\n",
            "[46]\tvalidation_0-mlogloss:3.48976\n",
            "[47]\tvalidation_0-mlogloss:3.52309\n",
            "[48]\tvalidation_0-mlogloss:3.54426\n",
            "[49]\tvalidation_0-mlogloss:3.57783\n",
            "[50]\tvalidation_0-mlogloss:3.60184\n",
            "[51]\tvalidation_0-mlogloss:3.63104\n",
            "[52]\tvalidation_0-mlogloss:3.65027\n",
            "[53]\tvalidation_0-mlogloss:3.68048\n",
            "[54]\tvalidation_0-mlogloss:3.69287\n",
            "[55]\tvalidation_0-mlogloss:3.70311\n",
            "[56]\tvalidation_0-mlogloss:3.71542\n",
            "[57]\tvalidation_0-mlogloss:3.74672\n",
            "[58]\tvalidation_0-mlogloss:3.76539\n",
            "[59]\tvalidation_0-mlogloss:3.78094\n",
            "[60]\tvalidation_0-mlogloss:3.79858\n",
            "[61]\tvalidation_0-mlogloss:3.82973\n",
            "[62]\tvalidation_0-mlogloss:3.83952\n",
            "[63]\tvalidation_0-mlogloss:3.86087\n",
            "[64]\tvalidation_0-mlogloss:3.86737\n",
            "[65]\tvalidation_0-mlogloss:3.89138\n",
            "[66]\tvalidation_0-mlogloss:3.91022\n",
            "[67]\tvalidation_0-mlogloss:3.92119\n",
            "[68]\tvalidation_0-mlogloss:3.93578\n",
            "[69]\tvalidation_0-mlogloss:3.93962\n",
            "[70]\tvalidation_0-mlogloss:3.96024\n",
            "[71]\tvalidation_0-mlogloss:3.97514\n",
            "[72]\tvalidation_0-mlogloss:3.98681\n",
            "[73]\tvalidation_0-mlogloss:3.98642\n",
            "[74]\tvalidation_0-mlogloss:4.00684\n",
            "[75]\tvalidation_0-mlogloss:4.01005\n",
            "[76]\tvalidation_0-mlogloss:4.02890\n",
            "[77]\tvalidation_0-mlogloss:4.02057\n",
            "[78]\tvalidation_0-mlogloss:4.03997\n",
            "[79]\tvalidation_0-mlogloss:4.02860\n",
            "[80]\tvalidation_0-mlogloss:4.02684\n",
            "[81]\tvalidation_0-mlogloss:4.02190\n",
            "[82]\tvalidation_0-mlogloss:4.01475\n",
            "[83]\tvalidation_0-mlogloss:4.02185\n",
            "[84]\tvalidation_0-mlogloss:4.00938\n",
            "[85]\tvalidation_0-mlogloss:4.01861\n",
            "[86]\tvalidation_0-mlogloss:3.98853\n",
            "[87]\tvalidation_0-mlogloss:3.95505\n",
            "[88]\tvalidation_0-mlogloss:3.94004\n",
            "[89]\tvalidation_0-mlogloss:3.90487\n",
            "[90]\tvalidation_0-mlogloss:3.88659\n",
            "[91]\tvalidation_0-mlogloss:3.85583\n",
            "[92]\tvalidation_0-mlogloss:3.82389\n",
            "[93]\tvalidation_0-mlogloss:3.80942\n",
            "[94]\tvalidation_0-mlogloss:3.79387\n",
            "[95]\tvalidation_0-mlogloss:3.76616\n",
            "[96]\tvalidation_0-mlogloss:3.74136\n",
            "[97]\tvalidation_0-mlogloss:3.71326\n",
            "[98]\tvalidation_0-mlogloss:3.69149\n",
            "[99]\tvalidation_0-mlogloss:3.67102\n",
            "[0]\tvalidation_0-mlogloss:2.25340\n",
            "[1]\tvalidation_0-mlogloss:2.30311\n",
            "[2]\tvalidation_0-mlogloss:2.35183\n",
            "[3]\tvalidation_0-mlogloss:2.40342\n",
            "[4]\tvalidation_0-mlogloss:2.45084\n",
            "[5]\tvalidation_0-mlogloss:2.49934\n",
            "[6]\tvalidation_0-mlogloss:2.54156\n",
            "[7]\tvalidation_0-mlogloss:2.58456\n",
            "[8]\tvalidation_0-mlogloss:2.62690\n",
            "[9]\tvalidation_0-mlogloss:2.67250\n",
            "[10]\tvalidation_0-mlogloss:2.71930\n",
            "[11]\tvalidation_0-mlogloss:2.76692\n",
            "[12]\tvalidation_0-mlogloss:2.81611\n",
            "[13]\tvalidation_0-mlogloss:2.86417\n",
            "[14]\tvalidation_0-mlogloss:2.91438\n",
            "[15]\tvalidation_0-mlogloss:2.96548\n",
            "[16]\tvalidation_0-mlogloss:3.01644\n",
            "[17]\tvalidation_0-mlogloss:3.06582\n",
            "[18]\tvalidation_0-mlogloss:3.12438\n",
            "[19]\tvalidation_0-mlogloss:3.18232\n",
            "[20]\tvalidation_0-mlogloss:3.24257\n",
            "[21]\tvalidation_0-mlogloss:3.30298\n",
            "[22]\tvalidation_0-mlogloss:3.36249\n",
            "[23]\tvalidation_0-mlogloss:3.42222\n",
            "[24]\tvalidation_0-mlogloss:3.48024\n",
            "[25]\tvalidation_0-mlogloss:3.53721\n",
            "[26]\tvalidation_0-mlogloss:3.59715\n",
            "[27]\tvalidation_0-mlogloss:3.65641\n",
            "[28]\tvalidation_0-mlogloss:3.71349\n",
            "[29]\tvalidation_0-mlogloss:3.77203\n",
            "[30]\tvalidation_0-mlogloss:3.83034\n",
            "[31]\tvalidation_0-mlogloss:3.88371\n",
            "[32]\tvalidation_0-mlogloss:3.93423\n",
            "[33]\tvalidation_0-mlogloss:3.98865\n",
            "[34]\tvalidation_0-mlogloss:4.04075\n",
            "[35]\tvalidation_0-mlogloss:4.08420\n",
            "[36]\tvalidation_0-mlogloss:4.11755\n",
            "[37]\tvalidation_0-mlogloss:4.15082\n",
            "[38]\tvalidation_0-mlogloss:4.18337\n",
            "[39]\tvalidation_0-mlogloss:4.20630\n",
            "[40]\tvalidation_0-mlogloss:4.22910\n",
            "[41]\tvalidation_0-mlogloss:4.25908\n",
            "[42]\tvalidation_0-mlogloss:4.29122\n",
            "[43]\tvalidation_0-mlogloss:4.31400\n",
            "[44]\tvalidation_0-mlogloss:4.34839\n",
            "[45]\tvalidation_0-mlogloss:4.37878\n",
            "[46]\tvalidation_0-mlogloss:4.40588\n",
            "[47]\tvalidation_0-mlogloss:4.43307\n",
            "[48]\tvalidation_0-mlogloss:4.47599\n",
            "[49]\tvalidation_0-mlogloss:4.49934\n",
            "[50]\tvalidation_0-mlogloss:4.53659\n",
            "[51]\tvalidation_0-mlogloss:4.56681\n",
            "[52]\tvalidation_0-mlogloss:4.60486\n",
            "[53]\tvalidation_0-mlogloss:4.63473\n",
            "[54]\tvalidation_0-mlogloss:4.67267\n",
            "[55]\tvalidation_0-mlogloss:4.71280\n",
            "[56]\tvalidation_0-mlogloss:4.74386\n",
            "[57]\tvalidation_0-mlogloss:4.78076\n",
            "[58]\tvalidation_0-mlogloss:4.80278\n",
            "[59]\tvalidation_0-mlogloss:4.83847\n",
            "[60]\tvalidation_0-mlogloss:4.87014\n",
            "[61]\tvalidation_0-mlogloss:4.89661\n",
            "[62]\tvalidation_0-mlogloss:4.91042\n",
            "[63]\tvalidation_0-mlogloss:4.91783\n",
            "[64]\tvalidation_0-mlogloss:4.93435\n",
            "[65]\tvalidation_0-mlogloss:4.94362\n",
            "[66]\tvalidation_0-mlogloss:4.95534\n",
            "[67]\tvalidation_0-mlogloss:4.95956\n",
            "[68]\tvalidation_0-mlogloss:4.96725\n",
            "[69]\tvalidation_0-mlogloss:4.96988\n",
            "[70]\tvalidation_0-mlogloss:4.98208\n",
            "[71]\tvalidation_0-mlogloss:4.98462\n",
            "[72]\tvalidation_0-mlogloss:4.99666\n",
            "[73]\tvalidation_0-mlogloss:5.00027\n",
            "[74]\tvalidation_0-mlogloss:5.01282\n",
            "[75]\tvalidation_0-mlogloss:5.01748\n",
            "[76]\tvalidation_0-mlogloss:5.03040\n",
            "[77]\tvalidation_0-mlogloss:5.03895\n",
            "[78]\tvalidation_0-mlogloss:5.04100\n",
            "[79]\tvalidation_0-mlogloss:5.02864\n",
            "[80]\tvalidation_0-mlogloss:5.03324\n",
            "[81]\tvalidation_0-mlogloss:5.02502\n",
            "[82]\tvalidation_0-mlogloss:5.02284\n",
            "[83]\tvalidation_0-mlogloss:5.01545\n",
            "[84]\tvalidation_0-mlogloss:5.01857\n",
            "[85]\tvalidation_0-mlogloss:5.00807\n",
            "[86]\tvalidation_0-mlogloss:5.02219\n",
            "[87]\tvalidation_0-mlogloss:5.01422\n",
            "[88]\tvalidation_0-mlogloss:5.01118\n",
            "[89]\tvalidation_0-mlogloss:4.99291\n",
            "[90]\tvalidation_0-mlogloss:4.97200\n",
            "[91]\tvalidation_0-mlogloss:4.95164\n",
            "[92]\tvalidation_0-mlogloss:4.93305\n",
            "[93]\tvalidation_0-mlogloss:4.92528\n",
            "[94]\tvalidation_0-mlogloss:4.91795\n",
            "[95]\tvalidation_0-mlogloss:4.90585\n",
            "[96]\tvalidation_0-mlogloss:4.90400\n",
            "[97]\tvalidation_0-mlogloss:4.89644\n",
            "[98]\tvalidation_0-mlogloss:4.88433\n",
            "[99]\tvalidation_0-mlogloss:4.88335\n",
            "[0]\tvalidation_0-mlogloss:2.22393\n",
            "[1]\tvalidation_0-mlogloss:2.24889\n",
            "[2]\tvalidation_0-mlogloss:2.27481\n",
            "[3]\tvalidation_0-mlogloss:2.29411\n",
            "[4]\tvalidation_0-mlogloss:2.31753\n",
            "[5]\tvalidation_0-mlogloss:2.34166\n",
            "[6]\tvalidation_0-mlogloss:2.37726\n",
            "[7]\tvalidation_0-mlogloss:2.41641\n",
            "[8]\tvalidation_0-mlogloss:2.45051\n",
            "[9]\tvalidation_0-mlogloss:2.49053\n",
            "[10]\tvalidation_0-mlogloss:2.52427\n",
            "[11]\tvalidation_0-mlogloss:2.55392\n",
            "[12]\tvalidation_0-mlogloss:2.58500\n",
            "[13]\tvalidation_0-mlogloss:2.62084\n",
            "[14]\tvalidation_0-mlogloss:2.65299\n",
            "[15]\tvalidation_0-mlogloss:2.68802\n",
            "[16]\tvalidation_0-mlogloss:2.72338\n",
            "[17]\tvalidation_0-mlogloss:2.76184\n",
            "[18]\tvalidation_0-mlogloss:2.79981\n",
            "[19]\tvalidation_0-mlogloss:2.84134\n",
            "[20]\tvalidation_0-mlogloss:2.88345\n",
            "[21]\tvalidation_0-mlogloss:2.92088\n",
            "[22]\tvalidation_0-mlogloss:2.95518\n",
            "[23]\tvalidation_0-mlogloss:2.99281\n",
            "[24]\tvalidation_0-mlogloss:3.03426\n",
            "[25]\tvalidation_0-mlogloss:3.07020\n",
            "[26]\tvalidation_0-mlogloss:3.10921\n",
            "[27]\tvalidation_0-mlogloss:3.14945\n",
            "[28]\tvalidation_0-mlogloss:3.18480\n",
            "[29]\tvalidation_0-mlogloss:3.21855\n",
            "[30]\tvalidation_0-mlogloss:3.25681\n",
            "[31]\tvalidation_0-mlogloss:3.28855\n",
            "[32]\tvalidation_0-mlogloss:3.31636\n",
            "[33]\tvalidation_0-mlogloss:3.35608\n",
            "[34]\tvalidation_0-mlogloss:3.38599\n",
            "[35]\tvalidation_0-mlogloss:3.42308\n",
            "[36]\tvalidation_0-mlogloss:3.45171\n",
            "[37]\tvalidation_0-mlogloss:3.47996\n",
            "[38]\tvalidation_0-mlogloss:3.51977\n",
            "[39]\tvalidation_0-mlogloss:3.54700\n",
            "[40]\tvalidation_0-mlogloss:3.58371\n",
            "[41]\tvalidation_0-mlogloss:3.60196\n",
            "[42]\tvalidation_0-mlogloss:3.63560\n",
            "[43]\tvalidation_0-mlogloss:3.66560\n",
            "[44]\tvalidation_0-mlogloss:3.70444\n",
            "[45]\tvalidation_0-mlogloss:3.73201\n",
            "[46]\tvalidation_0-mlogloss:3.76146\n",
            "[47]\tvalidation_0-mlogloss:3.80190\n",
            "[48]\tvalidation_0-mlogloss:3.83011\n",
            "[49]\tvalidation_0-mlogloss:3.87683\n",
            "[50]\tvalidation_0-mlogloss:3.90301\n",
            "[51]\tvalidation_0-mlogloss:3.92830\n",
            "[52]\tvalidation_0-mlogloss:3.96535\n",
            "[53]\tvalidation_0-mlogloss:3.99553\n",
            "[54]\tvalidation_0-mlogloss:4.03404\n",
            "[55]\tvalidation_0-mlogloss:4.05259\n",
            "[56]\tvalidation_0-mlogloss:4.09308\n",
            "[57]\tvalidation_0-mlogloss:4.12442\n",
            "[58]\tvalidation_0-mlogloss:4.14441\n",
            "[59]\tvalidation_0-mlogloss:4.16814\n",
            "[60]\tvalidation_0-mlogloss:4.19757\n",
            "[61]\tvalidation_0-mlogloss:4.22188\n",
            "[62]\tvalidation_0-mlogloss:4.25370\n",
            "[63]\tvalidation_0-mlogloss:4.26844\n",
            "[64]\tvalidation_0-mlogloss:4.30300\n",
            "[65]\tvalidation_0-mlogloss:4.32652\n",
            "[66]\tvalidation_0-mlogloss:4.34837\n",
            "[67]\tvalidation_0-mlogloss:4.36098\n",
            "[68]\tvalidation_0-mlogloss:4.38871\n",
            "[69]\tvalidation_0-mlogloss:4.39612\n",
            "[70]\tvalidation_0-mlogloss:4.41485\n",
            "[71]\tvalidation_0-mlogloss:4.41844\n",
            "[72]\tvalidation_0-mlogloss:4.42720\n",
            "[73]\tvalidation_0-mlogloss:4.42966\n",
            "[74]\tvalidation_0-mlogloss:4.43499\n",
            "[75]\tvalidation_0-mlogloss:4.41713\n",
            "[76]\tvalidation_0-mlogloss:4.41751\n",
            "[77]\tvalidation_0-mlogloss:4.40634\n",
            "[78]\tvalidation_0-mlogloss:4.39816\n",
            "[79]\tvalidation_0-mlogloss:4.38693\n",
            "[80]\tvalidation_0-mlogloss:4.37618\n",
            "[81]\tvalidation_0-mlogloss:4.37413\n",
            "[82]\tvalidation_0-mlogloss:4.37686\n",
            "[83]\tvalidation_0-mlogloss:4.36063\n",
            "[84]\tvalidation_0-mlogloss:4.34327\n",
            "[85]\tvalidation_0-mlogloss:4.33797\n",
            "[86]\tvalidation_0-mlogloss:4.33265\n",
            "[87]\tvalidation_0-mlogloss:4.32340\n",
            "[88]\tvalidation_0-mlogloss:4.30508\n",
            "[89]\tvalidation_0-mlogloss:4.30136\n",
            "[90]\tvalidation_0-mlogloss:4.29098\n",
            "[91]\tvalidation_0-mlogloss:4.29530\n",
            "[92]\tvalidation_0-mlogloss:4.27910\n",
            "[93]\tvalidation_0-mlogloss:4.26523\n",
            "[94]\tvalidation_0-mlogloss:4.26727\n",
            "[95]\tvalidation_0-mlogloss:4.25686\n",
            "[96]\tvalidation_0-mlogloss:4.25519\n",
            "[97]\tvalidation_0-mlogloss:4.25377\n",
            "[98]\tvalidation_0-mlogloss:4.24577\n",
            "[99]\tvalidation_0-mlogloss:4.24250\n",
            "[0]\tvalidation_0-mlogloss:2.21404\n",
            "[1]\tvalidation_0-mlogloss:2.23128\n",
            "[2]\tvalidation_0-mlogloss:2.25080\n",
            "[3]\tvalidation_0-mlogloss:2.26707\n",
            "[4]\tvalidation_0-mlogloss:2.28611\n",
            "[5]\tvalidation_0-mlogloss:2.31044\n",
            "[6]\tvalidation_0-mlogloss:2.33629\n",
            "[7]\tvalidation_0-mlogloss:2.36412\n",
            "[8]\tvalidation_0-mlogloss:2.39132\n",
            "[9]\tvalidation_0-mlogloss:2.42048\n",
            "[10]\tvalidation_0-mlogloss:2.45101\n",
            "[11]\tvalidation_0-mlogloss:2.48396\n",
            "[12]\tvalidation_0-mlogloss:2.51635\n",
            "[13]\tvalidation_0-mlogloss:2.54787\n",
            "[14]\tvalidation_0-mlogloss:2.58215\n",
            "[15]\tvalidation_0-mlogloss:2.61653\n",
            "[16]\tvalidation_0-mlogloss:2.65009\n",
            "[17]\tvalidation_0-mlogloss:2.68694\n",
            "[18]\tvalidation_0-mlogloss:2.72326\n",
            "[19]\tvalidation_0-mlogloss:2.76177\n",
            "[20]\tvalidation_0-mlogloss:2.79758\n",
            "[21]\tvalidation_0-mlogloss:2.83467\n",
            "[22]\tvalidation_0-mlogloss:2.86117\n",
            "[23]\tvalidation_0-mlogloss:2.89822\n",
            "[24]\tvalidation_0-mlogloss:2.91778\n",
            "[25]\tvalidation_0-mlogloss:2.94139\n",
            "[26]\tvalidation_0-mlogloss:2.96161\n",
            "[27]\tvalidation_0-mlogloss:2.99827\n",
            "[28]\tvalidation_0-mlogloss:3.02288\n",
            "[29]\tvalidation_0-mlogloss:3.04750\n",
            "[30]\tvalidation_0-mlogloss:3.08294\n",
            "[31]\tvalidation_0-mlogloss:3.10463\n",
            "[32]\tvalidation_0-mlogloss:3.13429\n",
            "[33]\tvalidation_0-mlogloss:3.17036\n",
            "[34]\tvalidation_0-mlogloss:3.19639\n",
            "[35]\tvalidation_0-mlogloss:3.21789\n",
            "[36]\tvalidation_0-mlogloss:3.25382\n",
            "[37]\tvalidation_0-mlogloss:3.27886\n",
            "[38]\tvalidation_0-mlogloss:3.30191\n",
            "[39]\tvalidation_0-mlogloss:3.33525\n",
            "[40]\tvalidation_0-mlogloss:3.36933\n",
            "[41]\tvalidation_0-mlogloss:3.38917\n",
            "[42]\tvalidation_0-mlogloss:3.41812\n",
            "[43]\tvalidation_0-mlogloss:3.44601\n",
            "[44]\tvalidation_0-mlogloss:3.46350\n",
            "[45]\tvalidation_0-mlogloss:3.49875\n",
            "[46]\tvalidation_0-mlogloss:3.52093\n",
            "[47]\tvalidation_0-mlogloss:3.54573\n",
            "[48]\tvalidation_0-mlogloss:3.57546\n",
            "[49]\tvalidation_0-mlogloss:3.60658\n",
            "[50]\tvalidation_0-mlogloss:3.62228\n",
            "[51]\tvalidation_0-mlogloss:3.64123\n",
            "[52]\tvalidation_0-mlogloss:3.66535\n",
            "[53]\tvalidation_0-mlogloss:3.68988\n",
            "[54]\tvalidation_0-mlogloss:3.71256\n",
            "[55]\tvalidation_0-mlogloss:3.73150\n",
            "[56]\tvalidation_0-mlogloss:3.76225\n",
            "[57]\tvalidation_0-mlogloss:3.78214\n",
            "[58]\tvalidation_0-mlogloss:3.81671\n",
            "[59]\tvalidation_0-mlogloss:3.84205\n",
            "[60]\tvalidation_0-mlogloss:3.85513\n",
            "[61]\tvalidation_0-mlogloss:3.88195\n",
            "[62]\tvalidation_0-mlogloss:3.90161\n",
            "[63]\tvalidation_0-mlogloss:3.91648\n",
            "[64]\tvalidation_0-mlogloss:3.93552\n",
            "[65]\tvalidation_0-mlogloss:3.94815\n",
            "[66]\tvalidation_0-mlogloss:3.98164\n",
            "[67]\tvalidation_0-mlogloss:4.00433\n",
            "[68]\tvalidation_0-mlogloss:4.01737\n",
            "[69]\tvalidation_0-mlogloss:4.02263\n",
            "[70]\tvalidation_0-mlogloss:4.03425\n",
            "[71]\tvalidation_0-mlogloss:4.04911\n",
            "[72]\tvalidation_0-mlogloss:4.06277\n",
            "[73]\tvalidation_0-mlogloss:4.07430\n",
            "[74]\tvalidation_0-mlogloss:4.09596\n",
            "[75]\tvalidation_0-mlogloss:4.09030\n",
            "[76]\tvalidation_0-mlogloss:4.09059\n",
            "[77]\tvalidation_0-mlogloss:4.08409\n",
            "[78]\tvalidation_0-mlogloss:4.08369\n",
            "[79]\tvalidation_0-mlogloss:4.07773\n",
            "[80]\tvalidation_0-mlogloss:4.08422\n",
            "[81]\tvalidation_0-mlogloss:4.08721\n",
            "[82]\tvalidation_0-mlogloss:4.05565\n",
            "[83]\tvalidation_0-mlogloss:4.06528\n",
            "[84]\tvalidation_0-mlogloss:4.04110\n",
            "[85]\tvalidation_0-mlogloss:4.01985\n",
            "[86]\tvalidation_0-mlogloss:4.02368\n",
            "[87]\tvalidation_0-mlogloss:4.01444\n",
            "[88]\tvalidation_0-mlogloss:4.00008\n",
            "[89]\tvalidation_0-mlogloss:3.98689\n",
            "[90]\tvalidation_0-mlogloss:3.99184\n",
            "[91]\tvalidation_0-mlogloss:3.98786\n",
            "[92]\tvalidation_0-mlogloss:3.98494\n",
            "[93]\tvalidation_0-mlogloss:3.97457\n",
            "[94]\tvalidation_0-mlogloss:3.97955\n",
            "[95]\tvalidation_0-mlogloss:3.97813\n",
            "[96]\tvalidation_0-mlogloss:3.97071\n",
            "[97]\tvalidation_0-mlogloss:3.97505\n",
            "[98]\tvalidation_0-mlogloss:3.96540\n",
            "[99]\tvalidation_0-mlogloss:3.96428\n",
            "[0]\tvalidation_0-mlogloss:2.21200\n",
            "[1]\tvalidation_0-mlogloss:2.22385\n",
            "[2]\tvalidation_0-mlogloss:2.23676\n",
            "[3]\tvalidation_0-mlogloss:2.24911\n",
            "[4]\tvalidation_0-mlogloss:2.26273\n",
            "[5]\tvalidation_0-mlogloss:2.28080\n",
            "[6]\tvalidation_0-mlogloss:2.30022\n",
            "[7]\tvalidation_0-mlogloss:2.32128\n",
            "[8]\tvalidation_0-mlogloss:2.34355\n",
            "[9]\tvalidation_0-mlogloss:2.36619\n",
            "[10]\tvalidation_0-mlogloss:2.38942\n",
            "[11]\tvalidation_0-mlogloss:2.41322\n",
            "[12]\tvalidation_0-mlogloss:2.43711\n",
            "[13]\tvalidation_0-mlogloss:2.46140\n",
            "[14]\tvalidation_0-mlogloss:2.48757\n",
            "[15]\tvalidation_0-mlogloss:2.51607\n",
            "[16]\tvalidation_0-mlogloss:2.54765\n",
            "[17]\tvalidation_0-mlogloss:2.57611\n",
            "[18]\tvalidation_0-mlogloss:2.60681\n",
            "[19]\tvalidation_0-mlogloss:2.63797\n",
            "[20]\tvalidation_0-mlogloss:2.65857\n",
            "[21]\tvalidation_0-mlogloss:2.69262\n",
            "[22]\tvalidation_0-mlogloss:2.71650\n",
            "[23]\tvalidation_0-mlogloss:2.74205\n",
            "[24]\tvalidation_0-mlogloss:2.76824\n",
            "[25]\tvalidation_0-mlogloss:2.79714\n",
            "[26]\tvalidation_0-mlogloss:2.83939\n",
            "[27]\tvalidation_0-mlogloss:2.86612\n",
            "[28]\tvalidation_0-mlogloss:2.91361\n",
            "[29]\tvalidation_0-mlogloss:2.94530\n",
            "[30]\tvalidation_0-mlogloss:2.96460\n",
            "[31]\tvalidation_0-mlogloss:2.98321\n",
            "[32]\tvalidation_0-mlogloss:3.01545\n",
            "[33]\tvalidation_0-mlogloss:3.03645\n",
            "[34]\tvalidation_0-mlogloss:3.06438\n",
            "[35]\tvalidation_0-mlogloss:3.09247\n",
            "[36]\tvalidation_0-mlogloss:3.10961\n",
            "[37]\tvalidation_0-mlogloss:3.12814\n",
            "[38]\tvalidation_0-mlogloss:3.15886\n",
            "[39]\tvalidation_0-mlogloss:3.17573\n",
            "[40]\tvalidation_0-mlogloss:3.20534\n",
            "[41]\tvalidation_0-mlogloss:3.23031\n",
            "[42]\tvalidation_0-mlogloss:3.24228\n",
            "[43]\tvalidation_0-mlogloss:3.25839\n",
            "[44]\tvalidation_0-mlogloss:3.28506\n",
            "[45]\tvalidation_0-mlogloss:3.30166\n",
            "[46]\tvalidation_0-mlogloss:3.31276\n",
            "[47]\tvalidation_0-mlogloss:3.34594\n",
            "[48]\tvalidation_0-mlogloss:3.36398\n",
            "[49]\tvalidation_0-mlogloss:3.37766\n",
            "[50]\tvalidation_0-mlogloss:3.39756\n",
            "[51]\tvalidation_0-mlogloss:3.42663\n",
            "[52]\tvalidation_0-mlogloss:3.43110\n",
            "[53]\tvalidation_0-mlogloss:3.46116\n",
            "[54]\tvalidation_0-mlogloss:3.48200\n",
            "[55]\tvalidation_0-mlogloss:3.49404\n",
            "[56]\tvalidation_0-mlogloss:3.50136\n",
            "[57]\tvalidation_0-mlogloss:3.52621\n",
            "[58]\tvalidation_0-mlogloss:3.54738\n",
            "[59]\tvalidation_0-mlogloss:3.54754\n",
            "[60]\tvalidation_0-mlogloss:3.55945\n",
            "[61]\tvalidation_0-mlogloss:3.56241\n",
            "[62]\tvalidation_0-mlogloss:3.57463\n",
            "[63]\tvalidation_0-mlogloss:3.57713\n",
            "[64]\tvalidation_0-mlogloss:3.59033\n",
            "[65]\tvalidation_0-mlogloss:3.61174\n",
            "[66]\tvalidation_0-mlogloss:3.61912\n",
            "[67]\tvalidation_0-mlogloss:3.62503\n",
            "[68]\tvalidation_0-mlogloss:3.64261\n",
            "[69]\tvalidation_0-mlogloss:3.65718\n",
            "[70]\tvalidation_0-mlogloss:3.66539\n",
            "[71]\tvalidation_0-mlogloss:3.68247\n",
            "[72]\tvalidation_0-mlogloss:3.66187\n",
            "[73]\tvalidation_0-mlogloss:3.67849\n",
            "[74]\tvalidation_0-mlogloss:3.68646\n",
            "[75]\tvalidation_0-mlogloss:3.70146\n",
            "[76]\tvalidation_0-mlogloss:3.68650\n",
            "[77]\tvalidation_0-mlogloss:3.68547\n",
            "[78]\tvalidation_0-mlogloss:3.68519\n",
            "[79]\tvalidation_0-mlogloss:3.65633\n",
            "[80]\tvalidation_0-mlogloss:3.65768\n",
            "[81]\tvalidation_0-mlogloss:3.63159\n",
            "[82]\tvalidation_0-mlogloss:3.64702\n",
            "[83]\tvalidation_0-mlogloss:3.61883\n",
            "[84]\tvalidation_0-mlogloss:3.62496\n",
            "[85]\tvalidation_0-mlogloss:3.61822\n",
            "[86]\tvalidation_0-mlogloss:3.63608\n",
            "[87]\tvalidation_0-mlogloss:3.63147\n",
            "[88]\tvalidation_0-mlogloss:3.63362\n",
            "[89]\tvalidation_0-mlogloss:3.64212\n",
            "[90]\tvalidation_0-mlogloss:3.64432\n",
            "[91]\tvalidation_0-mlogloss:3.65259\n",
            "[92]\tvalidation_0-mlogloss:3.65605\n",
            "[93]\tvalidation_0-mlogloss:3.64399\n",
            "[94]\tvalidation_0-mlogloss:3.63457\n",
            "[95]\tvalidation_0-mlogloss:3.62112\n",
            "[96]\tvalidation_0-mlogloss:3.59774\n",
            "[97]\tvalidation_0-mlogloss:3.58677\n",
            "[98]\tvalidation_0-mlogloss:3.56424\n",
            "[99]\tvalidation_0-mlogloss:3.54187\n",
            "[0]\tvalidation_0-mlogloss:2.20944\n",
            "[1]\tvalidation_0-mlogloss:2.21862\n",
            "[2]\tvalidation_0-mlogloss:2.23515\n",
            "[3]\tvalidation_0-mlogloss:2.24775\n",
            "[4]\tvalidation_0-mlogloss:2.25969\n",
            "[5]\tvalidation_0-mlogloss:2.27616\n",
            "[6]\tvalidation_0-mlogloss:2.29025\n",
            "[7]\tvalidation_0-mlogloss:2.30517\n",
            "[8]\tvalidation_0-mlogloss:2.32850\n",
            "[9]\tvalidation_0-mlogloss:2.35186\n",
            "[10]\tvalidation_0-mlogloss:2.37893\n",
            "[11]\tvalidation_0-mlogloss:2.40872\n",
            "[12]\tvalidation_0-mlogloss:2.44024\n",
            "[13]\tvalidation_0-mlogloss:2.47376\n",
            "[14]\tvalidation_0-mlogloss:2.49712\n",
            "[15]\tvalidation_0-mlogloss:2.52024\n",
            "[16]\tvalidation_0-mlogloss:2.54221\n",
            "[17]\tvalidation_0-mlogloss:2.56629\n",
            "[18]\tvalidation_0-mlogloss:2.59128\n",
            "[19]\tvalidation_0-mlogloss:2.62022\n",
            "[20]\tvalidation_0-mlogloss:2.64935\n",
            "[21]\tvalidation_0-mlogloss:2.67390\n",
            "[22]\tvalidation_0-mlogloss:2.69927\n",
            "[23]\tvalidation_0-mlogloss:2.71758\n",
            "[24]\tvalidation_0-mlogloss:2.73361\n",
            "[25]\tvalidation_0-mlogloss:2.75536\n",
            "[26]\tvalidation_0-mlogloss:2.76847\n",
            "[27]\tvalidation_0-mlogloss:2.78934\n",
            "[28]\tvalidation_0-mlogloss:2.80442\n",
            "[29]\tvalidation_0-mlogloss:2.81693\n",
            "[30]\tvalidation_0-mlogloss:2.83285\n",
            "[31]\tvalidation_0-mlogloss:2.85832\n",
            "[32]\tvalidation_0-mlogloss:2.87851\n",
            "[33]\tvalidation_0-mlogloss:2.89427\n",
            "[34]\tvalidation_0-mlogloss:2.92121\n",
            "[35]\tvalidation_0-mlogloss:2.95144\n",
            "[36]\tvalidation_0-mlogloss:2.96151\n",
            "[37]\tvalidation_0-mlogloss:2.97849\n",
            "[38]\tvalidation_0-mlogloss:3.01504\n",
            "[39]\tvalidation_0-mlogloss:3.03447\n",
            "[40]\tvalidation_0-mlogloss:3.06546\n",
            "[41]\tvalidation_0-mlogloss:3.08729\n",
            "[42]\tvalidation_0-mlogloss:3.11625\n",
            "[43]\tvalidation_0-mlogloss:3.13531\n",
            "[44]\tvalidation_0-mlogloss:3.16207\n",
            "[45]\tvalidation_0-mlogloss:3.17704\n",
            "[46]\tvalidation_0-mlogloss:3.19737\n",
            "[47]\tvalidation_0-mlogloss:3.22330\n",
            "[48]\tvalidation_0-mlogloss:3.23868\n",
            "[49]\tvalidation_0-mlogloss:3.26004\n",
            "[50]\tvalidation_0-mlogloss:3.29146\n",
            "[51]\tvalidation_0-mlogloss:3.31276\n",
            "[52]\tvalidation_0-mlogloss:3.33814\n",
            "[53]\tvalidation_0-mlogloss:3.36099\n",
            "[54]\tvalidation_0-mlogloss:3.38854\n",
            "[55]\tvalidation_0-mlogloss:3.41497\n",
            "[56]\tvalidation_0-mlogloss:3.43356\n",
            "[57]\tvalidation_0-mlogloss:3.45779\n",
            "[58]\tvalidation_0-mlogloss:3.48111\n",
            "[59]\tvalidation_0-mlogloss:3.49884\n",
            "[60]\tvalidation_0-mlogloss:3.51780\n",
            "[61]\tvalidation_0-mlogloss:3.53029\n",
            "[62]\tvalidation_0-mlogloss:3.54796\n",
            "[63]\tvalidation_0-mlogloss:3.54973\n",
            "[64]\tvalidation_0-mlogloss:3.56992\n",
            "[65]\tvalidation_0-mlogloss:3.58442\n",
            "[66]\tvalidation_0-mlogloss:3.58848\n",
            "[67]\tvalidation_0-mlogloss:3.60354\n",
            "[68]\tvalidation_0-mlogloss:3.61860\n",
            "[69]\tvalidation_0-mlogloss:3.63810\n",
            "[70]\tvalidation_0-mlogloss:3.63314\n",
            "[71]\tvalidation_0-mlogloss:3.64421\n",
            "[72]\tvalidation_0-mlogloss:3.65104\n",
            "[73]\tvalidation_0-mlogloss:3.65425\n",
            "[74]\tvalidation_0-mlogloss:3.66602\n",
            "[75]\tvalidation_0-mlogloss:3.67991\n",
            "[76]\tvalidation_0-mlogloss:3.69019\n",
            "[77]\tvalidation_0-mlogloss:3.70493\n",
            "[78]\tvalidation_0-mlogloss:3.70853\n",
            "[79]\tvalidation_0-mlogloss:3.69845\n",
            "[80]\tvalidation_0-mlogloss:3.70266\n",
            "[81]\tvalidation_0-mlogloss:3.71416\n",
            "[82]\tvalidation_0-mlogloss:3.71138\n",
            "[83]\tvalidation_0-mlogloss:3.70361\n",
            "[84]\tvalidation_0-mlogloss:3.70467\n",
            "[85]\tvalidation_0-mlogloss:3.69772\n",
            "[86]\tvalidation_0-mlogloss:3.70998\n",
            "[87]\tvalidation_0-mlogloss:3.70232\n",
            "[88]\tvalidation_0-mlogloss:3.68996\n",
            "[89]\tvalidation_0-mlogloss:3.67293\n",
            "[90]\tvalidation_0-mlogloss:3.66036\n",
            "[91]\tvalidation_0-mlogloss:3.64991\n",
            "[92]\tvalidation_0-mlogloss:3.65258\n",
            "[93]\tvalidation_0-mlogloss:3.64097\n",
            "[94]\tvalidation_0-mlogloss:3.62717\n",
            "[95]\tvalidation_0-mlogloss:3.61393\n",
            "[96]\tvalidation_0-mlogloss:3.61355\n",
            "[97]\tvalidation_0-mlogloss:3.60328\n",
            "[98]\tvalidation_0-mlogloss:3.60478\n",
            "[99]\tvalidation_0-mlogloss:3.58739\n",
            "[0]\tvalidation_0-mlogloss:2.19660\n",
            "[1]\tvalidation_0-mlogloss:2.20680\n",
            "[2]\tvalidation_0-mlogloss:2.21170\n",
            "[3]\tvalidation_0-mlogloss:2.22205\n",
            "[4]\tvalidation_0-mlogloss:2.23227\n",
            "[5]\tvalidation_0-mlogloss:2.24384\n",
            "[6]\tvalidation_0-mlogloss:2.25810\n",
            "[7]\tvalidation_0-mlogloss:2.28256\n",
            "[8]\tvalidation_0-mlogloss:2.30716\n",
            "[9]\tvalidation_0-mlogloss:2.33227\n",
            "[10]\tvalidation_0-mlogloss:2.36442\n",
            "[11]\tvalidation_0-mlogloss:2.39537\n",
            "[12]\tvalidation_0-mlogloss:2.42806\n",
            "[13]\tvalidation_0-mlogloss:2.45929\n",
            "[14]\tvalidation_0-mlogloss:2.49466\n",
            "[15]\tvalidation_0-mlogloss:2.52679\n",
            "[16]\tvalidation_0-mlogloss:2.55886\n",
            "[17]\tvalidation_0-mlogloss:2.59579\n",
            "[18]\tvalidation_0-mlogloss:2.62789\n",
            "[19]\tvalidation_0-mlogloss:2.66038\n",
            "[20]\tvalidation_0-mlogloss:2.69288\n",
            "[21]\tvalidation_0-mlogloss:2.72700\n",
            "[22]\tvalidation_0-mlogloss:2.76583\n",
            "[23]\tvalidation_0-mlogloss:2.80267\n",
            "[24]\tvalidation_0-mlogloss:2.83965\n",
            "[25]\tvalidation_0-mlogloss:2.87603\n",
            "[26]\tvalidation_0-mlogloss:2.91212\n",
            "[27]\tvalidation_0-mlogloss:2.95140\n",
            "[28]\tvalidation_0-mlogloss:2.98924\n",
            "[29]\tvalidation_0-mlogloss:3.02762\n",
            "[30]\tvalidation_0-mlogloss:3.06508\n",
            "[31]\tvalidation_0-mlogloss:3.10445\n",
            "[32]\tvalidation_0-mlogloss:3.13932\n",
            "[33]\tvalidation_0-mlogloss:3.18118\n",
            "[34]\tvalidation_0-mlogloss:3.20336\n",
            "[35]\tvalidation_0-mlogloss:3.22499\n",
            "[36]\tvalidation_0-mlogloss:3.26409\n",
            "[37]\tvalidation_0-mlogloss:3.29281\n",
            "[38]\tvalidation_0-mlogloss:3.32522\n",
            "[39]\tvalidation_0-mlogloss:3.34521\n",
            "[40]\tvalidation_0-mlogloss:3.37371\n",
            "[41]\tvalidation_0-mlogloss:3.39409\n",
            "[42]\tvalidation_0-mlogloss:3.42408\n",
            "[43]\tvalidation_0-mlogloss:3.44571\n",
            "[44]\tvalidation_0-mlogloss:3.47872\n",
            "[45]\tvalidation_0-mlogloss:3.50178\n",
            "[46]\tvalidation_0-mlogloss:3.52921\n",
            "[47]\tvalidation_0-mlogloss:3.54153\n",
            "[48]\tvalidation_0-mlogloss:3.56771\n",
            "[49]\tvalidation_0-mlogloss:3.58388\n",
            "[50]\tvalidation_0-mlogloss:3.61340\n",
            "[51]\tvalidation_0-mlogloss:3.62408\n",
            "[52]\tvalidation_0-mlogloss:3.65246\n",
            "[53]\tvalidation_0-mlogloss:3.66532\n",
            "[54]\tvalidation_0-mlogloss:3.69218\n",
            "[55]\tvalidation_0-mlogloss:3.71186\n",
            "[56]\tvalidation_0-mlogloss:3.73228\n",
            "[57]\tvalidation_0-mlogloss:3.74893\n",
            "[58]\tvalidation_0-mlogloss:3.76780\n",
            "[59]\tvalidation_0-mlogloss:3.80184\n",
            "[60]\tvalidation_0-mlogloss:3.82198\n",
            "[61]\tvalidation_0-mlogloss:3.85605\n",
            "[62]\tvalidation_0-mlogloss:3.87923\n",
            "[63]\tvalidation_0-mlogloss:3.89740\n",
            "[64]\tvalidation_0-mlogloss:3.91770\n",
            "[65]\tvalidation_0-mlogloss:3.94379\n",
            "[66]\tvalidation_0-mlogloss:3.95810\n",
            "[67]\tvalidation_0-mlogloss:3.97028\n",
            "[68]\tvalidation_0-mlogloss:3.98503\n",
            "[69]\tvalidation_0-mlogloss:4.00154\n",
            "[70]\tvalidation_0-mlogloss:4.00902\n",
            "[71]\tvalidation_0-mlogloss:4.02532\n",
            "[72]\tvalidation_0-mlogloss:4.03222\n",
            "[73]\tvalidation_0-mlogloss:4.05211\n",
            "[74]\tvalidation_0-mlogloss:4.06365\n",
            "[75]\tvalidation_0-mlogloss:4.08155\n",
            "[76]\tvalidation_0-mlogloss:4.09905\n",
            "[77]\tvalidation_0-mlogloss:4.12198\n",
            "[78]\tvalidation_0-mlogloss:4.11799\n",
            "[79]\tvalidation_0-mlogloss:4.12477\n",
            "[80]\tvalidation_0-mlogloss:4.10841\n",
            "[81]\tvalidation_0-mlogloss:4.11971\n",
            "[82]\tvalidation_0-mlogloss:4.10649\n",
            "[83]\tvalidation_0-mlogloss:4.11260\n",
            "[84]\tvalidation_0-mlogloss:4.12399\n",
            "[85]\tvalidation_0-mlogloss:4.10495\n",
            "[86]\tvalidation_0-mlogloss:4.11173\n",
            "[87]\tvalidation_0-mlogloss:4.09084\n",
            "[88]\tvalidation_0-mlogloss:4.08055\n",
            "[89]\tvalidation_0-mlogloss:4.07141\n",
            "[90]\tvalidation_0-mlogloss:4.06086\n",
            "[91]\tvalidation_0-mlogloss:4.07179\n",
            "[92]\tvalidation_0-mlogloss:4.05352\n",
            "[93]\tvalidation_0-mlogloss:4.05007\n",
            "[94]\tvalidation_0-mlogloss:4.04128\n",
            "[95]\tvalidation_0-mlogloss:4.04292\n",
            "[96]\tvalidation_0-mlogloss:4.05162\n",
            "[97]\tvalidation_0-mlogloss:4.04967\n",
            "[98]\tvalidation_0-mlogloss:4.03995\n",
            "[99]\tvalidation_0-mlogloss:4.04379\n",
            "[0]\tvalidation_0-mlogloss:2.20343\n",
            "[1]\tvalidation_0-mlogloss:2.21308\n",
            "[2]\tvalidation_0-mlogloss:2.22808\n",
            "[3]\tvalidation_0-mlogloss:2.24802\n",
            "[4]\tvalidation_0-mlogloss:2.27044\n",
            "[5]\tvalidation_0-mlogloss:2.29259\n",
            "[6]\tvalidation_0-mlogloss:2.31843\n",
            "[7]\tvalidation_0-mlogloss:2.34667\n",
            "[8]\tvalidation_0-mlogloss:2.37558\n",
            "[9]\tvalidation_0-mlogloss:2.40491\n",
            "[10]\tvalidation_0-mlogloss:2.43387\n",
            "[11]\tvalidation_0-mlogloss:2.46627\n",
            "[12]\tvalidation_0-mlogloss:2.49906\n",
            "[13]\tvalidation_0-mlogloss:2.53264\n",
            "[14]\tvalidation_0-mlogloss:2.56825\n",
            "[15]\tvalidation_0-mlogloss:2.60272\n",
            "[16]\tvalidation_0-mlogloss:2.63953\n",
            "[17]\tvalidation_0-mlogloss:2.67711\n",
            "[18]\tvalidation_0-mlogloss:2.71226\n",
            "[19]\tvalidation_0-mlogloss:2.74988\n",
            "[20]\tvalidation_0-mlogloss:2.79063\n",
            "[21]\tvalidation_0-mlogloss:2.82555\n",
            "[22]\tvalidation_0-mlogloss:2.86289\n",
            "[23]\tvalidation_0-mlogloss:2.89809\n",
            "[24]\tvalidation_0-mlogloss:2.93278\n",
            "[25]\tvalidation_0-mlogloss:2.96678\n",
            "[26]\tvalidation_0-mlogloss:3.00769\n",
            "[27]\tvalidation_0-mlogloss:3.02911\n",
            "[28]\tvalidation_0-mlogloss:3.07024\n",
            "[29]\tvalidation_0-mlogloss:3.10290\n",
            "[30]\tvalidation_0-mlogloss:3.14204\n",
            "[31]\tvalidation_0-mlogloss:3.17077\n",
            "[32]\tvalidation_0-mlogloss:3.20957\n",
            "[33]\tvalidation_0-mlogloss:3.23401\n",
            "[34]\tvalidation_0-mlogloss:3.27113\n",
            "[35]\tvalidation_0-mlogloss:3.28468\n",
            "[36]\tvalidation_0-mlogloss:3.32593\n",
            "[37]\tvalidation_0-mlogloss:3.35242\n",
            "[38]\tvalidation_0-mlogloss:3.38679\n",
            "[39]\tvalidation_0-mlogloss:3.41819\n",
            "[40]\tvalidation_0-mlogloss:3.46136\n",
            "[41]\tvalidation_0-mlogloss:3.49117\n",
            "[42]\tvalidation_0-mlogloss:3.52208\n",
            "[43]\tvalidation_0-mlogloss:3.54030\n",
            "[44]\tvalidation_0-mlogloss:3.57086\n",
            "[45]\tvalidation_0-mlogloss:3.58854\n",
            "[46]\tvalidation_0-mlogloss:3.62539\n",
            "[47]\tvalidation_0-mlogloss:3.65805\n",
            "[48]\tvalidation_0-mlogloss:3.67770\n",
            "[49]\tvalidation_0-mlogloss:3.70143\n",
            "[50]\tvalidation_0-mlogloss:3.71664\n",
            "[51]\tvalidation_0-mlogloss:3.72695\n",
            "[52]\tvalidation_0-mlogloss:3.75725\n",
            "[53]\tvalidation_0-mlogloss:3.77410\n",
            "[54]\tvalidation_0-mlogloss:3.79747\n",
            "[55]\tvalidation_0-mlogloss:3.81637\n",
            "[56]\tvalidation_0-mlogloss:3.84003\n",
            "[57]\tvalidation_0-mlogloss:3.86345\n",
            "[58]\tvalidation_0-mlogloss:3.86591\n",
            "[59]\tvalidation_0-mlogloss:3.88290\n",
            "[60]\tvalidation_0-mlogloss:3.89179\n",
            "[61]\tvalidation_0-mlogloss:3.91425\n",
            "[62]\tvalidation_0-mlogloss:3.92053\n",
            "[63]\tvalidation_0-mlogloss:3.93290\n",
            "[64]\tvalidation_0-mlogloss:3.94041\n",
            "[65]\tvalidation_0-mlogloss:3.95553\n",
            "[66]\tvalidation_0-mlogloss:3.96221\n",
            "[67]\tvalidation_0-mlogloss:3.97066\n",
            "[68]\tvalidation_0-mlogloss:3.98748\n",
            "[69]\tvalidation_0-mlogloss:4.00541\n",
            "[70]\tvalidation_0-mlogloss:4.01582\n",
            "[71]\tvalidation_0-mlogloss:4.02446\n",
            "[72]\tvalidation_0-mlogloss:4.04338\n",
            "[73]\tvalidation_0-mlogloss:4.04579\n",
            "[74]\tvalidation_0-mlogloss:4.06749\n",
            "[75]\tvalidation_0-mlogloss:4.07721\n",
            "[76]\tvalidation_0-mlogloss:4.08780\n",
            "[77]\tvalidation_0-mlogloss:4.10066\n",
            "[78]\tvalidation_0-mlogloss:4.10253\n",
            "[79]\tvalidation_0-mlogloss:4.09320\n",
            "[80]\tvalidation_0-mlogloss:4.08572\n",
            "[81]\tvalidation_0-mlogloss:4.08365\n",
            "[82]\tvalidation_0-mlogloss:4.08840\n",
            "[83]\tvalidation_0-mlogloss:4.07209\n",
            "[84]\tvalidation_0-mlogloss:4.07725\n",
            "[85]\tvalidation_0-mlogloss:4.07320\n",
            "[86]\tvalidation_0-mlogloss:4.07347\n",
            "[87]\tvalidation_0-mlogloss:4.06980\n",
            "[88]\tvalidation_0-mlogloss:4.05015\n",
            "[89]\tvalidation_0-mlogloss:4.03664\n",
            "[90]\tvalidation_0-mlogloss:4.01859\n",
            "[91]\tvalidation_0-mlogloss:4.00900\n",
            "[92]\tvalidation_0-mlogloss:3.99424\n",
            "[93]\tvalidation_0-mlogloss:3.98431\n",
            "[94]\tvalidation_0-mlogloss:3.97511\n",
            "[95]\tvalidation_0-mlogloss:3.96415\n",
            "[96]\tvalidation_0-mlogloss:3.95380\n",
            "[97]\tvalidation_0-mlogloss:3.94278\n",
            "[98]\tvalidation_0-mlogloss:3.92991\n",
            "[99]\tvalidation_0-mlogloss:3.92638\n",
            "[0]\tvalidation_0-mlogloss:2.22223\n",
            "[1]\tvalidation_0-mlogloss:2.25995\n",
            "[2]\tvalidation_0-mlogloss:2.29837\n",
            "[3]\tvalidation_0-mlogloss:2.33743\n",
            "[4]\tvalidation_0-mlogloss:2.37579\n",
            "[5]\tvalidation_0-mlogloss:2.42192\n",
            "[6]\tvalidation_0-mlogloss:2.45024\n",
            "[7]\tvalidation_0-mlogloss:2.47554\n",
            "[8]\tvalidation_0-mlogloss:2.50414\n",
            "[9]\tvalidation_0-mlogloss:2.53202\n",
            "[10]\tvalidation_0-mlogloss:2.57224\n",
            "[11]\tvalidation_0-mlogloss:2.60941\n",
            "[12]\tvalidation_0-mlogloss:2.65007\n",
            "[13]\tvalidation_0-mlogloss:2.69128\n",
            "[14]\tvalidation_0-mlogloss:2.72890\n",
            "[15]\tvalidation_0-mlogloss:2.76769\n",
            "[16]\tvalidation_0-mlogloss:2.80768\n",
            "[17]\tvalidation_0-mlogloss:2.84918\n",
            "[18]\tvalidation_0-mlogloss:2.88965\n",
            "[19]\tvalidation_0-mlogloss:2.93311\n",
            "[20]\tvalidation_0-mlogloss:2.97602\n",
            "[21]\tvalidation_0-mlogloss:3.02019\n",
            "[22]\tvalidation_0-mlogloss:3.06694\n",
            "[23]\tvalidation_0-mlogloss:3.11090\n",
            "[24]\tvalidation_0-mlogloss:3.14628\n",
            "[25]\tvalidation_0-mlogloss:3.18570\n",
            "[26]\tvalidation_0-mlogloss:3.22052\n",
            "[27]\tvalidation_0-mlogloss:3.25766\n",
            "[28]\tvalidation_0-mlogloss:3.29220\n",
            "[29]\tvalidation_0-mlogloss:3.33430\n",
            "[30]\tvalidation_0-mlogloss:3.36964\n",
            "[31]\tvalidation_0-mlogloss:3.40230\n",
            "[32]\tvalidation_0-mlogloss:3.42558\n",
            "[33]\tvalidation_0-mlogloss:3.45923\n",
            "[34]\tvalidation_0-mlogloss:3.48393\n",
            "[35]\tvalidation_0-mlogloss:3.51187\n",
            "[36]\tvalidation_0-mlogloss:3.53447\n",
            "[37]\tvalidation_0-mlogloss:3.54605\n",
            "[38]\tvalidation_0-mlogloss:3.57612\n",
            "[39]\tvalidation_0-mlogloss:3.58840\n",
            "[40]\tvalidation_0-mlogloss:3.61850\n",
            "[41]\tvalidation_0-mlogloss:3.65187\n",
            "[42]\tvalidation_0-mlogloss:3.67331\n",
            "[43]\tvalidation_0-mlogloss:3.70830\n",
            "[44]\tvalidation_0-mlogloss:3.72166\n",
            "[45]\tvalidation_0-mlogloss:3.74980\n",
            "[46]\tvalidation_0-mlogloss:3.77510\n",
            "[47]\tvalidation_0-mlogloss:3.79692\n",
            "[48]\tvalidation_0-mlogloss:3.83122\n",
            "[49]\tvalidation_0-mlogloss:3.85196\n",
            "[50]\tvalidation_0-mlogloss:3.87836\n",
            "[51]\tvalidation_0-mlogloss:3.90840\n",
            "[52]\tvalidation_0-mlogloss:3.93951\n",
            "[53]\tvalidation_0-mlogloss:3.96440\n",
            "[54]\tvalidation_0-mlogloss:3.98973\n",
            "[55]\tvalidation_0-mlogloss:4.01737\n",
            "[56]\tvalidation_0-mlogloss:4.04452\n",
            "[57]\tvalidation_0-mlogloss:4.07111\n",
            "[58]\tvalidation_0-mlogloss:4.10271\n",
            "[59]\tvalidation_0-mlogloss:4.12229\n",
            "[60]\tvalidation_0-mlogloss:4.15007\n",
            "[61]\tvalidation_0-mlogloss:4.15068\n",
            "[62]\tvalidation_0-mlogloss:4.15653\n",
            "[63]\tvalidation_0-mlogloss:4.16659\n",
            "[64]\tvalidation_0-mlogloss:4.17897\n",
            "[65]\tvalidation_0-mlogloss:4.19530\n",
            "[66]\tvalidation_0-mlogloss:4.19890\n",
            "[67]\tvalidation_0-mlogloss:4.20916\n",
            "[68]\tvalidation_0-mlogloss:4.23214\n",
            "[69]\tvalidation_0-mlogloss:4.23796\n",
            "[70]\tvalidation_0-mlogloss:4.24810\n",
            "[71]\tvalidation_0-mlogloss:4.24600\n",
            "[72]\tvalidation_0-mlogloss:4.23716\n",
            "[73]\tvalidation_0-mlogloss:4.24792\n",
            "[74]\tvalidation_0-mlogloss:4.25468\n",
            "[75]\tvalidation_0-mlogloss:4.24822\n",
            "[76]\tvalidation_0-mlogloss:4.25420\n",
            "[77]\tvalidation_0-mlogloss:4.24385\n",
            "[78]\tvalidation_0-mlogloss:4.24628\n",
            "[79]\tvalidation_0-mlogloss:4.23207\n",
            "[80]\tvalidation_0-mlogloss:4.21204\n",
            "[81]\tvalidation_0-mlogloss:4.20547\n",
            "[82]\tvalidation_0-mlogloss:4.18553\n",
            "[83]\tvalidation_0-mlogloss:4.16140\n",
            "[84]\tvalidation_0-mlogloss:4.15584\n",
            "[85]\tvalidation_0-mlogloss:4.13095\n",
            "[86]\tvalidation_0-mlogloss:4.12543\n",
            "[87]\tvalidation_0-mlogloss:4.10052\n",
            "[88]\tvalidation_0-mlogloss:4.08625\n",
            "[89]\tvalidation_0-mlogloss:4.08083\n",
            "[90]\tvalidation_0-mlogloss:4.06603\n",
            "[91]\tvalidation_0-mlogloss:4.04880\n",
            "[92]\tvalidation_0-mlogloss:4.04620\n",
            "[93]\tvalidation_0-mlogloss:4.02849\n",
            "[94]\tvalidation_0-mlogloss:4.01724\n",
            "[95]\tvalidation_0-mlogloss:4.02078\n",
            "[96]\tvalidation_0-mlogloss:4.00288\n",
            "[97]\tvalidation_0-mlogloss:3.99449\n",
            "[98]\tvalidation_0-mlogloss:3.99335\n",
            "[99]\tvalidation_0-mlogloss:3.97871\n",
            "[0]\tvalidation_0-mlogloss:2.21739\n",
            "[1]\tvalidation_0-mlogloss:2.24228\n",
            "[2]\tvalidation_0-mlogloss:2.26860\n",
            "[3]\tvalidation_0-mlogloss:2.29723\n",
            "[4]\tvalidation_0-mlogloss:2.32703\n",
            "[5]\tvalidation_0-mlogloss:2.35683\n",
            "[6]\tvalidation_0-mlogloss:2.38181\n",
            "[7]\tvalidation_0-mlogloss:2.40702\n",
            "[8]\tvalidation_0-mlogloss:2.42643\n",
            "[9]\tvalidation_0-mlogloss:2.45049\n",
            "[10]\tvalidation_0-mlogloss:2.47393\n",
            "[11]\tvalidation_0-mlogloss:2.50006\n",
            "[12]\tvalidation_0-mlogloss:2.52620\n",
            "[13]\tvalidation_0-mlogloss:2.55599\n",
            "[14]\tvalidation_0-mlogloss:2.58503\n",
            "[15]\tvalidation_0-mlogloss:2.61475\n",
            "[16]\tvalidation_0-mlogloss:2.63970\n",
            "[17]\tvalidation_0-mlogloss:2.66386\n",
            "[18]\tvalidation_0-mlogloss:2.68989\n",
            "[19]\tvalidation_0-mlogloss:2.70688\n",
            "[20]\tvalidation_0-mlogloss:2.73748\n",
            "[21]\tvalidation_0-mlogloss:2.75366\n",
            "[22]\tvalidation_0-mlogloss:2.77236\n",
            "[23]\tvalidation_0-mlogloss:2.80333\n",
            "[24]\tvalidation_0-mlogloss:2.82406\n",
            "[25]\tvalidation_0-mlogloss:2.85814\n",
            "[26]\tvalidation_0-mlogloss:2.87945\n",
            "[27]\tvalidation_0-mlogloss:2.90423\n",
            "[28]\tvalidation_0-mlogloss:2.93005\n",
            "[29]\tvalidation_0-mlogloss:2.95390\n",
            "[30]\tvalidation_0-mlogloss:2.99149\n",
            "[31]\tvalidation_0-mlogloss:3.01645\n",
            "[32]\tvalidation_0-mlogloss:3.04095\n",
            "[33]\tvalidation_0-mlogloss:3.07961\n",
            "[34]\tvalidation_0-mlogloss:3.10353\n",
            "[35]\tvalidation_0-mlogloss:3.13792\n",
            "[36]\tvalidation_0-mlogloss:3.17393\n",
            "[37]\tvalidation_0-mlogloss:3.20441\n",
            "[38]\tvalidation_0-mlogloss:3.24104\n",
            "[39]\tvalidation_0-mlogloss:3.27930\n",
            "[40]\tvalidation_0-mlogloss:3.29757\n",
            "[41]\tvalidation_0-mlogloss:3.34050\n",
            "[42]\tvalidation_0-mlogloss:3.36518\n",
            "[43]\tvalidation_0-mlogloss:3.39937\n",
            "[44]\tvalidation_0-mlogloss:3.43651\n",
            "[45]\tvalidation_0-mlogloss:3.46170\n",
            "[46]\tvalidation_0-mlogloss:3.49391\n",
            "[47]\tvalidation_0-mlogloss:3.52607\n",
            "[48]\tvalidation_0-mlogloss:3.54960\n",
            "[49]\tvalidation_0-mlogloss:3.58506\n",
            "[50]\tvalidation_0-mlogloss:3.61037\n",
            "[51]\tvalidation_0-mlogloss:3.63458\n",
            "[52]\tvalidation_0-mlogloss:3.66134\n",
            "[53]\tvalidation_0-mlogloss:3.68652\n",
            "[54]\tvalidation_0-mlogloss:3.70703\n",
            "[55]\tvalidation_0-mlogloss:3.73192\n",
            "[56]\tvalidation_0-mlogloss:3.74601\n",
            "[57]\tvalidation_0-mlogloss:3.76777\n",
            "[58]\tvalidation_0-mlogloss:3.78801\n",
            "[59]\tvalidation_0-mlogloss:3.80180\n",
            "[60]\tvalidation_0-mlogloss:3.82698\n",
            "[61]\tvalidation_0-mlogloss:3.84363\n",
            "[62]\tvalidation_0-mlogloss:3.86906\n",
            "[63]\tvalidation_0-mlogloss:3.88112\n",
            "[64]\tvalidation_0-mlogloss:3.89738\n",
            "[65]\tvalidation_0-mlogloss:3.91191\n",
            "[66]\tvalidation_0-mlogloss:3.92267\n",
            "[67]\tvalidation_0-mlogloss:3.93776\n",
            "[68]\tvalidation_0-mlogloss:3.94287\n",
            "[69]\tvalidation_0-mlogloss:3.95481\n",
            "[70]\tvalidation_0-mlogloss:3.97261\n",
            "[71]\tvalidation_0-mlogloss:3.98281\n",
            "[72]\tvalidation_0-mlogloss:3.99463\n",
            "[73]\tvalidation_0-mlogloss:4.00876\n",
            "[74]\tvalidation_0-mlogloss:4.01942\n",
            "[75]\tvalidation_0-mlogloss:4.01878\n",
            "[76]\tvalidation_0-mlogloss:4.01802\n",
            "[77]\tvalidation_0-mlogloss:3.98505\n",
            "[78]\tvalidation_0-mlogloss:3.95249\n",
            "[79]\tvalidation_0-mlogloss:3.94269\n",
            "[80]\tvalidation_0-mlogloss:3.92062\n",
            "[81]\tvalidation_0-mlogloss:3.91605\n",
            "[82]\tvalidation_0-mlogloss:3.89058\n",
            "[83]\tvalidation_0-mlogloss:3.86585\n",
            "[84]\tvalidation_0-mlogloss:3.85610\n",
            "[85]\tvalidation_0-mlogloss:3.83418\n",
            "[86]\tvalidation_0-mlogloss:3.82768\n",
            "[87]\tvalidation_0-mlogloss:3.82589\n",
            "[88]\tvalidation_0-mlogloss:3.81828\n",
            "[89]\tvalidation_0-mlogloss:3.79271\n",
            "[90]\tvalidation_0-mlogloss:3.78504\n",
            "[91]\tvalidation_0-mlogloss:3.78267\n",
            "[92]\tvalidation_0-mlogloss:3.75539\n",
            "[93]\tvalidation_0-mlogloss:3.75952\n",
            "[94]\tvalidation_0-mlogloss:3.75905\n",
            "[95]\tvalidation_0-mlogloss:3.72987\n",
            "[96]\tvalidation_0-mlogloss:3.70384\n",
            "[97]\tvalidation_0-mlogloss:3.68744\n",
            "[98]\tvalidation_0-mlogloss:3.68550\n",
            "[99]\tvalidation_0-mlogloss:3.66779\n",
            "[0]\tvalidation_0-mlogloss:2.22530\n",
            "[1]\tvalidation_0-mlogloss:2.25282\n",
            "[2]\tvalidation_0-mlogloss:2.29273\n",
            "[3]\tvalidation_0-mlogloss:2.32045\n",
            "[4]\tvalidation_0-mlogloss:2.35254\n",
            "[5]\tvalidation_0-mlogloss:2.37743\n",
            "[6]\tvalidation_0-mlogloss:2.40588\n",
            "[7]\tvalidation_0-mlogloss:2.43463\n",
            "[8]\tvalidation_0-mlogloss:2.44569\n",
            "[9]\tvalidation_0-mlogloss:2.45710\n",
            "[10]\tvalidation_0-mlogloss:2.47071\n",
            "[11]\tvalidation_0-mlogloss:2.48588\n",
            "[12]\tvalidation_0-mlogloss:2.50289\n",
            "[13]\tvalidation_0-mlogloss:2.52612\n",
            "[14]\tvalidation_0-mlogloss:2.54856\n",
            "[15]\tvalidation_0-mlogloss:2.57403\n",
            "[16]\tvalidation_0-mlogloss:2.59905\n",
            "[17]\tvalidation_0-mlogloss:2.62185\n",
            "[18]\tvalidation_0-mlogloss:2.64248\n",
            "[19]\tvalidation_0-mlogloss:2.66625\n",
            "[20]\tvalidation_0-mlogloss:2.68693\n",
            "[21]\tvalidation_0-mlogloss:2.71145\n",
            "[22]\tvalidation_0-mlogloss:2.74052\n",
            "[23]\tvalidation_0-mlogloss:2.77153\n",
            "[24]\tvalidation_0-mlogloss:2.80373\n",
            "[25]\tvalidation_0-mlogloss:2.83205\n",
            "[26]\tvalidation_0-mlogloss:2.85360\n",
            "[27]\tvalidation_0-mlogloss:2.86811\n",
            "[28]\tvalidation_0-mlogloss:2.88199\n",
            "[29]\tvalidation_0-mlogloss:2.89577\n",
            "[30]\tvalidation_0-mlogloss:2.91144\n",
            "[31]\tvalidation_0-mlogloss:2.92515\n",
            "[32]\tvalidation_0-mlogloss:2.93737\n",
            "[33]\tvalidation_0-mlogloss:2.95829\n",
            "[34]\tvalidation_0-mlogloss:2.97115\n",
            "[35]\tvalidation_0-mlogloss:2.99490\n",
            "[36]\tvalidation_0-mlogloss:3.01582\n",
            "[37]\tvalidation_0-mlogloss:3.03174\n",
            "[38]\tvalidation_0-mlogloss:3.05307\n",
            "[39]\tvalidation_0-mlogloss:3.06783\n",
            "[40]\tvalidation_0-mlogloss:3.09580\n",
            "[41]\tvalidation_0-mlogloss:3.11210\n",
            "[42]\tvalidation_0-mlogloss:3.13654\n",
            "[43]\tvalidation_0-mlogloss:3.16175\n",
            "[44]\tvalidation_0-mlogloss:3.18523\n",
            "[45]\tvalidation_0-mlogloss:3.20125\n",
            "[46]\tvalidation_0-mlogloss:3.21732\n",
            "[47]\tvalidation_0-mlogloss:3.24679\n",
            "[48]\tvalidation_0-mlogloss:3.26657\n",
            "[49]\tvalidation_0-mlogloss:3.28055\n",
            "[50]\tvalidation_0-mlogloss:3.30766\n",
            "[51]\tvalidation_0-mlogloss:3.31375\n",
            "[52]\tvalidation_0-mlogloss:3.32144\n",
            "[53]\tvalidation_0-mlogloss:3.32860\n",
            "[54]\tvalidation_0-mlogloss:3.33727\n",
            "[55]\tvalidation_0-mlogloss:3.34811\n",
            "[56]\tvalidation_0-mlogloss:3.35288\n",
            "[57]\tvalidation_0-mlogloss:3.36312\n",
            "[58]\tvalidation_0-mlogloss:3.36536\n",
            "[59]\tvalidation_0-mlogloss:3.37273\n",
            "[60]\tvalidation_0-mlogloss:3.37534\n",
            "[61]\tvalidation_0-mlogloss:3.38392\n",
            "[62]\tvalidation_0-mlogloss:3.39357\n",
            "[63]\tvalidation_0-mlogloss:3.39377\n",
            "[64]\tvalidation_0-mlogloss:3.40911\n",
            "[65]\tvalidation_0-mlogloss:3.40627\n",
            "[66]\tvalidation_0-mlogloss:3.41382\n",
            "[67]\tvalidation_0-mlogloss:3.40667\n",
            "[68]\tvalidation_0-mlogloss:3.41492\n",
            "[69]\tvalidation_0-mlogloss:3.40555\n",
            "[70]\tvalidation_0-mlogloss:3.40891\n",
            "[71]\tvalidation_0-mlogloss:3.40782\n",
            "[72]\tvalidation_0-mlogloss:3.41271\n",
            "[73]\tvalidation_0-mlogloss:3.40431\n",
            "[74]\tvalidation_0-mlogloss:3.41458\n",
            "[75]\tvalidation_0-mlogloss:3.41075\n",
            "[76]\tvalidation_0-mlogloss:3.40654\n",
            "[77]\tvalidation_0-mlogloss:3.38745\n",
            "[78]\tvalidation_0-mlogloss:3.36615\n",
            "[79]\tvalidation_0-mlogloss:3.35829\n",
            "[80]\tvalidation_0-mlogloss:3.33355\n",
            "[81]\tvalidation_0-mlogloss:3.31085\n",
            "[82]\tvalidation_0-mlogloss:3.29917\n",
            "[83]\tvalidation_0-mlogloss:3.29264\n",
            "[84]\tvalidation_0-mlogloss:3.27995\n",
            "[85]\tvalidation_0-mlogloss:3.26662\n",
            "[86]\tvalidation_0-mlogloss:3.26014\n",
            "[87]\tvalidation_0-mlogloss:3.24267\n",
            "[88]\tvalidation_0-mlogloss:3.24568\n",
            "[89]\tvalidation_0-mlogloss:3.24000\n",
            "[90]\tvalidation_0-mlogloss:3.23017\n",
            "[91]\tvalidation_0-mlogloss:3.22528\n",
            "[92]\tvalidation_0-mlogloss:3.22693\n",
            "[93]\tvalidation_0-mlogloss:3.22181\n",
            "[94]\tvalidation_0-mlogloss:3.21036\n",
            "[95]\tvalidation_0-mlogloss:3.20971\n",
            "[96]\tvalidation_0-mlogloss:3.19446\n",
            "[97]\tvalidation_0-mlogloss:3.19297\n",
            "[98]\tvalidation_0-mlogloss:3.17224\n",
            "[99]\tvalidation_0-mlogloss:3.16826\n",
            "[0]\tvalidation_0-mlogloss:2.22372\n",
            "[1]\tvalidation_0-mlogloss:2.21655\n",
            "[2]\tvalidation_0-mlogloss:2.21769\n",
            "[3]\tvalidation_0-mlogloss:2.22188\n",
            "[4]\tvalidation_0-mlogloss:2.23013\n",
            "[5]\tvalidation_0-mlogloss:2.24260\n",
            "[6]\tvalidation_0-mlogloss:2.25814\n",
            "[7]\tvalidation_0-mlogloss:2.27313\n",
            "[8]\tvalidation_0-mlogloss:2.29469\n",
            "[9]\tvalidation_0-mlogloss:2.31568\n",
            "[10]\tvalidation_0-mlogloss:2.33740\n",
            "[11]\tvalidation_0-mlogloss:2.35964\n",
            "[12]\tvalidation_0-mlogloss:2.38036\n",
            "[13]\tvalidation_0-mlogloss:2.40477\n",
            "[14]\tvalidation_0-mlogloss:2.42825\n",
            "[15]\tvalidation_0-mlogloss:2.45416\n",
            "[16]\tvalidation_0-mlogloss:2.47929\n",
            "[17]\tvalidation_0-mlogloss:2.50597\n",
            "[18]\tvalidation_0-mlogloss:2.53457\n",
            "[19]\tvalidation_0-mlogloss:2.56354\n",
            "[20]\tvalidation_0-mlogloss:2.59447\n",
            "[21]\tvalidation_0-mlogloss:2.62735\n",
            "[22]\tvalidation_0-mlogloss:2.64449\n",
            "[23]\tvalidation_0-mlogloss:2.66761\n",
            "[24]\tvalidation_0-mlogloss:2.70280\n",
            "[25]\tvalidation_0-mlogloss:2.72775\n",
            "[26]\tvalidation_0-mlogloss:2.75277\n",
            "[27]\tvalidation_0-mlogloss:2.77937\n",
            "[28]\tvalidation_0-mlogloss:2.82047\n",
            "[29]\tvalidation_0-mlogloss:2.84926\n",
            "[30]\tvalidation_0-mlogloss:2.87461\n",
            "[31]\tvalidation_0-mlogloss:2.90142\n",
            "[32]\tvalidation_0-mlogloss:2.92710\n",
            "[33]\tvalidation_0-mlogloss:2.96477\n",
            "[34]\tvalidation_0-mlogloss:2.98286\n",
            "[35]\tvalidation_0-mlogloss:3.01891\n",
            "[36]\tvalidation_0-mlogloss:3.05862\n",
            "[37]\tvalidation_0-mlogloss:3.09456\n",
            "[38]\tvalidation_0-mlogloss:3.10895\n",
            "[39]\tvalidation_0-mlogloss:3.14612\n",
            "[40]\tvalidation_0-mlogloss:3.17959\n",
            "[41]\tvalidation_0-mlogloss:3.21394\n",
            "[42]\tvalidation_0-mlogloss:3.24195\n",
            "[43]\tvalidation_0-mlogloss:3.26792\n",
            "[44]\tvalidation_0-mlogloss:3.30429\n",
            "[45]\tvalidation_0-mlogloss:3.32803\n",
            "[46]\tvalidation_0-mlogloss:3.36125\n",
            "[47]\tvalidation_0-mlogloss:3.36946\n",
            "[48]\tvalidation_0-mlogloss:3.41142\n",
            "[49]\tvalidation_0-mlogloss:3.43288\n",
            "[50]\tvalidation_0-mlogloss:3.44656\n",
            "[51]\tvalidation_0-mlogloss:3.47628\n",
            "[52]\tvalidation_0-mlogloss:3.50589\n",
            "[53]\tvalidation_0-mlogloss:3.52907\n",
            "[54]\tvalidation_0-mlogloss:3.55040\n",
            "[55]\tvalidation_0-mlogloss:3.56986\n",
            "[56]\tvalidation_0-mlogloss:3.59832\n",
            "[57]\tvalidation_0-mlogloss:3.61870\n",
            "[58]\tvalidation_0-mlogloss:3.64165\n",
            "[59]\tvalidation_0-mlogloss:3.65453\n",
            "[60]\tvalidation_0-mlogloss:3.68562\n",
            "[61]\tvalidation_0-mlogloss:3.70785\n",
            "[62]\tvalidation_0-mlogloss:3.72365\n",
            "[63]\tvalidation_0-mlogloss:3.73572\n",
            "[64]\tvalidation_0-mlogloss:3.75028\n",
            "[65]\tvalidation_0-mlogloss:3.76925\n",
            "[66]\tvalidation_0-mlogloss:3.77803\n",
            "[67]\tvalidation_0-mlogloss:3.79803\n",
            "[68]\tvalidation_0-mlogloss:3.80124\n",
            "[69]\tvalidation_0-mlogloss:3.82143\n",
            "[70]\tvalidation_0-mlogloss:3.83356\n",
            "[71]\tvalidation_0-mlogloss:3.85445\n",
            "[72]\tvalidation_0-mlogloss:3.86503\n",
            "[73]\tvalidation_0-mlogloss:3.85751\n",
            "[74]\tvalidation_0-mlogloss:3.87727\n",
            "[75]\tvalidation_0-mlogloss:3.89094\n",
            "[76]\tvalidation_0-mlogloss:3.88479\n",
            "[77]\tvalidation_0-mlogloss:3.90527\n",
            "[78]\tvalidation_0-mlogloss:3.88512\n",
            "[79]\tvalidation_0-mlogloss:3.88320\n",
            "[80]\tvalidation_0-mlogloss:3.87679\n",
            "[81]\tvalidation_0-mlogloss:3.87416\n",
            "[82]\tvalidation_0-mlogloss:3.87193\n",
            "[83]\tvalidation_0-mlogloss:3.83750\n",
            "[84]\tvalidation_0-mlogloss:3.81610\n",
            "[85]\tvalidation_0-mlogloss:3.80835\n",
            "[86]\tvalidation_0-mlogloss:3.78422\n",
            "[87]\tvalidation_0-mlogloss:3.75095\n",
            "[88]\tvalidation_0-mlogloss:3.75705\n",
            "[89]\tvalidation_0-mlogloss:3.73787\n",
            "[90]\tvalidation_0-mlogloss:3.71340\n",
            "[91]\tvalidation_0-mlogloss:3.69752\n",
            "[92]\tvalidation_0-mlogloss:3.69185\n",
            "[93]\tvalidation_0-mlogloss:3.68793\n",
            "[94]\tvalidation_0-mlogloss:3.67043\n",
            "[95]\tvalidation_0-mlogloss:3.65824\n",
            "[96]\tvalidation_0-mlogloss:3.64112\n",
            "[97]\tvalidation_0-mlogloss:3.63487\n",
            "[98]\tvalidation_0-mlogloss:3.61623\n",
            "[99]\tvalidation_0-mlogloss:3.60581\n",
            "[0]\tvalidation_0-mlogloss:2.20331\n",
            "[1]\tvalidation_0-mlogloss:2.21425\n",
            "[2]\tvalidation_0-mlogloss:2.22569\n",
            "[3]\tvalidation_0-mlogloss:2.24192\n",
            "[4]\tvalidation_0-mlogloss:2.26395\n",
            "[5]\tvalidation_0-mlogloss:2.29455\n",
            "[6]\tvalidation_0-mlogloss:2.31149\n",
            "[7]\tvalidation_0-mlogloss:2.33552\n",
            "[8]\tvalidation_0-mlogloss:2.36417\n",
            "[9]\tvalidation_0-mlogloss:2.39650\n",
            "[10]\tvalidation_0-mlogloss:2.42987\n",
            "[11]\tvalidation_0-mlogloss:2.45934\n",
            "[12]\tvalidation_0-mlogloss:2.49010\n",
            "[13]\tvalidation_0-mlogloss:2.52425\n",
            "[14]\tvalidation_0-mlogloss:2.56116\n",
            "[15]\tvalidation_0-mlogloss:2.58857\n",
            "[16]\tvalidation_0-mlogloss:2.62275\n",
            "[17]\tvalidation_0-mlogloss:2.65490\n",
            "[18]\tvalidation_0-mlogloss:2.68859\n",
            "[19]\tvalidation_0-mlogloss:2.71927\n",
            "[20]\tvalidation_0-mlogloss:2.75604\n",
            "[21]\tvalidation_0-mlogloss:2.79195\n",
            "[22]\tvalidation_0-mlogloss:2.82679\n",
            "[23]\tvalidation_0-mlogloss:2.86068\n",
            "[24]\tvalidation_0-mlogloss:2.89220\n",
            "[25]\tvalidation_0-mlogloss:2.92776\n",
            "[26]\tvalidation_0-mlogloss:2.96178\n",
            "[27]\tvalidation_0-mlogloss:2.99875\n",
            "[28]\tvalidation_0-mlogloss:3.02985\n",
            "[29]\tvalidation_0-mlogloss:3.05317\n",
            "[30]\tvalidation_0-mlogloss:3.07530\n",
            "[31]\tvalidation_0-mlogloss:3.10137\n",
            "[32]\tvalidation_0-mlogloss:3.12690\n",
            "[33]\tvalidation_0-mlogloss:3.15233\n",
            "[34]\tvalidation_0-mlogloss:3.17234\n",
            "[35]\tvalidation_0-mlogloss:3.20795\n",
            "[36]\tvalidation_0-mlogloss:3.21548\n",
            "[37]\tvalidation_0-mlogloss:3.22345\n",
            "[38]\tvalidation_0-mlogloss:3.25267\n",
            "[39]\tvalidation_0-mlogloss:3.26429\n",
            "[40]\tvalidation_0-mlogloss:3.28487\n",
            "[41]\tvalidation_0-mlogloss:3.30529\n",
            "[42]\tvalidation_0-mlogloss:3.31498\n",
            "[43]\tvalidation_0-mlogloss:3.33564\n",
            "[44]\tvalidation_0-mlogloss:3.36458\n",
            "[45]\tvalidation_0-mlogloss:3.38533\n",
            "[46]\tvalidation_0-mlogloss:3.40492\n",
            "[47]\tvalidation_0-mlogloss:3.42767\n",
            "[48]\tvalidation_0-mlogloss:3.45356\n",
            "[49]\tvalidation_0-mlogloss:3.47908\n",
            "[50]\tvalidation_0-mlogloss:3.50521\n",
            "[51]\tvalidation_0-mlogloss:3.53363\n",
            "[52]\tvalidation_0-mlogloss:3.56441\n",
            "[53]\tvalidation_0-mlogloss:3.58806\n",
            "[54]\tvalidation_0-mlogloss:3.61262\n",
            "[55]\tvalidation_0-mlogloss:3.63607\n",
            "[56]\tvalidation_0-mlogloss:3.66353\n",
            "[57]\tvalidation_0-mlogloss:3.68555\n",
            "[58]\tvalidation_0-mlogloss:3.71660\n",
            "[59]\tvalidation_0-mlogloss:3.73911\n",
            "[60]\tvalidation_0-mlogloss:3.75444\n",
            "[61]\tvalidation_0-mlogloss:3.78225\n",
            "[62]\tvalidation_0-mlogloss:3.79339\n",
            "[63]\tvalidation_0-mlogloss:3.80731\n",
            "[64]\tvalidation_0-mlogloss:3.83315\n",
            "[65]\tvalidation_0-mlogloss:3.84960\n",
            "[66]\tvalidation_0-mlogloss:3.86182\n",
            "[67]\tvalidation_0-mlogloss:3.87318\n",
            "[68]\tvalidation_0-mlogloss:3.87953\n",
            "[69]\tvalidation_0-mlogloss:3.87815\n",
            "[70]\tvalidation_0-mlogloss:3.88941\n",
            "[71]\tvalidation_0-mlogloss:3.89641\n",
            "[72]\tvalidation_0-mlogloss:3.89504\n",
            "[73]\tvalidation_0-mlogloss:3.90713\n",
            "[74]\tvalidation_0-mlogloss:3.91650\n",
            "[75]\tvalidation_0-mlogloss:3.92808\n",
            "[76]\tvalidation_0-mlogloss:3.93542\n",
            "[77]\tvalidation_0-mlogloss:3.94447\n",
            "[78]\tvalidation_0-mlogloss:3.92765\n",
            "[79]\tvalidation_0-mlogloss:3.91503\n",
            "[80]\tvalidation_0-mlogloss:3.91331\n",
            "[81]\tvalidation_0-mlogloss:3.89158\n",
            "[82]\tvalidation_0-mlogloss:3.89217\n",
            "[83]\tvalidation_0-mlogloss:3.86959\n",
            "[84]\tvalidation_0-mlogloss:3.86490\n",
            "[85]\tvalidation_0-mlogloss:3.85145\n",
            "[86]\tvalidation_0-mlogloss:3.84251\n",
            "[87]\tvalidation_0-mlogloss:3.82845\n",
            "[88]\tvalidation_0-mlogloss:3.81264\n",
            "[89]\tvalidation_0-mlogloss:3.79488\n",
            "[90]\tvalidation_0-mlogloss:3.77963\n",
            "[91]\tvalidation_0-mlogloss:3.77047\n",
            "[92]\tvalidation_0-mlogloss:3.75995\n",
            "[93]\tvalidation_0-mlogloss:3.74205\n",
            "[94]\tvalidation_0-mlogloss:3.72353\n",
            "[95]\tvalidation_0-mlogloss:3.71820\n",
            "[96]\tvalidation_0-mlogloss:3.70939\n",
            "[97]\tvalidation_0-mlogloss:3.68449\n",
            "[98]\tvalidation_0-mlogloss:3.68498\n",
            "[99]\tvalidation_0-mlogloss:3.68069\n",
            "[0]\tvalidation_0-mlogloss:2.20114\n",
            "[1]\tvalidation_0-mlogloss:2.19769\n",
            "[2]\tvalidation_0-mlogloss:2.21009\n",
            "[3]\tvalidation_0-mlogloss:2.22711\n",
            "[4]\tvalidation_0-mlogloss:2.24523\n",
            "[5]\tvalidation_0-mlogloss:2.25879\n",
            "[6]\tvalidation_0-mlogloss:2.27846\n",
            "[7]\tvalidation_0-mlogloss:2.29984\n",
            "[8]\tvalidation_0-mlogloss:2.32001\n",
            "[9]\tvalidation_0-mlogloss:2.34101\n",
            "[10]\tvalidation_0-mlogloss:2.36523\n",
            "[11]\tvalidation_0-mlogloss:2.38760\n",
            "[12]\tvalidation_0-mlogloss:2.41511\n",
            "[13]\tvalidation_0-mlogloss:2.44113\n",
            "[14]\tvalidation_0-mlogloss:2.47052\n",
            "[15]\tvalidation_0-mlogloss:2.49822\n",
            "[16]\tvalidation_0-mlogloss:2.52896\n",
            "[17]\tvalidation_0-mlogloss:2.56295\n",
            "[18]\tvalidation_0-mlogloss:2.59908\n",
            "[19]\tvalidation_0-mlogloss:2.62021\n",
            "[20]\tvalidation_0-mlogloss:2.64444\n",
            "[21]\tvalidation_0-mlogloss:2.66777\n",
            "[22]\tvalidation_0-mlogloss:2.69309\n",
            "[23]\tvalidation_0-mlogloss:2.71960\n",
            "[24]\tvalidation_0-mlogloss:2.75888\n",
            "[25]\tvalidation_0-mlogloss:2.78063\n",
            "[26]\tvalidation_0-mlogloss:2.80571\n",
            "[27]\tvalidation_0-mlogloss:2.83160\n",
            "[28]\tvalidation_0-mlogloss:2.83583\n",
            "[29]\tvalidation_0-mlogloss:2.87686\n",
            "[30]\tvalidation_0-mlogloss:2.87925\n",
            "[31]\tvalidation_0-mlogloss:2.90580\n",
            "[32]\tvalidation_0-mlogloss:2.91053\n",
            "[33]\tvalidation_0-mlogloss:2.92894\n",
            "[34]\tvalidation_0-mlogloss:2.96137\n",
            "[35]\tvalidation_0-mlogloss:2.97443\n",
            "[36]\tvalidation_0-mlogloss:2.99871\n",
            "[37]\tvalidation_0-mlogloss:3.03274\n",
            "[38]\tvalidation_0-mlogloss:3.06113\n",
            "[39]\tvalidation_0-mlogloss:3.09871\n",
            "[40]\tvalidation_0-mlogloss:3.12352\n",
            "[41]\tvalidation_0-mlogloss:3.15984\n",
            "[42]\tvalidation_0-mlogloss:3.18555\n",
            "[43]\tvalidation_0-mlogloss:3.22270\n",
            "[44]\tvalidation_0-mlogloss:3.26095\n",
            "[45]\tvalidation_0-mlogloss:3.29692\n",
            "[46]\tvalidation_0-mlogloss:3.32234\n",
            "[47]\tvalidation_0-mlogloss:3.35704\n",
            "[48]\tvalidation_0-mlogloss:3.38202\n",
            "[49]\tvalidation_0-mlogloss:3.41886\n",
            "[50]\tvalidation_0-mlogloss:3.44902\n",
            "[51]\tvalidation_0-mlogloss:3.47280\n",
            "[52]\tvalidation_0-mlogloss:3.50560\n",
            "[53]\tvalidation_0-mlogloss:3.53270\n",
            "[54]\tvalidation_0-mlogloss:3.55425\n",
            "[55]\tvalidation_0-mlogloss:3.57942\n",
            "[56]\tvalidation_0-mlogloss:3.59500\n",
            "[57]\tvalidation_0-mlogloss:3.62690\n",
            "[58]\tvalidation_0-mlogloss:3.65288\n",
            "[59]\tvalidation_0-mlogloss:3.66405\n",
            "[60]\tvalidation_0-mlogloss:3.68154\n",
            "[61]\tvalidation_0-mlogloss:3.69818\n",
            "[62]\tvalidation_0-mlogloss:3.71267\n",
            "[63]\tvalidation_0-mlogloss:3.72006\n",
            "[64]\tvalidation_0-mlogloss:3.71579\n",
            "[65]\tvalidation_0-mlogloss:3.72133\n",
            "[66]\tvalidation_0-mlogloss:3.72148\n",
            "[67]\tvalidation_0-mlogloss:3.72875\n",
            "[68]\tvalidation_0-mlogloss:3.71539\n",
            "[69]\tvalidation_0-mlogloss:3.71721\n",
            "[70]\tvalidation_0-mlogloss:3.71452\n",
            "[71]\tvalidation_0-mlogloss:3.71361\n",
            "[72]\tvalidation_0-mlogloss:3.70770\n",
            "[73]\tvalidation_0-mlogloss:3.69070\n",
            "[74]\tvalidation_0-mlogloss:3.70167\n",
            "[75]\tvalidation_0-mlogloss:3.69482\n",
            "[76]\tvalidation_0-mlogloss:3.68825\n",
            "[77]\tvalidation_0-mlogloss:3.67737\n",
            "[78]\tvalidation_0-mlogloss:3.68430\n",
            "[79]\tvalidation_0-mlogloss:3.65570\n",
            "[80]\tvalidation_0-mlogloss:3.63987\n",
            "[81]\tvalidation_0-mlogloss:3.60905\n",
            "[82]\tvalidation_0-mlogloss:3.60620\n",
            "[83]\tvalidation_0-mlogloss:3.58305\n",
            "[84]\tvalidation_0-mlogloss:3.56064\n",
            "[85]\tvalidation_0-mlogloss:3.55671\n",
            "[86]\tvalidation_0-mlogloss:3.53338\n",
            "[87]\tvalidation_0-mlogloss:3.52808\n",
            "[88]\tvalidation_0-mlogloss:3.50733\n",
            "[89]\tvalidation_0-mlogloss:3.49351\n",
            "[90]\tvalidation_0-mlogloss:3.48032\n",
            "[91]\tvalidation_0-mlogloss:3.46215\n",
            "[92]\tvalidation_0-mlogloss:3.44075\n",
            "[93]\tvalidation_0-mlogloss:3.42587\n",
            "[94]\tvalidation_0-mlogloss:3.40551\n",
            "[95]\tvalidation_0-mlogloss:3.38963\n",
            "[96]\tvalidation_0-mlogloss:3.37561\n",
            "[97]\tvalidation_0-mlogloss:3.35528\n",
            "[98]\tvalidation_0-mlogloss:3.34812\n",
            "[99]\tvalidation_0-mlogloss:3.33974\n",
            "[0]\tvalidation_0-mlogloss:2.20286\n",
            "[1]\tvalidation_0-mlogloss:2.21860\n",
            "[2]\tvalidation_0-mlogloss:2.22497\n",
            "[3]\tvalidation_0-mlogloss:2.24553\n",
            "[4]\tvalidation_0-mlogloss:2.27911\n",
            "[5]\tvalidation_0-mlogloss:2.31867\n",
            "[6]\tvalidation_0-mlogloss:2.35628\n",
            "[7]\tvalidation_0-mlogloss:2.39684\n",
            "[8]\tvalidation_0-mlogloss:2.43982\n",
            "[9]\tvalidation_0-mlogloss:2.47837\n",
            "[10]\tvalidation_0-mlogloss:2.51617\n",
            "[11]\tvalidation_0-mlogloss:2.55696\n",
            "[12]\tvalidation_0-mlogloss:2.59379\n",
            "[13]\tvalidation_0-mlogloss:2.63336\n",
            "[14]\tvalidation_0-mlogloss:2.67190\n",
            "[15]\tvalidation_0-mlogloss:2.71146\n",
            "[16]\tvalidation_0-mlogloss:2.75369\n",
            "[17]\tvalidation_0-mlogloss:2.79476\n",
            "[18]\tvalidation_0-mlogloss:2.83659\n",
            "[19]\tvalidation_0-mlogloss:2.87604\n",
            "[20]\tvalidation_0-mlogloss:2.91672\n",
            "[21]\tvalidation_0-mlogloss:2.95597\n",
            "[22]\tvalidation_0-mlogloss:2.99767\n",
            "[23]\tvalidation_0-mlogloss:3.04029\n",
            "[24]\tvalidation_0-mlogloss:3.08084\n",
            "[25]\tvalidation_0-mlogloss:3.12092\n",
            "[26]\tvalidation_0-mlogloss:3.15770\n",
            "[27]\tvalidation_0-mlogloss:3.19429\n",
            "[28]\tvalidation_0-mlogloss:3.23211\n",
            "[29]\tvalidation_0-mlogloss:3.27055\n",
            "[30]\tvalidation_0-mlogloss:3.30412\n",
            "[31]\tvalidation_0-mlogloss:3.32210\n",
            "[32]\tvalidation_0-mlogloss:3.35571\n",
            "[33]\tvalidation_0-mlogloss:3.37877\n",
            "[34]\tvalidation_0-mlogloss:3.41162\n",
            "[35]\tvalidation_0-mlogloss:3.43304\n",
            "[36]\tvalidation_0-mlogloss:3.45988\n",
            "[37]\tvalidation_0-mlogloss:3.49275\n",
            "[38]\tvalidation_0-mlogloss:3.51611\n",
            "[39]\tvalidation_0-mlogloss:3.54856\n",
            "[40]\tvalidation_0-mlogloss:3.57875\n",
            "[41]\tvalidation_0-mlogloss:3.60157\n",
            "[42]\tvalidation_0-mlogloss:3.64133\n",
            "[43]\tvalidation_0-mlogloss:3.66807\n",
            "[44]\tvalidation_0-mlogloss:3.71056\n",
            "[45]\tvalidation_0-mlogloss:3.75184\n",
            "[46]\tvalidation_0-mlogloss:3.77937\n",
            "[47]\tvalidation_0-mlogloss:3.82004\n",
            "[48]\tvalidation_0-mlogloss:3.84880\n",
            "[49]\tvalidation_0-mlogloss:3.86869\n",
            "[50]\tvalidation_0-mlogloss:3.89801\n",
            "[51]\tvalidation_0-mlogloss:3.92107\n",
            "[52]\tvalidation_0-mlogloss:3.94112\n",
            "[53]\tvalidation_0-mlogloss:3.96900\n",
            "[54]\tvalidation_0-mlogloss:3.98884\n",
            "[55]\tvalidation_0-mlogloss:4.01369\n",
            "[56]\tvalidation_0-mlogloss:4.02832\n",
            "[57]\tvalidation_0-mlogloss:4.04791\n",
            "[58]\tvalidation_0-mlogloss:4.06080\n",
            "[59]\tvalidation_0-mlogloss:4.08729\n",
            "[60]\tvalidation_0-mlogloss:4.10888\n",
            "[61]\tvalidation_0-mlogloss:4.11897\n",
            "[62]\tvalidation_0-mlogloss:4.14052\n",
            "[63]\tvalidation_0-mlogloss:4.14089\n",
            "[64]\tvalidation_0-mlogloss:4.13583\n",
            "[65]\tvalidation_0-mlogloss:4.13168\n",
            "[66]\tvalidation_0-mlogloss:4.13212\n",
            "[67]\tvalidation_0-mlogloss:4.11968\n",
            "[68]\tvalidation_0-mlogloss:4.12399\n",
            "[69]\tvalidation_0-mlogloss:4.11701\n",
            "[70]\tvalidation_0-mlogloss:4.12145\n",
            "[71]\tvalidation_0-mlogloss:4.12341\n",
            "[72]\tvalidation_0-mlogloss:4.12248\n",
            "[73]\tvalidation_0-mlogloss:4.10816\n",
            "[74]\tvalidation_0-mlogloss:4.10898\n",
            "[75]\tvalidation_0-mlogloss:4.09456\n",
            "[76]\tvalidation_0-mlogloss:4.08662\n",
            "[77]\tvalidation_0-mlogloss:4.06866\n",
            "[78]\tvalidation_0-mlogloss:4.05284\n",
            "[79]\tvalidation_0-mlogloss:4.03595\n",
            "[80]\tvalidation_0-mlogloss:4.02002\n",
            "[81]\tvalidation_0-mlogloss:4.00363\n",
            "[82]\tvalidation_0-mlogloss:3.99709\n",
            "[83]\tvalidation_0-mlogloss:3.98016\n",
            "[84]\tvalidation_0-mlogloss:3.96913\n",
            "[85]\tvalidation_0-mlogloss:3.95801\n",
            "[86]\tvalidation_0-mlogloss:3.95071\n",
            "[87]\tvalidation_0-mlogloss:3.94227\n",
            "[88]\tvalidation_0-mlogloss:3.93979\n",
            "[89]\tvalidation_0-mlogloss:3.93072\n",
            "[90]\tvalidation_0-mlogloss:3.93670\n",
            "[91]\tvalidation_0-mlogloss:3.92575\n",
            "[92]\tvalidation_0-mlogloss:3.92147\n",
            "[93]\tvalidation_0-mlogloss:3.92668\n",
            "[94]\tvalidation_0-mlogloss:3.92155\n",
            "[95]\tvalidation_0-mlogloss:3.91100\n",
            "[96]\tvalidation_0-mlogloss:3.90681\n",
            "[97]\tvalidation_0-mlogloss:3.89724\n",
            "[98]\tvalidation_0-mlogloss:3.88867\n",
            "[99]\tvalidation_0-mlogloss:3.88467\n",
            "[0]\tvalidation_0-mlogloss:2.21182\n",
            "[1]\tvalidation_0-mlogloss:2.20848\n",
            "[2]\tvalidation_0-mlogloss:2.21331\n",
            "[3]\tvalidation_0-mlogloss:2.23222\n",
            "[4]\tvalidation_0-mlogloss:2.25334\n",
            "[5]\tvalidation_0-mlogloss:2.28684\n",
            "[6]\tvalidation_0-mlogloss:2.32311\n",
            "[7]\tvalidation_0-mlogloss:2.35469\n",
            "[8]\tvalidation_0-mlogloss:2.38632\n",
            "[9]\tvalidation_0-mlogloss:2.41600\n",
            "[10]\tvalidation_0-mlogloss:2.42194\n",
            "[11]\tvalidation_0-mlogloss:2.44448\n",
            "[12]\tvalidation_0-mlogloss:2.46357\n",
            "[13]\tvalidation_0-mlogloss:2.48475\n",
            "[14]\tvalidation_0-mlogloss:2.50747\n",
            "[15]\tvalidation_0-mlogloss:2.52893\n",
            "[16]\tvalidation_0-mlogloss:2.55072\n",
            "[17]\tvalidation_0-mlogloss:2.57417\n",
            "[18]\tvalidation_0-mlogloss:2.60282\n",
            "[19]\tvalidation_0-mlogloss:2.62310\n",
            "[20]\tvalidation_0-mlogloss:2.64659\n",
            "[21]\tvalidation_0-mlogloss:2.67061\n",
            "[22]\tvalidation_0-mlogloss:2.69460\n",
            "[23]\tvalidation_0-mlogloss:2.72031\n",
            "[24]\tvalidation_0-mlogloss:2.74739\n",
            "[25]\tvalidation_0-mlogloss:2.77421\n",
            "[26]\tvalidation_0-mlogloss:2.80618\n",
            "[27]\tvalidation_0-mlogloss:2.84092\n",
            "[28]\tvalidation_0-mlogloss:2.87464\n",
            "[29]\tvalidation_0-mlogloss:2.90678\n",
            "[30]\tvalidation_0-mlogloss:2.94737\n",
            "[31]\tvalidation_0-mlogloss:2.97361\n",
            "[32]\tvalidation_0-mlogloss:3.00291\n",
            "[33]\tvalidation_0-mlogloss:3.03448\n",
            "[34]\tvalidation_0-mlogloss:3.06183\n",
            "[35]\tvalidation_0-mlogloss:3.08597\n",
            "[36]\tvalidation_0-mlogloss:3.11735\n",
            "[37]\tvalidation_0-mlogloss:3.14797\n",
            "[38]\tvalidation_0-mlogloss:3.17209\n",
            "[39]\tvalidation_0-mlogloss:3.20020\n",
            "[40]\tvalidation_0-mlogloss:3.22833\n",
            "[41]\tvalidation_0-mlogloss:3.24460\n",
            "[42]\tvalidation_0-mlogloss:3.27074\n",
            "[43]\tvalidation_0-mlogloss:3.28882\n",
            "[44]\tvalidation_0-mlogloss:3.32358\n",
            "[45]\tvalidation_0-mlogloss:3.33340\n",
            "[46]\tvalidation_0-mlogloss:3.35438\n",
            "[47]\tvalidation_0-mlogloss:3.36132\n",
            "[48]\tvalidation_0-mlogloss:3.38130\n",
            "[49]\tvalidation_0-mlogloss:3.38726\n",
            "[50]\tvalidation_0-mlogloss:3.40989\n",
            "[51]\tvalidation_0-mlogloss:3.43052\n",
            "[52]\tvalidation_0-mlogloss:3.44545\n",
            "[53]\tvalidation_0-mlogloss:3.46127\n",
            "[54]\tvalidation_0-mlogloss:3.48237\n",
            "[55]\tvalidation_0-mlogloss:3.49654\n",
            "[56]\tvalidation_0-mlogloss:3.50799\n",
            "[57]\tvalidation_0-mlogloss:3.51219\n",
            "[58]\tvalidation_0-mlogloss:3.51512\n",
            "[59]\tvalidation_0-mlogloss:3.52530\n",
            "[60]\tvalidation_0-mlogloss:3.53084\n",
            "[61]\tvalidation_0-mlogloss:3.54083\n",
            "[62]\tvalidation_0-mlogloss:3.55181\n",
            "[63]\tvalidation_0-mlogloss:3.57199\n",
            "[64]\tvalidation_0-mlogloss:3.58886\n",
            "[65]\tvalidation_0-mlogloss:3.58348\n",
            "[66]\tvalidation_0-mlogloss:3.58387\n",
            "[67]\tvalidation_0-mlogloss:3.58048\n",
            "[68]\tvalidation_0-mlogloss:3.58668\n",
            "[69]\tvalidation_0-mlogloss:3.57743\n",
            "[70]\tvalidation_0-mlogloss:3.57612\n",
            "[71]\tvalidation_0-mlogloss:3.56041\n",
            "[72]\tvalidation_0-mlogloss:3.55696\n",
            "[73]\tvalidation_0-mlogloss:3.55495\n",
            "[74]\tvalidation_0-mlogloss:3.55315\n",
            "[75]\tvalidation_0-mlogloss:3.55200\n",
            "[76]\tvalidation_0-mlogloss:3.55437\n",
            "[77]\tvalidation_0-mlogloss:3.55660\n",
            "[78]\tvalidation_0-mlogloss:3.56185\n",
            "[79]\tvalidation_0-mlogloss:3.55436\n",
            "[80]\tvalidation_0-mlogloss:3.56095\n",
            "[81]\tvalidation_0-mlogloss:3.54825\n",
            "[82]\tvalidation_0-mlogloss:3.53215\n",
            "[83]\tvalidation_0-mlogloss:3.53594\n",
            "[84]\tvalidation_0-mlogloss:3.52209\n",
            "[85]\tvalidation_0-mlogloss:3.51568\n",
            "[86]\tvalidation_0-mlogloss:3.50105\n",
            "[87]\tvalidation_0-mlogloss:3.49697\n",
            "[88]\tvalidation_0-mlogloss:3.48840\n",
            "[89]\tvalidation_0-mlogloss:3.48618\n",
            "[90]\tvalidation_0-mlogloss:3.47803\n",
            "[91]\tvalidation_0-mlogloss:3.46268\n",
            "[92]\tvalidation_0-mlogloss:3.46136\n",
            "[93]\tvalidation_0-mlogloss:3.46250\n",
            "[94]\tvalidation_0-mlogloss:3.45848\n",
            "[95]\tvalidation_0-mlogloss:3.45916\n",
            "[96]\tvalidation_0-mlogloss:3.45744\n",
            "[97]\tvalidation_0-mlogloss:3.45500\n",
            "[98]\tvalidation_0-mlogloss:3.44930\n",
            "[99]\tvalidation_0-mlogloss:3.44857\n",
            "[0]\tvalidation_0-mlogloss:2.22326\n",
            "[1]\tvalidation_0-mlogloss:2.24183\n",
            "[2]\tvalidation_0-mlogloss:2.25685\n",
            "[3]\tvalidation_0-mlogloss:2.27335\n",
            "[4]\tvalidation_0-mlogloss:2.28971\n",
            "[5]\tvalidation_0-mlogloss:2.30484\n",
            "[6]\tvalidation_0-mlogloss:2.32458\n",
            "[7]\tvalidation_0-mlogloss:2.34157\n",
            "[8]\tvalidation_0-mlogloss:2.36702\n",
            "[9]\tvalidation_0-mlogloss:2.39284\n",
            "[10]\tvalidation_0-mlogloss:2.42072\n",
            "[11]\tvalidation_0-mlogloss:2.44829\n",
            "[12]\tvalidation_0-mlogloss:2.47304\n",
            "[13]\tvalidation_0-mlogloss:2.49548\n",
            "[14]\tvalidation_0-mlogloss:2.51791\n",
            "[15]\tvalidation_0-mlogloss:2.52796\n",
            "[16]\tvalidation_0-mlogloss:2.54984\n",
            "[17]\tvalidation_0-mlogloss:2.56232\n",
            "[18]\tvalidation_0-mlogloss:2.57288\n",
            "[19]\tvalidation_0-mlogloss:2.60123\n",
            "[20]\tvalidation_0-mlogloss:2.61289\n",
            "[21]\tvalidation_0-mlogloss:2.62535\n",
            "[22]\tvalidation_0-mlogloss:2.64933\n",
            "[23]\tvalidation_0-mlogloss:2.66335\n",
            "[24]\tvalidation_0-mlogloss:2.67420\n",
            "[25]\tvalidation_0-mlogloss:2.68041\n",
            "[26]\tvalidation_0-mlogloss:2.70817\n",
            "[27]\tvalidation_0-mlogloss:2.71973\n",
            "[28]\tvalidation_0-mlogloss:2.73706\n",
            "[29]\tvalidation_0-mlogloss:2.75094\n",
            "[30]\tvalidation_0-mlogloss:2.77625\n",
            "[31]\tvalidation_0-mlogloss:2.79387\n",
            "[32]\tvalidation_0-mlogloss:2.81717\n",
            "[33]\tvalidation_0-mlogloss:2.83835\n",
            "[34]\tvalidation_0-mlogloss:2.84616\n",
            "[35]\tvalidation_0-mlogloss:2.85767\n",
            "[36]\tvalidation_0-mlogloss:2.87912\n",
            "[37]\tvalidation_0-mlogloss:2.89807\n",
            "[38]\tvalidation_0-mlogloss:2.92955\n",
            "[39]\tvalidation_0-mlogloss:2.94493\n",
            "[40]\tvalidation_0-mlogloss:2.96770\n",
            "[41]\tvalidation_0-mlogloss:2.98214\n",
            "[42]\tvalidation_0-mlogloss:2.99700\n",
            "[43]\tvalidation_0-mlogloss:3.01770\n",
            "[44]\tvalidation_0-mlogloss:3.03746\n",
            "[45]\tvalidation_0-mlogloss:3.05212\n",
            "[46]\tvalidation_0-mlogloss:3.07403\n",
            "[47]\tvalidation_0-mlogloss:3.09272\n",
            "[48]\tvalidation_0-mlogloss:3.11349\n",
            "[49]\tvalidation_0-mlogloss:3.13180\n",
            "[50]\tvalidation_0-mlogloss:3.14608\n",
            "[51]\tvalidation_0-mlogloss:3.16535\n",
            "[52]\tvalidation_0-mlogloss:3.18753\n",
            "[53]\tvalidation_0-mlogloss:3.20695\n",
            "[54]\tvalidation_0-mlogloss:3.20996\n",
            "[55]\tvalidation_0-mlogloss:3.22761\n",
            "[56]\tvalidation_0-mlogloss:3.23613\n",
            "[57]\tvalidation_0-mlogloss:3.25552\n",
            "[58]\tvalidation_0-mlogloss:3.25960\n",
            "[59]\tvalidation_0-mlogloss:3.27013\n",
            "[60]\tvalidation_0-mlogloss:3.27803\n",
            "[61]\tvalidation_0-mlogloss:3.29080\n",
            "[62]\tvalidation_0-mlogloss:3.30312\n",
            "[63]\tvalidation_0-mlogloss:3.31684\n",
            "[64]\tvalidation_0-mlogloss:3.33741\n",
            "[65]\tvalidation_0-mlogloss:3.35037\n",
            "[66]\tvalidation_0-mlogloss:3.36280\n",
            "[67]\tvalidation_0-mlogloss:3.36867\n",
            "[68]\tvalidation_0-mlogloss:3.38215\n",
            "[69]\tvalidation_0-mlogloss:3.39362\n",
            "[70]\tvalidation_0-mlogloss:3.39903\n",
            "[71]\tvalidation_0-mlogloss:3.40313\n",
            "[72]\tvalidation_0-mlogloss:3.40849\n",
            "[73]\tvalidation_0-mlogloss:3.42266\n",
            "[74]\tvalidation_0-mlogloss:3.42123\n",
            "[75]\tvalidation_0-mlogloss:3.43509\n",
            "[76]\tvalidation_0-mlogloss:3.44276\n",
            "[77]\tvalidation_0-mlogloss:3.43634\n",
            "[78]\tvalidation_0-mlogloss:3.42346\n",
            "[79]\tvalidation_0-mlogloss:3.41544\n",
            "[80]\tvalidation_0-mlogloss:3.40075\n",
            "[81]\tvalidation_0-mlogloss:3.39214\n",
            "[82]\tvalidation_0-mlogloss:3.38359\n",
            "[83]\tvalidation_0-mlogloss:3.36686\n",
            "[84]\tvalidation_0-mlogloss:3.36202\n",
            "[85]\tvalidation_0-mlogloss:3.35537\n",
            "[86]\tvalidation_0-mlogloss:3.33330\n",
            "[87]\tvalidation_0-mlogloss:3.31410\n",
            "[88]\tvalidation_0-mlogloss:3.29643\n",
            "[89]\tvalidation_0-mlogloss:3.28768\n",
            "[90]\tvalidation_0-mlogloss:3.26465\n",
            "[91]\tvalidation_0-mlogloss:3.25194\n",
            "[92]\tvalidation_0-mlogloss:3.24078\n",
            "[93]\tvalidation_0-mlogloss:3.23292\n",
            "[94]\tvalidation_0-mlogloss:3.21574\n",
            "[95]\tvalidation_0-mlogloss:3.21072\n",
            "[96]\tvalidation_0-mlogloss:3.19655\n",
            "[97]\tvalidation_0-mlogloss:3.18904\n",
            "[98]\tvalidation_0-mlogloss:3.17700\n",
            "[99]\tvalidation_0-mlogloss:3.17131\n",
            "[0]\tvalidation_0-mlogloss:2.20919\n",
            "[1]\tvalidation_0-mlogloss:2.22314\n",
            "[2]\tvalidation_0-mlogloss:2.24560\n",
            "[3]\tvalidation_0-mlogloss:2.27493\n",
            "[4]\tvalidation_0-mlogloss:2.30280\n",
            "[5]\tvalidation_0-mlogloss:2.33221\n",
            "[6]\tvalidation_0-mlogloss:2.35673\n",
            "[7]\tvalidation_0-mlogloss:2.38534\n",
            "[8]\tvalidation_0-mlogloss:2.40429\n",
            "[9]\tvalidation_0-mlogloss:2.42899\n",
            "[10]\tvalidation_0-mlogloss:2.45477\n",
            "[11]\tvalidation_0-mlogloss:2.48752\n",
            "[12]\tvalidation_0-mlogloss:2.51825\n",
            "[13]\tvalidation_0-mlogloss:2.54983\n",
            "[14]\tvalidation_0-mlogloss:2.58368\n",
            "[15]\tvalidation_0-mlogloss:2.61587\n",
            "[16]\tvalidation_0-mlogloss:2.64784\n",
            "[17]\tvalidation_0-mlogloss:2.68687\n",
            "[18]\tvalidation_0-mlogloss:2.71980\n",
            "[19]\tvalidation_0-mlogloss:2.75513\n",
            "[20]\tvalidation_0-mlogloss:2.79094\n",
            "[21]\tvalidation_0-mlogloss:2.82976\n",
            "[22]\tvalidation_0-mlogloss:2.86744\n",
            "[23]\tvalidation_0-mlogloss:2.89044\n",
            "[24]\tvalidation_0-mlogloss:2.91315\n",
            "[25]\tvalidation_0-mlogloss:2.93680\n",
            "[26]\tvalidation_0-mlogloss:2.96332\n",
            "[27]\tvalidation_0-mlogloss:2.98120\n",
            "[28]\tvalidation_0-mlogloss:3.01712\n",
            "[29]\tvalidation_0-mlogloss:3.04251\n",
            "[30]\tvalidation_0-mlogloss:3.06939\n",
            "[31]\tvalidation_0-mlogloss:3.09395\n",
            "[32]\tvalidation_0-mlogloss:3.11969\n",
            "[33]\tvalidation_0-mlogloss:3.14919\n",
            "[34]\tvalidation_0-mlogloss:3.17628\n",
            "[35]\tvalidation_0-mlogloss:3.21265\n",
            "[36]\tvalidation_0-mlogloss:3.23426\n",
            "[37]\tvalidation_0-mlogloss:3.27618\n",
            "[38]\tvalidation_0-mlogloss:3.31759\n",
            "[39]\tvalidation_0-mlogloss:3.34042\n",
            "[40]\tvalidation_0-mlogloss:3.38213\n",
            "[41]\tvalidation_0-mlogloss:3.41492\n",
            "[42]\tvalidation_0-mlogloss:3.45020\n",
            "[43]\tvalidation_0-mlogloss:3.47852\n",
            "[44]\tvalidation_0-mlogloss:3.51320\n",
            "[45]\tvalidation_0-mlogloss:3.54861\n",
            "[46]\tvalidation_0-mlogloss:3.56883\n",
            "[47]\tvalidation_0-mlogloss:3.57629\n",
            "[48]\tvalidation_0-mlogloss:3.59181\n",
            "[49]\tvalidation_0-mlogloss:3.60771\n",
            "[50]\tvalidation_0-mlogloss:3.62237\n",
            "[51]\tvalidation_0-mlogloss:3.64568\n",
            "[52]\tvalidation_0-mlogloss:3.67929\n",
            "[53]\tvalidation_0-mlogloss:3.69088\n",
            "[54]\tvalidation_0-mlogloss:3.71051\n",
            "[55]\tvalidation_0-mlogloss:3.73374\n",
            "[56]\tvalidation_0-mlogloss:3.74668\n",
            "[57]\tvalidation_0-mlogloss:3.76579\n",
            "[58]\tvalidation_0-mlogloss:3.78129\n",
            "[59]\tvalidation_0-mlogloss:3.79487\n",
            "[60]\tvalidation_0-mlogloss:3.79906\n",
            "[61]\tvalidation_0-mlogloss:3.80712\n",
            "[62]\tvalidation_0-mlogloss:3.82235\n",
            "[63]\tvalidation_0-mlogloss:3.84293\n",
            "[64]\tvalidation_0-mlogloss:3.84760\n",
            "[65]\tvalidation_0-mlogloss:3.84341\n",
            "[66]\tvalidation_0-mlogloss:3.86024\n",
            "[67]\tvalidation_0-mlogloss:3.86822\n",
            "[68]\tvalidation_0-mlogloss:3.87670\n",
            "[69]\tvalidation_0-mlogloss:3.88110\n",
            "[70]\tvalidation_0-mlogloss:3.89361\n",
            "[71]\tvalidation_0-mlogloss:3.87815\n",
            "[72]\tvalidation_0-mlogloss:3.85673\n",
            "[73]\tvalidation_0-mlogloss:3.83722\n",
            "[74]\tvalidation_0-mlogloss:3.81837\n",
            "[75]\tvalidation_0-mlogloss:3.82268\n",
            "[76]\tvalidation_0-mlogloss:3.79481\n",
            "[77]\tvalidation_0-mlogloss:3.78691\n",
            "[78]\tvalidation_0-mlogloss:3.76459\n",
            "[79]\tvalidation_0-mlogloss:3.74511\n",
            "[80]\tvalidation_0-mlogloss:3.73136\n",
            "[81]\tvalidation_0-mlogloss:3.71324\n",
            "[82]\tvalidation_0-mlogloss:3.70149\n",
            "[83]\tvalidation_0-mlogloss:3.68338\n",
            "[84]\tvalidation_0-mlogloss:3.66209\n",
            "[85]\tvalidation_0-mlogloss:3.63856\n",
            "[86]\tvalidation_0-mlogloss:3.61251\n",
            "[87]\tvalidation_0-mlogloss:3.58432\n",
            "[88]\tvalidation_0-mlogloss:3.57599\n",
            "[89]\tvalidation_0-mlogloss:3.55240\n",
            "[90]\tvalidation_0-mlogloss:3.52935\n",
            "[91]\tvalidation_0-mlogloss:3.50328\n",
            "[92]\tvalidation_0-mlogloss:3.48990\n",
            "[93]\tvalidation_0-mlogloss:3.47125\n",
            "[94]\tvalidation_0-mlogloss:3.44989\n",
            "[95]\tvalidation_0-mlogloss:3.43532\n",
            "[96]\tvalidation_0-mlogloss:3.42209\n",
            "[97]\tvalidation_0-mlogloss:3.40299\n",
            "[98]\tvalidation_0-mlogloss:3.38967\n",
            "[99]\tvalidation_0-mlogloss:3.37467\n",
            "[0]\tvalidation_0-mlogloss:2.21107\n",
            "[1]\tvalidation_0-mlogloss:2.21744\n",
            "[2]\tvalidation_0-mlogloss:2.23575\n",
            "[3]\tvalidation_0-mlogloss:2.25417\n",
            "[4]\tvalidation_0-mlogloss:2.27673\n",
            "[5]\tvalidation_0-mlogloss:2.29947\n",
            "[6]\tvalidation_0-mlogloss:2.32604\n",
            "[7]\tvalidation_0-mlogloss:2.35890\n",
            "[8]\tvalidation_0-mlogloss:2.38549\n",
            "[9]\tvalidation_0-mlogloss:2.41350\n",
            "[10]\tvalidation_0-mlogloss:2.44273\n",
            "[11]\tvalidation_0-mlogloss:2.47355\n",
            "[12]\tvalidation_0-mlogloss:2.51114\n",
            "[13]\tvalidation_0-mlogloss:2.54714\n",
            "[14]\tvalidation_0-mlogloss:2.58849\n",
            "[15]\tvalidation_0-mlogloss:2.62398\n",
            "[16]\tvalidation_0-mlogloss:2.66146\n",
            "[17]\tvalidation_0-mlogloss:2.69382\n",
            "[18]\tvalidation_0-mlogloss:2.73551\n",
            "[19]\tvalidation_0-mlogloss:2.77068\n",
            "[20]\tvalidation_0-mlogloss:2.80412\n",
            "[21]\tvalidation_0-mlogloss:2.84041\n",
            "[22]\tvalidation_0-mlogloss:2.87280\n",
            "[23]\tvalidation_0-mlogloss:2.90866\n",
            "[24]\tvalidation_0-mlogloss:2.93050\n",
            "[25]\tvalidation_0-mlogloss:2.96617\n",
            "[26]\tvalidation_0-mlogloss:2.98405\n",
            "[27]\tvalidation_0-mlogloss:3.00683\n",
            "[28]\tvalidation_0-mlogloss:3.02897\n",
            "[29]\tvalidation_0-mlogloss:3.05309\n",
            "[30]\tvalidation_0-mlogloss:3.06461\n",
            "[31]\tvalidation_0-mlogloss:3.07531\n",
            "[32]\tvalidation_0-mlogloss:3.08820\n",
            "[33]\tvalidation_0-mlogloss:3.10285\n",
            "[34]\tvalidation_0-mlogloss:3.13360\n",
            "[35]\tvalidation_0-mlogloss:3.15043\n",
            "[36]\tvalidation_0-mlogloss:3.17807\n",
            "[37]\tvalidation_0-mlogloss:3.20669\n",
            "[38]\tvalidation_0-mlogloss:3.23338\n",
            "[39]\tvalidation_0-mlogloss:3.24830\n",
            "[40]\tvalidation_0-mlogloss:3.26693\n",
            "[41]\tvalidation_0-mlogloss:3.29988\n",
            "[42]\tvalidation_0-mlogloss:3.32348\n",
            "[43]\tvalidation_0-mlogloss:3.34551\n",
            "[44]\tvalidation_0-mlogloss:3.37778\n",
            "[45]\tvalidation_0-mlogloss:3.39905\n",
            "[46]\tvalidation_0-mlogloss:3.42274\n",
            "[47]\tvalidation_0-mlogloss:3.43874\n",
            "[48]\tvalidation_0-mlogloss:3.46379\n",
            "[49]\tvalidation_0-mlogloss:3.49178\n",
            "[50]\tvalidation_0-mlogloss:3.51475\n",
            "[51]\tvalidation_0-mlogloss:3.53979\n",
            "[52]\tvalidation_0-mlogloss:3.55473\n",
            "[53]\tvalidation_0-mlogloss:3.58941\n",
            "[54]\tvalidation_0-mlogloss:3.61051\n",
            "[55]\tvalidation_0-mlogloss:3.61470\n",
            "[56]\tvalidation_0-mlogloss:3.64425\n",
            "[57]\tvalidation_0-mlogloss:3.66034\n",
            "[58]\tvalidation_0-mlogloss:3.68363\n",
            "[59]\tvalidation_0-mlogloss:3.68873\n",
            "[60]\tvalidation_0-mlogloss:3.70625\n",
            "[61]\tvalidation_0-mlogloss:3.71874\n",
            "[62]\tvalidation_0-mlogloss:3.73925\n",
            "[63]\tvalidation_0-mlogloss:3.74826\n",
            "[64]\tvalidation_0-mlogloss:3.75837\n",
            "[65]\tvalidation_0-mlogloss:3.76635\n",
            "[66]\tvalidation_0-mlogloss:3.78256\n",
            "[67]\tvalidation_0-mlogloss:3.78691\n",
            "[68]\tvalidation_0-mlogloss:3.80294\n",
            "[69]\tvalidation_0-mlogloss:3.80231\n",
            "[70]\tvalidation_0-mlogloss:3.81498\n",
            "[71]\tvalidation_0-mlogloss:3.82913\n",
            "[72]\tvalidation_0-mlogloss:3.84005\n",
            "[73]\tvalidation_0-mlogloss:3.84952\n",
            "[74]\tvalidation_0-mlogloss:3.86201\n",
            "[75]\tvalidation_0-mlogloss:3.86945\n",
            "[76]\tvalidation_0-mlogloss:3.87933\n",
            "[77]\tvalidation_0-mlogloss:3.88511\n",
            "[78]\tvalidation_0-mlogloss:3.89012\n",
            "[79]\tvalidation_0-mlogloss:3.88501\n",
            "[80]\tvalidation_0-mlogloss:3.90163\n",
            "[81]\tvalidation_0-mlogloss:3.90253\n",
            "[82]\tvalidation_0-mlogloss:3.86551\n",
            "[83]\tvalidation_0-mlogloss:3.84425\n",
            "[84]\tvalidation_0-mlogloss:3.81495\n",
            "[85]\tvalidation_0-mlogloss:3.78953\n",
            "[86]\tvalidation_0-mlogloss:3.76134\n",
            "[87]\tvalidation_0-mlogloss:3.73304\n",
            "[88]\tvalidation_0-mlogloss:3.69902\n",
            "[89]\tvalidation_0-mlogloss:3.67857\n",
            "[90]\tvalidation_0-mlogloss:3.64797\n",
            "[91]\tvalidation_0-mlogloss:3.62868\n",
            "[92]\tvalidation_0-mlogloss:3.60670\n",
            "[93]\tvalidation_0-mlogloss:3.58183\n",
            "[94]\tvalidation_0-mlogloss:3.55909\n",
            "[95]\tvalidation_0-mlogloss:3.54008\n",
            "[96]\tvalidation_0-mlogloss:3.51750\n",
            "[97]\tvalidation_0-mlogloss:3.49835\n",
            "[98]\tvalidation_0-mlogloss:3.48109\n",
            "[99]\tvalidation_0-mlogloss:3.45775\n",
            "[0]\tvalidation_0-mlogloss:2.22054\n",
            "[1]\tvalidation_0-mlogloss:2.25956\n",
            "[2]\tvalidation_0-mlogloss:2.29262\n",
            "[3]\tvalidation_0-mlogloss:2.29834\n",
            "[4]\tvalidation_0-mlogloss:2.30735\n",
            "[5]\tvalidation_0-mlogloss:2.33245\n",
            "[6]\tvalidation_0-mlogloss:2.35620\n",
            "[7]\tvalidation_0-mlogloss:2.38091\n",
            "[8]\tvalidation_0-mlogloss:2.40703\n",
            "[9]\tvalidation_0-mlogloss:2.43074\n",
            "[10]\tvalidation_0-mlogloss:2.45371\n",
            "[11]\tvalidation_0-mlogloss:2.48285\n",
            "[12]\tvalidation_0-mlogloss:2.51321\n",
            "[13]\tvalidation_0-mlogloss:2.54486\n",
            "[14]\tvalidation_0-mlogloss:2.57752\n",
            "[15]\tvalidation_0-mlogloss:2.61059\n",
            "[16]\tvalidation_0-mlogloss:2.64221\n",
            "[17]\tvalidation_0-mlogloss:2.67814\n",
            "[18]\tvalidation_0-mlogloss:2.71426\n",
            "[19]\tvalidation_0-mlogloss:2.75135\n",
            "[20]\tvalidation_0-mlogloss:2.78981\n",
            "[21]\tvalidation_0-mlogloss:2.83002\n",
            "[22]\tvalidation_0-mlogloss:2.86986\n",
            "[23]\tvalidation_0-mlogloss:2.91072\n",
            "[24]\tvalidation_0-mlogloss:2.95202\n",
            "[25]\tvalidation_0-mlogloss:2.99563\n",
            "[26]\tvalidation_0-mlogloss:3.03634\n",
            "[27]\tvalidation_0-mlogloss:3.08234\n",
            "[28]\tvalidation_0-mlogloss:3.11348\n",
            "[29]\tvalidation_0-mlogloss:3.14452\n",
            "[30]\tvalidation_0-mlogloss:3.16961\n",
            "[31]\tvalidation_0-mlogloss:3.20133\n",
            "[32]\tvalidation_0-mlogloss:3.23119\n",
            "[33]\tvalidation_0-mlogloss:3.26313\n",
            "[34]\tvalidation_0-mlogloss:3.28962\n",
            "[35]\tvalidation_0-mlogloss:3.31763\n",
            "[36]\tvalidation_0-mlogloss:3.34650\n",
            "[37]\tvalidation_0-mlogloss:3.37569\n",
            "[38]\tvalidation_0-mlogloss:3.41483\n",
            "[39]\tvalidation_0-mlogloss:3.44358\n",
            "[40]\tvalidation_0-mlogloss:3.48365\n",
            "[41]\tvalidation_0-mlogloss:3.51498\n",
            "[42]\tvalidation_0-mlogloss:3.54329\n",
            "[43]\tvalidation_0-mlogloss:3.56714\n",
            "[44]\tvalidation_0-mlogloss:3.59371\n",
            "[45]\tvalidation_0-mlogloss:3.61944\n",
            "[46]\tvalidation_0-mlogloss:3.64123\n",
            "[47]\tvalidation_0-mlogloss:3.66062\n",
            "[48]\tvalidation_0-mlogloss:3.67811\n",
            "[49]\tvalidation_0-mlogloss:3.69498\n",
            "[50]\tvalidation_0-mlogloss:3.70946\n",
            "[51]\tvalidation_0-mlogloss:3.72968\n",
            "[52]\tvalidation_0-mlogloss:3.74635\n",
            "[53]\tvalidation_0-mlogloss:3.77332\n",
            "[54]\tvalidation_0-mlogloss:3.79881\n",
            "[55]\tvalidation_0-mlogloss:3.82208\n",
            "[56]\tvalidation_0-mlogloss:3.84765\n",
            "[57]\tvalidation_0-mlogloss:3.87020\n",
            "[58]\tvalidation_0-mlogloss:3.89602\n",
            "[59]\tvalidation_0-mlogloss:3.91687\n",
            "[60]\tvalidation_0-mlogloss:3.93420\n",
            "[61]\tvalidation_0-mlogloss:3.95674\n",
            "[62]\tvalidation_0-mlogloss:3.97389\n",
            "[63]\tvalidation_0-mlogloss:4.00459\n",
            "[64]\tvalidation_0-mlogloss:4.01692\n",
            "[65]\tvalidation_0-mlogloss:4.03516\n",
            "[66]\tvalidation_0-mlogloss:4.05315\n",
            "[67]\tvalidation_0-mlogloss:4.07025\n",
            "[68]\tvalidation_0-mlogloss:4.08652\n",
            "[69]\tvalidation_0-mlogloss:4.10270\n",
            "[70]\tvalidation_0-mlogloss:4.11773\n",
            "[71]\tvalidation_0-mlogloss:4.13970\n",
            "[72]\tvalidation_0-mlogloss:4.15270\n",
            "[73]\tvalidation_0-mlogloss:4.17590\n",
            "[74]\tvalidation_0-mlogloss:4.16203\n",
            "[75]\tvalidation_0-mlogloss:4.15324\n",
            "[76]\tvalidation_0-mlogloss:4.14489\n",
            "[77]\tvalidation_0-mlogloss:4.15811\n",
            "[78]\tvalidation_0-mlogloss:4.14975\n",
            "[79]\tvalidation_0-mlogloss:4.14273\n",
            "[80]\tvalidation_0-mlogloss:4.12649\n",
            "[81]\tvalidation_0-mlogloss:4.10827\n",
            "[82]\tvalidation_0-mlogloss:4.10101\n",
            "[83]\tvalidation_0-mlogloss:4.08000\n",
            "[84]\tvalidation_0-mlogloss:4.06436\n",
            "[85]\tvalidation_0-mlogloss:4.04407\n",
            "[86]\tvalidation_0-mlogloss:4.03024\n",
            "[87]\tvalidation_0-mlogloss:4.01209\n",
            "[88]\tvalidation_0-mlogloss:3.99824\n",
            "[89]\tvalidation_0-mlogloss:3.97900\n",
            "[90]\tvalidation_0-mlogloss:3.96538\n",
            "[91]\tvalidation_0-mlogloss:3.95347\n",
            "[92]\tvalidation_0-mlogloss:3.93235\n",
            "[93]\tvalidation_0-mlogloss:3.90592\n",
            "[94]\tvalidation_0-mlogloss:3.88601\n",
            "[95]\tvalidation_0-mlogloss:3.86861\n",
            "[96]\tvalidation_0-mlogloss:3.85022\n",
            "[97]\tvalidation_0-mlogloss:3.83687\n",
            "[98]\tvalidation_0-mlogloss:3.81795\n",
            "[99]\tvalidation_0-mlogloss:3.80587\n",
            "[0]\tvalidation_0-mlogloss:2.21794\n",
            "[1]\tvalidation_0-mlogloss:2.23356\n",
            "[2]\tvalidation_0-mlogloss:2.25929\n",
            "[3]\tvalidation_0-mlogloss:2.27150\n",
            "[4]\tvalidation_0-mlogloss:2.29302\n",
            "[5]\tvalidation_0-mlogloss:2.30964\n",
            "[6]\tvalidation_0-mlogloss:2.32292\n",
            "[7]\tvalidation_0-mlogloss:2.34554\n",
            "[8]\tvalidation_0-mlogloss:2.36714\n",
            "[9]\tvalidation_0-mlogloss:2.39447\n",
            "[10]\tvalidation_0-mlogloss:2.41546\n",
            "[11]\tvalidation_0-mlogloss:2.43878\n",
            "[12]\tvalidation_0-mlogloss:2.46372\n",
            "[13]\tvalidation_0-mlogloss:2.49091\n",
            "[14]\tvalidation_0-mlogloss:2.51663\n",
            "[15]\tvalidation_0-mlogloss:2.54365\n",
            "[16]\tvalidation_0-mlogloss:2.57030\n",
            "[17]\tvalidation_0-mlogloss:2.60043\n",
            "[18]\tvalidation_0-mlogloss:2.62747\n",
            "[19]\tvalidation_0-mlogloss:2.65717\n",
            "[20]\tvalidation_0-mlogloss:2.68744\n",
            "[21]\tvalidation_0-mlogloss:2.71885\n",
            "[22]\tvalidation_0-mlogloss:2.74908\n",
            "[23]\tvalidation_0-mlogloss:2.78152\n",
            "[24]\tvalidation_0-mlogloss:2.81504\n",
            "[25]\tvalidation_0-mlogloss:2.84292\n",
            "[26]\tvalidation_0-mlogloss:2.87007\n",
            "[27]\tvalidation_0-mlogloss:2.89909\n",
            "[28]\tvalidation_0-mlogloss:2.91710\n",
            "[29]\tvalidation_0-mlogloss:2.93387\n",
            "[30]\tvalidation_0-mlogloss:2.95282\n",
            "[31]\tvalidation_0-mlogloss:2.97137\n",
            "[32]\tvalidation_0-mlogloss:3.00431\n",
            "[33]\tvalidation_0-mlogloss:3.02712\n",
            "[34]\tvalidation_0-mlogloss:3.04669\n",
            "[35]\tvalidation_0-mlogloss:3.07147\n",
            "[36]\tvalidation_0-mlogloss:3.09416\n",
            "[37]\tvalidation_0-mlogloss:3.13084\n",
            "[38]\tvalidation_0-mlogloss:3.15511\n",
            "[39]\tvalidation_0-mlogloss:3.18144\n",
            "[40]\tvalidation_0-mlogloss:3.20838\n",
            "[41]\tvalidation_0-mlogloss:3.23058\n",
            "[42]\tvalidation_0-mlogloss:3.25398\n",
            "[43]\tvalidation_0-mlogloss:3.28409\n",
            "[44]\tvalidation_0-mlogloss:3.30564\n",
            "[45]\tvalidation_0-mlogloss:3.33676\n",
            "[46]\tvalidation_0-mlogloss:3.36847\n",
            "[47]\tvalidation_0-mlogloss:3.38787\n",
            "[48]\tvalidation_0-mlogloss:3.42010\n",
            "[49]\tvalidation_0-mlogloss:3.44528\n",
            "[50]\tvalidation_0-mlogloss:3.47837\n",
            "[51]\tvalidation_0-mlogloss:3.50874\n",
            "[52]\tvalidation_0-mlogloss:3.53169\n",
            "[53]\tvalidation_0-mlogloss:3.55866\n",
            "[54]\tvalidation_0-mlogloss:3.57990\n",
            "[55]\tvalidation_0-mlogloss:3.60695\n",
            "[56]\tvalidation_0-mlogloss:3.62488\n",
            "[57]\tvalidation_0-mlogloss:3.65473\n",
            "[58]\tvalidation_0-mlogloss:3.65812\n",
            "[59]\tvalidation_0-mlogloss:3.69343\n",
            "[60]\tvalidation_0-mlogloss:3.70811\n",
            "[61]\tvalidation_0-mlogloss:3.71901\n",
            "[62]\tvalidation_0-mlogloss:3.72462\n",
            "[63]\tvalidation_0-mlogloss:3.73327\n",
            "[64]\tvalidation_0-mlogloss:3.73833\n",
            "[65]\tvalidation_0-mlogloss:3.75664\n",
            "[66]\tvalidation_0-mlogloss:3.75528\n",
            "[67]\tvalidation_0-mlogloss:3.76895\n",
            "[68]\tvalidation_0-mlogloss:3.77713\n",
            "[69]\tvalidation_0-mlogloss:3.78016\n",
            "[70]\tvalidation_0-mlogloss:3.78981\n",
            "[71]\tvalidation_0-mlogloss:3.80123\n",
            "[72]\tvalidation_0-mlogloss:3.79629\n",
            "[73]\tvalidation_0-mlogloss:3.81047\n",
            "[74]\tvalidation_0-mlogloss:3.82316\n",
            "[75]\tvalidation_0-mlogloss:3.82879\n",
            "[76]\tvalidation_0-mlogloss:3.83762\n",
            "[77]\tvalidation_0-mlogloss:3.84828\n",
            "[78]\tvalidation_0-mlogloss:3.82817\n",
            "[79]\tvalidation_0-mlogloss:3.81207\n",
            "[80]\tvalidation_0-mlogloss:3.79834\n",
            "[81]\tvalidation_0-mlogloss:3.78733\n",
            "[82]\tvalidation_0-mlogloss:3.77105\n",
            "[83]\tvalidation_0-mlogloss:3.76245\n",
            "[84]\tvalidation_0-mlogloss:3.74510\n",
            "[85]\tvalidation_0-mlogloss:3.73563\n",
            "[86]\tvalidation_0-mlogloss:3.72402\n",
            "[87]\tvalidation_0-mlogloss:3.70622\n",
            "[88]\tvalidation_0-mlogloss:3.69126\n",
            "[89]\tvalidation_0-mlogloss:3.68140\n",
            "[90]\tvalidation_0-mlogloss:3.66064\n",
            "[91]\tvalidation_0-mlogloss:3.65052\n",
            "[92]\tvalidation_0-mlogloss:3.63039\n",
            "[93]\tvalidation_0-mlogloss:3.61764\n",
            "[94]\tvalidation_0-mlogloss:3.59446\n",
            "[95]\tvalidation_0-mlogloss:3.59061\n",
            "[96]\tvalidation_0-mlogloss:3.56652\n",
            "[97]\tvalidation_0-mlogloss:3.55538\n",
            "[98]\tvalidation_0-mlogloss:3.53351\n",
            "[99]\tvalidation_0-mlogloss:3.52179\n",
            "[0]\tvalidation_0-mlogloss:2.12045\n",
            "[1]\tvalidation_0-mlogloss:2.10097\n",
            "[2]\tvalidation_0-mlogloss:2.08874\n",
            "[3]\tvalidation_0-mlogloss:2.08541\n",
            "[4]\tvalidation_0-mlogloss:2.08733\n",
            "[5]\tvalidation_0-mlogloss:2.09452\n",
            "[6]\tvalidation_0-mlogloss:2.09817\n",
            "[7]\tvalidation_0-mlogloss:2.10678\n",
            "[8]\tvalidation_0-mlogloss:2.11930\n",
            "[9]\tvalidation_0-mlogloss:2.13613\n",
            "[10]\tvalidation_0-mlogloss:2.14976\n",
            "[11]\tvalidation_0-mlogloss:2.16918\n",
            "[12]\tvalidation_0-mlogloss:2.19119\n",
            "[13]\tvalidation_0-mlogloss:2.21600\n",
            "[14]\tvalidation_0-mlogloss:2.24138\n",
            "[15]\tvalidation_0-mlogloss:2.26668\n",
            "[16]\tvalidation_0-mlogloss:2.28653\n",
            "[17]\tvalidation_0-mlogloss:2.30894\n",
            "[18]\tvalidation_0-mlogloss:2.33431\n",
            "[19]\tvalidation_0-mlogloss:2.35862\n",
            "[20]\tvalidation_0-mlogloss:2.38093\n",
            "[21]\tvalidation_0-mlogloss:2.40376\n",
            "[22]\tvalidation_0-mlogloss:2.43148\n",
            "[23]\tvalidation_0-mlogloss:2.45275\n",
            "[24]\tvalidation_0-mlogloss:2.47791\n",
            "[25]\tvalidation_0-mlogloss:2.49942\n",
            "[26]\tvalidation_0-mlogloss:2.52554\n",
            "[27]\tvalidation_0-mlogloss:2.54964\n",
            "[28]\tvalidation_0-mlogloss:2.57857\n",
            "[29]\tvalidation_0-mlogloss:2.59686\n",
            "[30]\tvalidation_0-mlogloss:2.62213\n",
            "[31]\tvalidation_0-mlogloss:2.64515\n",
            "[32]\tvalidation_0-mlogloss:2.66266\n",
            "[33]\tvalidation_0-mlogloss:2.68662\n",
            "[34]\tvalidation_0-mlogloss:2.70631\n",
            "[35]\tvalidation_0-mlogloss:2.73359\n",
            "[36]\tvalidation_0-mlogloss:2.75948\n",
            "[37]\tvalidation_0-mlogloss:2.79013\n",
            "[38]\tvalidation_0-mlogloss:2.81930\n",
            "[39]\tvalidation_0-mlogloss:2.84987\n",
            "[40]\tvalidation_0-mlogloss:2.87591\n",
            "[41]\tvalidation_0-mlogloss:2.90317\n",
            "[42]\tvalidation_0-mlogloss:2.92747\n",
            "[43]\tvalidation_0-mlogloss:2.94810\n",
            "[44]\tvalidation_0-mlogloss:2.97392\n",
            "[45]\tvalidation_0-mlogloss:2.99501\n",
            "[46]\tvalidation_0-mlogloss:3.01796\n",
            "[47]\tvalidation_0-mlogloss:3.04398\n",
            "[48]\tvalidation_0-mlogloss:3.06871\n",
            "[49]\tvalidation_0-mlogloss:3.09379\n",
            "[50]\tvalidation_0-mlogloss:3.12196\n",
            "[51]\tvalidation_0-mlogloss:3.14987\n",
            "[52]\tvalidation_0-mlogloss:3.17514\n",
            "[53]\tvalidation_0-mlogloss:3.18411\n",
            "[54]\tvalidation_0-mlogloss:3.20514\n",
            "[55]\tvalidation_0-mlogloss:3.23094\n",
            "[56]\tvalidation_0-mlogloss:3.25172\n",
            "[57]\tvalidation_0-mlogloss:3.27549\n",
            "[58]\tvalidation_0-mlogloss:3.29437\n",
            "[59]\tvalidation_0-mlogloss:3.30979\n",
            "[60]\tvalidation_0-mlogloss:3.32456\n",
            "[61]\tvalidation_0-mlogloss:3.33791\n",
            "[62]\tvalidation_0-mlogloss:3.35209\n",
            "[63]\tvalidation_0-mlogloss:3.35597\n",
            "[64]\tvalidation_0-mlogloss:3.36143\n",
            "[65]\tvalidation_0-mlogloss:3.37225\n",
            "[66]\tvalidation_0-mlogloss:3.36295\n",
            "[67]\tvalidation_0-mlogloss:3.37381\n",
            "[68]\tvalidation_0-mlogloss:3.36126\n",
            "[69]\tvalidation_0-mlogloss:3.37147\n",
            "[70]\tvalidation_0-mlogloss:3.36600\n",
            "[71]\tvalidation_0-mlogloss:3.36522\n",
            "[72]\tvalidation_0-mlogloss:3.35835\n",
            "[73]\tvalidation_0-mlogloss:3.35166\n",
            "[74]\tvalidation_0-mlogloss:3.34759\n",
            "[75]\tvalidation_0-mlogloss:3.34684\n",
            "[76]\tvalidation_0-mlogloss:3.34155\n",
            "[77]\tvalidation_0-mlogloss:3.33202\n",
            "[78]\tvalidation_0-mlogloss:3.33375\n",
            "[79]\tvalidation_0-mlogloss:3.32615\n",
            "[80]\tvalidation_0-mlogloss:3.31932\n",
            "[81]\tvalidation_0-mlogloss:3.30689\n",
            "[82]\tvalidation_0-mlogloss:3.30681\n",
            "[83]\tvalidation_0-mlogloss:3.29820\n",
            "[84]\tvalidation_0-mlogloss:3.29283\n",
            "[85]\tvalidation_0-mlogloss:3.27448\n",
            "[86]\tvalidation_0-mlogloss:3.26336\n",
            "[87]\tvalidation_0-mlogloss:3.24382\n",
            "[88]\tvalidation_0-mlogloss:3.22635\n",
            "[89]\tvalidation_0-mlogloss:3.21534\n",
            "[90]\tvalidation_0-mlogloss:3.19983\n",
            "[91]\tvalidation_0-mlogloss:3.18908\n",
            "[92]\tvalidation_0-mlogloss:3.17664\n",
            "[93]\tvalidation_0-mlogloss:3.16554\n",
            "[94]\tvalidation_0-mlogloss:3.16330\n",
            "[95]\tvalidation_0-mlogloss:3.15565\n",
            "[96]\tvalidation_0-mlogloss:3.15028\n",
            "[97]\tvalidation_0-mlogloss:3.14669\n",
            "[98]\tvalidation_0-mlogloss:3.13961\n",
            "[99]\tvalidation_0-mlogloss:3.14170\n",
            "[0]\tvalidation_0-mlogloss:2.20792\n",
            "[1]\tvalidation_0-mlogloss:2.23272\n",
            "[2]\tvalidation_0-mlogloss:2.25984\n",
            "[3]\tvalidation_0-mlogloss:2.28975\n",
            "[4]\tvalidation_0-mlogloss:2.31568\n",
            "[5]\tvalidation_0-mlogloss:2.34718\n",
            "[6]\tvalidation_0-mlogloss:2.37557\n",
            "[7]\tvalidation_0-mlogloss:2.40586\n",
            "[8]\tvalidation_0-mlogloss:2.43735\n",
            "[9]\tvalidation_0-mlogloss:2.46901\n",
            "[10]\tvalidation_0-mlogloss:2.50617\n",
            "[11]\tvalidation_0-mlogloss:2.54355\n",
            "[12]\tvalidation_0-mlogloss:2.58105\n",
            "[13]\tvalidation_0-mlogloss:2.60005\n",
            "[14]\tvalidation_0-mlogloss:2.62511\n",
            "[15]\tvalidation_0-mlogloss:2.65324\n",
            "[16]\tvalidation_0-mlogloss:2.69733\n",
            "[17]\tvalidation_0-mlogloss:2.72973\n",
            "[18]\tvalidation_0-mlogloss:2.76223\n",
            "[19]\tvalidation_0-mlogloss:2.79531\n",
            "[20]\tvalidation_0-mlogloss:2.82477\n",
            "[21]\tvalidation_0-mlogloss:2.86035\n",
            "[22]\tvalidation_0-mlogloss:2.86887\n",
            "[23]\tvalidation_0-mlogloss:2.90961\n",
            "[24]\tvalidation_0-mlogloss:2.91771\n",
            "[25]\tvalidation_0-mlogloss:2.93620\n",
            "[26]\tvalidation_0-mlogloss:2.97693\n",
            "[27]\tvalidation_0-mlogloss:2.98755\n",
            "[28]\tvalidation_0-mlogloss:3.01530\n",
            "[29]\tvalidation_0-mlogloss:3.02944\n",
            "[30]\tvalidation_0-mlogloss:3.06081\n",
            "[31]\tvalidation_0-mlogloss:3.07359\n",
            "[32]\tvalidation_0-mlogloss:3.10574\n",
            "[33]\tvalidation_0-mlogloss:3.15317\n",
            "[34]\tvalidation_0-mlogloss:3.17104\n",
            "[35]\tvalidation_0-mlogloss:3.21572\n",
            "[36]\tvalidation_0-mlogloss:3.22434\n",
            "[37]\tvalidation_0-mlogloss:3.25555\n",
            "[38]\tvalidation_0-mlogloss:3.29394\n",
            "[39]\tvalidation_0-mlogloss:3.32745\n",
            "[40]\tvalidation_0-mlogloss:3.35362\n",
            "[41]\tvalidation_0-mlogloss:3.37881\n",
            "[42]\tvalidation_0-mlogloss:3.41048\n",
            "[43]\tvalidation_0-mlogloss:3.43848\n",
            "[44]\tvalidation_0-mlogloss:3.45497\n",
            "[45]\tvalidation_0-mlogloss:3.49501\n",
            "[46]\tvalidation_0-mlogloss:3.51878\n",
            "[47]\tvalidation_0-mlogloss:3.54765\n",
            "[48]\tvalidation_0-mlogloss:3.56985\n",
            "[49]\tvalidation_0-mlogloss:3.59805\n",
            "[50]\tvalidation_0-mlogloss:3.61969\n",
            "[51]\tvalidation_0-mlogloss:3.64583\n",
            "[52]\tvalidation_0-mlogloss:3.66130\n",
            "[53]\tvalidation_0-mlogloss:3.67895\n",
            "[54]\tvalidation_0-mlogloss:3.68346\n",
            "[55]\tvalidation_0-mlogloss:3.70011\n",
            "[56]\tvalidation_0-mlogloss:3.70046\n",
            "[57]\tvalidation_0-mlogloss:3.70804\n",
            "[58]\tvalidation_0-mlogloss:3.71046\n",
            "[59]\tvalidation_0-mlogloss:3.71644\n",
            "[60]\tvalidation_0-mlogloss:3.72348\n",
            "[61]\tvalidation_0-mlogloss:3.73133\n",
            "[62]\tvalidation_0-mlogloss:3.73807\n",
            "[63]\tvalidation_0-mlogloss:3.74474\n",
            "[64]\tvalidation_0-mlogloss:3.75339\n",
            "[65]\tvalidation_0-mlogloss:3.74132\n",
            "[66]\tvalidation_0-mlogloss:3.75025\n",
            "[67]\tvalidation_0-mlogloss:3.75078\n",
            "[68]\tvalidation_0-mlogloss:3.76319\n",
            "[69]\tvalidation_0-mlogloss:3.77041\n",
            "[70]\tvalidation_0-mlogloss:3.78694\n",
            "[71]\tvalidation_0-mlogloss:3.76792\n",
            "[72]\tvalidation_0-mlogloss:3.78149\n",
            "[73]\tvalidation_0-mlogloss:3.76144\n",
            "[74]\tvalidation_0-mlogloss:3.77294\n",
            "[75]\tvalidation_0-mlogloss:3.75569\n",
            "[76]\tvalidation_0-mlogloss:3.75814\n",
            "[77]\tvalidation_0-mlogloss:3.77251\n",
            "[78]\tvalidation_0-mlogloss:3.75319\n",
            "[79]\tvalidation_0-mlogloss:3.76836\n",
            "[80]\tvalidation_0-mlogloss:3.75005\n",
            "[81]\tvalidation_0-mlogloss:3.76236\n",
            "[82]\tvalidation_0-mlogloss:3.75623\n",
            "[83]\tvalidation_0-mlogloss:3.74897\n",
            "[84]\tvalidation_0-mlogloss:3.73959\n",
            "[85]\tvalidation_0-mlogloss:3.72392\n",
            "[86]\tvalidation_0-mlogloss:3.71977\n",
            "[87]\tvalidation_0-mlogloss:3.71036\n",
            "[88]\tvalidation_0-mlogloss:3.68737\n",
            "[89]\tvalidation_0-mlogloss:3.68873\n",
            "[90]\tvalidation_0-mlogloss:3.67136\n",
            "[91]\tvalidation_0-mlogloss:3.66305\n",
            "[92]\tvalidation_0-mlogloss:3.64918\n",
            "[93]\tvalidation_0-mlogloss:3.62487\n",
            "[94]\tvalidation_0-mlogloss:3.61661\n",
            "[95]\tvalidation_0-mlogloss:3.60453\n",
            "[96]\tvalidation_0-mlogloss:3.58723\n",
            "[97]\tvalidation_0-mlogloss:3.58266\n",
            "[98]\tvalidation_0-mlogloss:3.57785\n",
            "[99]\tvalidation_0-mlogloss:3.56236\n",
            "[0]\tvalidation_0-mlogloss:2.20286\n",
            "[1]\tvalidation_0-mlogloss:2.21338\n",
            "[2]\tvalidation_0-mlogloss:2.22394\n",
            "[3]\tvalidation_0-mlogloss:2.24678\n",
            "[4]\tvalidation_0-mlogloss:2.27132\n",
            "[5]\tvalidation_0-mlogloss:2.29764\n",
            "[6]\tvalidation_0-mlogloss:2.32727\n",
            "[7]\tvalidation_0-mlogloss:2.33954\n",
            "[8]\tvalidation_0-mlogloss:2.37206\n",
            "[9]\tvalidation_0-mlogloss:2.37987\n",
            "[10]\tvalidation_0-mlogloss:2.39522\n",
            "[11]\tvalidation_0-mlogloss:2.41411\n",
            "[12]\tvalidation_0-mlogloss:2.43337\n",
            "[13]\tvalidation_0-mlogloss:2.45580\n",
            "[14]\tvalidation_0-mlogloss:2.48096\n",
            "[15]\tvalidation_0-mlogloss:2.50760\n",
            "[16]\tvalidation_0-mlogloss:2.53579\n",
            "[17]\tvalidation_0-mlogloss:2.56459\n",
            "[18]\tvalidation_0-mlogloss:2.59348\n",
            "[19]\tvalidation_0-mlogloss:2.62366\n",
            "[20]\tvalidation_0-mlogloss:2.65288\n",
            "[21]\tvalidation_0-mlogloss:2.68595\n",
            "[22]\tvalidation_0-mlogloss:2.71110\n",
            "[23]\tvalidation_0-mlogloss:2.74560\n",
            "[24]\tvalidation_0-mlogloss:2.78002\n",
            "[25]\tvalidation_0-mlogloss:2.81509\n",
            "[26]\tvalidation_0-mlogloss:2.84948\n",
            "[27]\tvalidation_0-mlogloss:2.88595\n",
            "[28]\tvalidation_0-mlogloss:2.92248\n",
            "[29]\tvalidation_0-mlogloss:2.95851\n",
            "[30]\tvalidation_0-mlogloss:2.99711\n",
            "[31]\tvalidation_0-mlogloss:3.02548\n",
            "[32]\tvalidation_0-mlogloss:3.05251\n",
            "[33]\tvalidation_0-mlogloss:3.07792\n",
            "[34]\tvalidation_0-mlogloss:3.10142\n",
            "[35]\tvalidation_0-mlogloss:3.12450\n",
            "[36]\tvalidation_0-mlogloss:3.14810\n",
            "[37]\tvalidation_0-mlogloss:3.17144\n",
            "[38]\tvalidation_0-mlogloss:3.19434\n",
            "[39]\tvalidation_0-mlogloss:3.22053\n",
            "[40]\tvalidation_0-mlogloss:3.25170\n",
            "[41]\tvalidation_0-mlogloss:3.27649\n",
            "[42]\tvalidation_0-mlogloss:3.29970\n",
            "[43]\tvalidation_0-mlogloss:3.32585\n",
            "[44]\tvalidation_0-mlogloss:3.35134\n",
            "[45]\tvalidation_0-mlogloss:3.37737\n",
            "[46]\tvalidation_0-mlogloss:3.40351\n",
            "[47]\tvalidation_0-mlogloss:3.42886\n",
            "[48]\tvalidation_0-mlogloss:3.45595\n",
            "[49]\tvalidation_0-mlogloss:3.48479\n",
            "[50]\tvalidation_0-mlogloss:3.51410\n",
            "[51]\tvalidation_0-mlogloss:3.54265\n",
            "[52]\tvalidation_0-mlogloss:3.57254\n",
            "[53]\tvalidation_0-mlogloss:3.60622\n",
            "[54]\tvalidation_0-mlogloss:3.62692\n",
            "[55]\tvalidation_0-mlogloss:3.65958\n",
            "[56]\tvalidation_0-mlogloss:3.68642\n",
            "[57]\tvalidation_0-mlogloss:3.70535\n",
            "[58]\tvalidation_0-mlogloss:3.72260\n",
            "[59]\tvalidation_0-mlogloss:3.74204\n",
            "[60]\tvalidation_0-mlogloss:3.75333\n",
            "[61]\tvalidation_0-mlogloss:3.77379\n",
            "[62]\tvalidation_0-mlogloss:3.79718\n",
            "[63]\tvalidation_0-mlogloss:3.81449\n",
            "[64]\tvalidation_0-mlogloss:3.82594\n",
            "[65]\tvalidation_0-mlogloss:3.85311\n",
            "[66]\tvalidation_0-mlogloss:3.84675\n",
            "[67]\tvalidation_0-mlogloss:3.86640\n",
            "[68]\tvalidation_0-mlogloss:3.88152\n",
            "[69]\tvalidation_0-mlogloss:3.88166\n",
            "[70]\tvalidation_0-mlogloss:3.87868\n",
            "[71]\tvalidation_0-mlogloss:3.90075\n",
            "[72]\tvalidation_0-mlogloss:3.91702\n",
            "[73]\tvalidation_0-mlogloss:3.92097\n",
            "[74]\tvalidation_0-mlogloss:3.93826\n",
            "[75]\tvalidation_0-mlogloss:3.94470\n",
            "[76]\tvalidation_0-mlogloss:3.94243\n",
            "[77]\tvalidation_0-mlogloss:3.94987\n",
            "[78]\tvalidation_0-mlogloss:3.94744\n",
            "[79]\tvalidation_0-mlogloss:3.96771\n",
            "[80]\tvalidation_0-mlogloss:3.96738\n",
            "[81]\tvalidation_0-mlogloss:3.96260\n",
            "[82]\tvalidation_0-mlogloss:3.96431\n",
            "[83]\tvalidation_0-mlogloss:3.96318\n",
            "[84]\tvalidation_0-mlogloss:3.95812\n",
            "[85]\tvalidation_0-mlogloss:3.94861\n",
            "[86]\tvalidation_0-mlogloss:3.92514\n",
            "[87]\tvalidation_0-mlogloss:3.90694\n",
            "[88]\tvalidation_0-mlogloss:3.89976\n",
            "[89]\tvalidation_0-mlogloss:3.87788\n",
            "[90]\tvalidation_0-mlogloss:3.87037\n",
            "[91]\tvalidation_0-mlogloss:3.86116\n",
            "[92]\tvalidation_0-mlogloss:3.84149\n",
            "[93]\tvalidation_0-mlogloss:3.83418\n",
            "[94]\tvalidation_0-mlogloss:3.81644\n",
            "[95]\tvalidation_0-mlogloss:3.79740\n",
            "[96]\tvalidation_0-mlogloss:3.80004\n",
            "[97]\tvalidation_0-mlogloss:3.79169\n",
            "[98]\tvalidation_0-mlogloss:3.79437\n",
            "[99]\tvalidation_0-mlogloss:3.78589\n",
            "[0]\tvalidation_0-mlogloss:2.21869\n",
            "[1]\tvalidation_0-mlogloss:2.24415\n",
            "[2]\tvalidation_0-mlogloss:2.27115\n",
            "[3]\tvalidation_0-mlogloss:2.30770\n",
            "[4]\tvalidation_0-mlogloss:2.34469\n",
            "[5]\tvalidation_0-mlogloss:2.38094\n",
            "[6]\tvalidation_0-mlogloss:2.41926\n",
            "[7]\tvalidation_0-mlogloss:2.45317\n",
            "[8]\tvalidation_0-mlogloss:2.47500\n",
            "[9]\tvalidation_0-mlogloss:2.51088\n",
            "[10]\tvalidation_0-mlogloss:2.51813\n",
            "[11]\tvalidation_0-mlogloss:2.53453\n",
            "[12]\tvalidation_0-mlogloss:2.55226\n",
            "[13]\tvalidation_0-mlogloss:2.57275\n",
            "[14]\tvalidation_0-mlogloss:2.59378\n",
            "[15]\tvalidation_0-mlogloss:2.61472\n",
            "[16]\tvalidation_0-mlogloss:2.63940\n",
            "[17]\tvalidation_0-mlogloss:2.66829\n",
            "[18]\tvalidation_0-mlogloss:2.69863\n",
            "[19]\tvalidation_0-mlogloss:2.72005\n",
            "[20]\tvalidation_0-mlogloss:2.74155\n",
            "[21]\tvalidation_0-mlogloss:2.76544\n",
            "[22]\tvalidation_0-mlogloss:2.78740\n",
            "[23]\tvalidation_0-mlogloss:2.82380\n",
            "[24]\tvalidation_0-mlogloss:2.85084\n",
            "[25]\tvalidation_0-mlogloss:2.88278\n",
            "[26]\tvalidation_0-mlogloss:2.90964\n",
            "[27]\tvalidation_0-mlogloss:2.93700\n",
            "[28]\tvalidation_0-mlogloss:2.96646\n",
            "[29]\tvalidation_0-mlogloss:3.00019\n",
            "[30]\tvalidation_0-mlogloss:3.03349\n",
            "[31]\tvalidation_0-mlogloss:3.08025\n",
            "[32]\tvalidation_0-mlogloss:3.11115\n",
            "[33]\tvalidation_0-mlogloss:3.15145\n",
            "[34]\tvalidation_0-mlogloss:3.18006\n",
            "[35]\tvalidation_0-mlogloss:3.22221\n",
            "[36]\tvalidation_0-mlogloss:3.25435\n",
            "[37]\tvalidation_0-mlogloss:3.29388\n",
            "[38]\tvalidation_0-mlogloss:3.32691\n",
            "[39]\tvalidation_0-mlogloss:3.36707\n",
            "[40]\tvalidation_0-mlogloss:3.39877\n",
            "[41]\tvalidation_0-mlogloss:3.42779\n",
            "[42]\tvalidation_0-mlogloss:3.47130\n",
            "[43]\tvalidation_0-mlogloss:3.50674\n",
            "[44]\tvalidation_0-mlogloss:3.55182\n",
            "[45]\tvalidation_0-mlogloss:3.58002\n",
            "[46]\tvalidation_0-mlogloss:3.61149\n",
            "[47]\tvalidation_0-mlogloss:3.63986\n",
            "[48]\tvalidation_0-mlogloss:3.67061\n",
            "[49]\tvalidation_0-mlogloss:3.70184\n",
            "[50]\tvalidation_0-mlogloss:3.73354\n",
            "[51]\tvalidation_0-mlogloss:3.76844\n",
            "[52]\tvalidation_0-mlogloss:3.79918\n",
            "[53]\tvalidation_0-mlogloss:3.83216\n",
            "[54]\tvalidation_0-mlogloss:3.86707\n",
            "[55]\tvalidation_0-mlogloss:3.89120\n",
            "[56]\tvalidation_0-mlogloss:3.91420\n",
            "[57]\tvalidation_0-mlogloss:3.93702\n",
            "[58]\tvalidation_0-mlogloss:3.95483\n",
            "[59]\tvalidation_0-mlogloss:3.96616\n",
            "[60]\tvalidation_0-mlogloss:3.98189\n",
            "[61]\tvalidation_0-mlogloss:3.98764\n",
            "[62]\tvalidation_0-mlogloss:3.99839\n",
            "[63]\tvalidation_0-mlogloss:4.01208\n",
            "[64]\tvalidation_0-mlogloss:4.02354\n",
            "[65]\tvalidation_0-mlogloss:4.03426\n",
            "[66]\tvalidation_0-mlogloss:4.04187\n",
            "[67]\tvalidation_0-mlogloss:4.05317\n",
            "[68]\tvalidation_0-mlogloss:4.06198\n",
            "[69]\tvalidation_0-mlogloss:4.07979\n",
            "[70]\tvalidation_0-mlogloss:4.09258\n",
            "[71]\tvalidation_0-mlogloss:4.10897\n",
            "[72]\tvalidation_0-mlogloss:4.11233\n",
            "[73]\tvalidation_0-mlogloss:4.12756\n",
            "[74]\tvalidation_0-mlogloss:4.12819\n",
            "[75]\tvalidation_0-mlogloss:4.14594\n",
            "[76]\tvalidation_0-mlogloss:4.15025\n",
            "[77]\tvalidation_0-mlogloss:4.14423\n",
            "[78]\tvalidation_0-mlogloss:4.15764\n",
            "[79]\tvalidation_0-mlogloss:4.13895\n",
            "[80]\tvalidation_0-mlogloss:4.13736\n",
            "[81]\tvalidation_0-mlogloss:4.12175\n",
            "[82]\tvalidation_0-mlogloss:4.11239\n",
            "[83]\tvalidation_0-mlogloss:4.09729\n",
            "[84]\tvalidation_0-mlogloss:4.07255\n",
            "[85]\tvalidation_0-mlogloss:4.04714\n",
            "[86]\tvalidation_0-mlogloss:4.03733\n",
            "[87]\tvalidation_0-mlogloss:4.02091\n",
            "[88]\tvalidation_0-mlogloss:4.00156\n",
            "[89]\tvalidation_0-mlogloss:3.97795\n",
            "[90]\tvalidation_0-mlogloss:3.94938\n",
            "[91]\tvalidation_0-mlogloss:3.94036\n",
            "[92]\tvalidation_0-mlogloss:3.91141\n",
            "[93]\tvalidation_0-mlogloss:3.88800\n",
            "[94]\tvalidation_0-mlogloss:3.86662\n",
            "[95]\tvalidation_0-mlogloss:3.85139\n",
            "[96]\tvalidation_0-mlogloss:3.82896\n",
            "[97]\tvalidation_0-mlogloss:3.80862\n",
            "[98]\tvalidation_0-mlogloss:3.79322\n",
            "[99]\tvalidation_0-mlogloss:3.77648\n",
            "[0]\tvalidation_0-mlogloss:2.22126\n",
            "[1]\tvalidation_0-mlogloss:2.24340\n",
            "[2]\tvalidation_0-mlogloss:2.26368\n",
            "[3]\tvalidation_0-mlogloss:2.28908\n",
            "[4]\tvalidation_0-mlogloss:2.31737\n",
            "[5]\tvalidation_0-mlogloss:2.35078\n",
            "[6]\tvalidation_0-mlogloss:2.38616\n",
            "[7]\tvalidation_0-mlogloss:2.42242\n",
            "[8]\tvalidation_0-mlogloss:2.44049\n",
            "[9]\tvalidation_0-mlogloss:2.47937\n",
            "[10]\tvalidation_0-mlogloss:2.51985\n",
            "[11]\tvalidation_0-mlogloss:2.52711\n",
            "[12]\tvalidation_0-mlogloss:2.55153\n",
            "[13]\tvalidation_0-mlogloss:2.57660\n",
            "[14]\tvalidation_0-mlogloss:2.60267\n",
            "[15]\tvalidation_0-mlogloss:2.61106\n",
            "[16]\tvalidation_0-mlogloss:2.63544\n",
            "[17]\tvalidation_0-mlogloss:2.66009\n",
            "[18]\tvalidation_0-mlogloss:2.66867\n",
            "[19]\tvalidation_0-mlogloss:2.69399\n",
            "[20]\tvalidation_0-mlogloss:2.72202\n",
            "[21]\tvalidation_0-mlogloss:2.74796\n",
            "[22]\tvalidation_0-mlogloss:2.76286\n",
            "[23]\tvalidation_0-mlogloss:2.79137\n",
            "[24]\tvalidation_0-mlogloss:2.82209\n",
            "[25]\tvalidation_0-mlogloss:2.83601\n",
            "[26]\tvalidation_0-mlogloss:2.86711\n",
            "[27]\tvalidation_0-mlogloss:2.89542\n",
            "[28]\tvalidation_0-mlogloss:2.91744\n",
            "[29]\tvalidation_0-mlogloss:2.95114\n",
            "[30]\tvalidation_0-mlogloss:2.97168\n",
            "[31]\tvalidation_0-mlogloss:2.99431\n",
            "[32]\tvalidation_0-mlogloss:3.01694\n",
            "[33]\tvalidation_0-mlogloss:3.04764\n",
            "[34]\tvalidation_0-mlogloss:3.07342\n",
            "[35]\tvalidation_0-mlogloss:3.08491\n",
            "[36]\tvalidation_0-mlogloss:3.10912\n",
            "[37]\tvalidation_0-mlogloss:3.12386\n",
            "[38]\tvalidation_0-mlogloss:3.14271\n",
            "[39]\tvalidation_0-mlogloss:3.17178\n",
            "[40]\tvalidation_0-mlogloss:3.18792\n",
            "[41]\tvalidation_0-mlogloss:3.21539\n",
            "[42]\tvalidation_0-mlogloss:3.23800\n",
            "[43]\tvalidation_0-mlogloss:3.25538\n",
            "[44]\tvalidation_0-mlogloss:3.27482\n",
            "[45]\tvalidation_0-mlogloss:3.30020\n",
            "[46]\tvalidation_0-mlogloss:3.32296\n",
            "[47]\tvalidation_0-mlogloss:3.34039\n",
            "[48]\tvalidation_0-mlogloss:3.36506\n",
            "[49]\tvalidation_0-mlogloss:3.37947\n",
            "[50]\tvalidation_0-mlogloss:3.39724\n",
            "[51]\tvalidation_0-mlogloss:3.42060\n",
            "[52]\tvalidation_0-mlogloss:3.43326\n",
            "[53]\tvalidation_0-mlogloss:3.45494\n",
            "[54]\tvalidation_0-mlogloss:3.47236\n",
            "[55]\tvalidation_0-mlogloss:3.48414\n",
            "[56]\tvalidation_0-mlogloss:3.51630\n",
            "[57]\tvalidation_0-mlogloss:3.53021\n",
            "[58]\tvalidation_0-mlogloss:3.55969\n",
            "[59]\tvalidation_0-mlogloss:3.59162\n",
            "[60]\tvalidation_0-mlogloss:3.60602\n",
            "[61]\tvalidation_0-mlogloss:3.61334\n",
            "[62]\tvalidation_0-mlogloss:3.63224\n",
            "[63]\tvalidation_0-mlogloss:3.64506\n",
            "[64]\tvalidation_0-mlogloss:3.65772\n",
            "[65]\tvalidation_0-mlogloss:3.66865\n",
            "[66]\tvalidation_0-mlogloss:3.68382\n",
            "[67]\tvalidation_0-mlogloss:3.68571\n",
            "[68]\tvalidation_0-mlogloss:3.70406\n",
            "[69]\tvalidation_0-mlogloss:3.71302\n",
            "[70]\tvalidation_0-mlogloss:3.71649\n",
            "[71]\tvalidation_0-mlogloss:3.73323\n",
            "[72]\tvalidation_0-mlogloss:3.74332\n",
            "[73]\tvalidation_0-mlogloss:3.75079\n",
            "[74]\tvalidation_0-mlogloss:3.76045\n",
            "[75]\tvalidation_0-mlogloss:3.77587\n",
            "[76]\tvalidation_0-mlogloss:3.78695\n",
            "[77]\tvalidation_0-mlogloss:3.76874\n",
            "[78]\tvalidation_0-mlogloss:3.75487\n",
            "[79]\tvalidation_0-mlogloss:3.74112\n",
            "[80]\tvalidation_0-mlogloss:3.72651\n",
            "[81]\tvalidation_0-mlogloss:3.70759\n",
            "[82]\tvalidation_0-mlogloss:3.69300\n",
            "[83]\tvalidation_0-mlogloss:3.67388\n",
            "[84]\tvalidation_0-mlogloss:3.65443\n",
            "[85]\tvalidation_0-mlogloss:3.63338\n",
            "[86]\tvalidation_0-mlogloss:3.60334\n",
            "[87]\tvalidation_0-mlogloss:3.58801\n",
            "[88]\tvalidation_0-mlogloss:3.55738\n",
            "[89]\tvalidation_0-mlogloss:3.53228\n",
            "[90]\tvalidation_0-mlogloss:3.50477\n",
            "[91]\tvalidation_0-mlogloss:3.47808\n",
            "[92]\tvalidation_0-mlogloss:3.46331\n",
            "[93]\tvalidation_0-mlogloss:3.43632\n",
            "[94]\tvalidation_0-mlogloss:3.41343\n",
            "[95]\tvalidation_0-mlogloss:3.39102\n",
            "[96]\tvalidation_0-mlogloss:3.37211\n",
            "[97]\tvalidation_0-mlogloss:3.34787\n",
            "[98]\tvalidation_0-mlogloss:3.34129\n",
            "[99]\tvalidation_0-mlogloss:3.32175\n",
            "[0]\tvalidation_0-mlogloss:2.20435\n",
            "[1]\tvalidation_0-mlogloss:2.21527\n",
            "[2]\tvalidation_0-mlogloss:2.22691\n",
            "[3]\tvalidation_0-mlogloss:2.23613\n",
            "[4]\tvalidation_0-mlogloss:2.25122\n",
            "[5]\tvalidation_0-mlogloss:2.26351\n",
            "[6]\tvalidation_0-mlogloss:2.27804\n",
            "[7]\tvalidation_0-mlogloss:2.29937\n",
            "[8]\tvalidation_0-mlogloss:2.31428\n",
            "[9]\tvalidation_0-mlogloss:2.33126\n",
            "[10]\tvalidation_0-mlogloss:2.34685\n",
            "[11]\tvalidation_0-mlogloss:2.36910\n",
            "[12]\tvalidation_0-mlogloss:2.39058\n",
            "[13]\tvalidation_0-mlogloss:2.41145\n",
            "[14]\tvalidation_0-mlogloss:2.43458\n",
            "[15]\tvalidation_0-mlogloss:2.45836\n",
            "[16]\tvalidation_0-mlogloss:2.48267\n",
            "[17]\tvalidation_0-mlogloss:2.50792\n",
            "[18]\tvalidation_0-mlogloss:2.53496\n",
            "[19]\tvalidation_0-mlogloss:2.56000\n",
            "[20]\tvalidation_0-mlogloss:2.58543\n",
            "[21]\tvalidation_0-mlogloss:2.61510\n",
            "[22]\tvalidation_0-mlogloss:2.64037\n",
            "[23]\tvalidation_0-mlogloss:2.66843\n",
            "[24]\tvalidation_0-mlogloss:2.69828\n",
            "[25]\tvalidation_0-mlogloss:2.72598\n",
            "[26]\tvalidation_0-mlogloss:2.73976\n",
            "[27]\tvalidation_0-mlogloss:2.75424\n",
            "[28]\tvalidation_0-mlogloss:2.77096\n",
            "[29]\tvalidation_0-mlogloss:2.78819\n",
            "[30]\tvalidation_0-mlogloss:2.80435\n",
            "[31]\tvalidation_0-mlogloss:2.82280\n",
            "[32]\tvalidation_0-mlogloss:2.84077\n",
            "[33]\tvalidation_0-mlogloss:2.85899\n",
            "[34]\tvalidation_0-mlogloss:2.87131\n",
            "[35]\tvalidation_0-mlogloss:2.89108\n",
            "[36]\tvalidation_0-mlogloss:2.90459\n",
            "[37]\tvalidation_0-mlogloss:2.93601\n",
            "[38]\tvalidation_0-mlogloss:2.95213\n",
            "[39]\tvalidation_0-mlogloss:2.98178\n",
            "[40]\tvalidation_0-mlogloss:3.00217\n",
            "[41]\tvalidation_0-mlogloss:3.02086\n",
            "[42]\tvalidation_0-mlogloss:3.04047\n",
            "[43]\tvalidation_0-mlogloss:3.06295\n",
            "[44]\tvalidation_0-mlogloss:3.07876\n",
            "[45]\tvalidation_0-mlogloss:3.09523\n",
            "[46]\tvalidation_0-mlogloss:3.11554\n",
            "[47]\tvalidation_0-mlogloss:3.13718\n",
            "[48]\tvalidation_0-mlogloss:3.16651\n",
            "[49]\tvalidation_0-mlogloss:3.19263\n",
            "[50]\tvalidation_0-mlogloss:3.21386\n",
            "[51]\tvalidation_0-mlogloss:3.24219\n",
            "[52]\tvalidation_0-mlogloss:3.27353\n",
            "[53]\tvalidation_0-mlogloss:3.29194\n",
            "[54]\tvalidation_0-mlogloss:3.31839\n",
            "[55]\tvalidation_0-mlogloss:3.34136\n",
            "[56]\tvalidation_0-mlogloss:3.36691\n",
            "[57]\tvalidation_0-mlogloss:3.38123\n",
            "[58]\tvalidation_0-mlogloss:3.41372\n",
            "[59]\tvalidation_0-mlogloss:3.43460\n",
            "[60]\tvalidation_0-mlogloss:3.44240\n",
            "[61]\tvalidation_0-mlogloss:3.46048\n",
            "[62]\tvalidation_0-mlogloss:3.46771\n",
            "[63]\tvalidation_0-mlogloss:3.48040\n",
            "[64]\tvalidation_0-mlogloss:3.49351\n",
            "[65]\tvalidation_0-mlogloss:3.49973\n",
            "[66]\tvalidation_0-mlogloss:3.50514\n",
            "[67]\tvalidation_0-mlogloss:3.51488\n",
            "[68]\tvalidation_0-mlogloss:3.52612\n",
            "[69]\tvalidation_0-mlogloss:3.52736\n",
            "[70]\tvalidation_0-mlogloss:3.50710\n",
            "[71]\tvalidation_0-mlogloss:3.52527\n",
            "[72]\tvalidation_0-mlogloss:3.51064\n",
            "[73]\tvalidation_0-mlogloss:3.52225\n",
            "[74]\tvalidation_0-mlogloss:3.50885\n",
            "[75]\tvalidation_0-mlogloss:3.50284\n",
            "[76]\tvalidation_0-mlogloss:3.48836\n",
            "[77]\tvalidation_0-mlogloss:3.47639\n",
            "[78]\tvalidation_0-mlogloss:3.45262\n",
            "[79]\tvalidation_0-mlogloss:3.44719\n",
            "[80]\tvalidation_0-mlogloss:3.43659\n",
            "[81]\tvalidation_0-mlogloss:3.42348\n",
            "[82]\tvalidation_0-mlogloss:3.41643\n",
            "[83]\tvalidation_0-mlogloss:3.40749\n",
            "[84]\tvalidation_0-mlogloss:3.38845\n",
            "[85]\tvalidation_0-mlogloss:3.36774\n",
            "[86]\tvalidation_0-mlogloss:3.34394\n",
            "[87]\tvalidation_0-mlogloss:3.32555\n",
            "[88]\tvalidation_0-mlogloss:3.31488\n",
            "[89]\tvalidation_0-mlogloss:3.29540\n",
            "[90]\tvalidation_0-mlogloss:3.27163\n",
            "[91]\tvalidation_0-mlogloss:3.25384\n",
            "[92]\tvalidation_0-mlogloss:3.23885\n",
            "[93]\tvalidation_0-mlogloss:3.21905\n",
            "[94]\tvalidation_0-mlogloss:3.20057\n",
            "[95]\tvalidation_0-mlogloss:3.18943\n",
            "[96]\tvalidation_0-mlogloss:3.17430\n",
            "[97]\tvalidation_0-mlogloss:3.15777\n",
            "[98]\tvalidation_0-mlogloss:3.14387\n",
            "[99]\tvalidation_0-mlogloss:3.12603\n",
            "[0]\tvalidation_0-mlogloss:2.19108\n",
            "[1]\tvalidation_0-mlogloss:2.18766\n",
            "[2]\tvalidation_0-mlogloss:2.19531\n",
            "[3]\tvalidation_0-mlogloss:2.20049\n",
            "[4]\tvalidation_0-mlogloss:2.20967\n",
            "[5]\tvalidation_0-mlogloss:2.22043\n",
            "[6]\tvalidation_0-mlogloss:2.23184\n",
            "[7]\tvalidation_0-mlogloss:2.23794\n",
            "[8]\tvalidation_0-mlogloss:2.25570\n",
            "[9]\tvalidation_0-mlogloss:2.27301\n",
            "[10]\tvalidation_0-mlogloss:2.28578\n",
            "[11]\tvalidation_0-mlogloss:2.30134\n",
            "[12]\tvalidation_0-mlogloss:2.31618\n",
            "[13]\tvalidation_0-mlogloss:2.32626\n",
            "[14]\tvalidation_0-mlogloss:2.31629\n",
            "[15]\tvalidation_0-mlogloss:2.33449\n",
            "[16]\tvalidation_0-mlogloss:2.32893\n",
            "[17]\tvalidation_0-mlogloss:2.35043\n",
            "[18]\tvalidation_0-mlogloss:2.34873\n",
            "[19]\tvalidation_0-mlogloss:2.36999\n",
            "[20]\tvalidation_0-mlogloss:2.36898\n",
            "[21]\tvalidation_0-mlogloss:2.38806\n",
            "[22]\tvalidation_0-mlogloss:2.38703\n",
            "[23]\tvalidation_0-mlogloss:2.39380\n",
            "[24]\tvalidation_0-mlogloss:2.40704\n",
            "[25]\tvalidation_0-mlogloss:2.41108\n",
            "[26]\tvalidation_0-mlogloss:2.43090\n",
            "[27]\tvalidation_0-mlogloss:2.43512\n",
            "[28]\tvalidation_0-mlogloss:2.43185\n",
            "[29]\tvalidation_0-mlogloss:2.43513\n",
            "[30]\tvalidation_0-mlogloss:2.45015\n",
            "[31]\tvalidation_0-mlogloss:2.46017\n",
            "[32]\tvalidation_0-mlogloss:2.46782\n",
            "[33]\tvalidation_0-mlogloss:2.47705\n",
            "[34]\tvalidation_0-mlogloss:2.49778\n",
            "[35]\tvalidation_0-mlogloss:2.51029\n",
            "[36]\tvalidation_0-mlogloss:2.51983\n",
            "[37]\tvalidation_0-mlogloss:2.53732\n",
            "[38]\tvalidation_0-mlogloss:2.55329\n",
            "[39]\tvalidation_0-mlogloss:2.56774\n",
            "[40]\tvalidation_0-mlogloss:2.58618\n",
            "[41]\tvalidation_0-mlogloss:2.60053\n",
            "[42]\tvalidation_0-mlogloss:2.62395\n",
            "[43]\tvalidation_0-mlogloss:2.63079\n",
            "[44]\tvalidation_0-mlogloss:2.63982\n",
            "[45]\tvalidation_0-mlogloss:2.64877\n",
            "[46]\tvalidation_0-mlogloss:2.66037\n",
            "[47]\tvalidation_0-mlogloss:2.67031\n",
            "[48]\tvalidation_0-mlogloss:2.69761\n",
            "[49]\tvalidation_0-mlogloss:2.72299\n",
            "[50]\tvalidation_0-mlogloss:2.73426\n",
            "[51]\tvalidation_0-mlogloss:2.75883\n",
            "[52]\tvalidation_0-mlogloss:2.77645\n",
            "[53]\tvalidation_0-mlogloss:2.79406\n",
            "[54]\tvalidation_0-mlogloss:2.81540\n",
            "[55]\tvalidation_0-mlogloss:2.83147\n",
            "[56]\tvalidation_0-mlogloss:2.84461\n",
            "[57]\tvalidation_0-mlogloss:2.87009\n",
            "[58]\tvalidation_0-mlogloss:2.88671\n",
            "[59]\tvalidation_0-mlogloss:2.89948\n",
            "[60]\tvalidation_0-mlogloss:2.90409\n",
            "[61]\tvalidation_0-mlogloss:2.91660\n",
            "[62]\tvalidation_0-mlogloss:2.91613\n",
            "[63]\tvalidation_0-mlogloss:2.92771\n",
            "[64]\tvalidation_0-mlogloss:2.92997\n",
            "[65]\tvalidation_0-mlogloss:2.93811\n",
            "[66]\tvalidation_0-mlogloss:2.95022\n",
            "[67]\tvalidation_0-mlogloss:2.95604\n",
            "[68]\tvalidation_0-mlogloss:2.95734\n",
            "[69]\tvalidation_0-mlogloss:2.96509\n",
            "[70]\tvalidation_0-mlogloss:2.97352\n",
            "[71]\tvalidation_0-mlogloss:2.95760\n",
            "[72]\tvalidation_0-mlogloss:2.96988\n",
            "[73]\tvalidation_0-mlogloss:2.97767\n",
            "[74]\tvalidation_0-mlogloss:2.98221\n",
            "[75]\tvalidation_0-mlogloss:2.97128\n",
            "[76]\tvalidation_0-mlogloss:2.97325\n",
            "[77]\tvalidation_0-mlogloss:2.99042\n",
            "[78]\tvalidation_0-mlogloss:2.97050\n",
            "[79]\tvalidation_0-mlogloss:2.95187\n",
            "[80]\tvalidation_0-mlogloss:2.93985\n",
            "[81]\tvalidation_0-mlogloss:2.92778\n",
            "[82]\tvalidation_0-mlogloss:2.91318\n",
            "[83]\tvalidation_0-mlogloss:2.89351\n",
            "[84]\tvalidation_0-mlogloss:2.87377\n",
            "[85]\tvalidation_0-mlogloss:2.86187\n",
            "[86]\tvalidation_0-mlogloss:2.84123\n",
            "[87]\tvalidation_0-mlogloss:2.81020\n",
            "[88]\tvalidation_0-mlogloss:2.79760\n",
            "[89]\tvalidation_0-mlogloss:2.76878\n",
            "[90]\tvalidation_0-mlogloss:2.75594\n",
            "[91]\tvalidation_0-mlogloss:2.72823\n",
            "[92]\tvalidation_0-mlogloss:2.71290\n",
            "[93]\tvalidation_0-mlogloss:2.69220\n",
            "[94]\tvalidation_0-mlogloss:2.66870\n",
            "[95]\tvalidation_0-mlogloss:2.65609\n",
            "[96]\tvalidation_0-mlogloss:2.63889\n",
            "[97]\tvalidation_0-mlogloss:2.62385\n",
            "[98]\tvalidation_0-mlogloss:2.61023\n",
            "[99]\tvalidation_0-mlogloss:2.59629\n",
            "[0]\tvalidation_0-mlogloss:2.17770\n",
            "[1]\tvalidation_0-mlogloss:2.18100\n",
            "[2]\tvalidation_0-mlogloss:2.19755\n",
            "[3]\tvalidation_0-mlogloss:2.22041\n",
            "[4]\tvalidation_0-mlogloss:2.24651\n",
            "[5]\tvalidation_0-mlogloss:2.27999\n",
            "[6]\tvalidation_0-mlogloss:2.31839\n",
            "[7]\tvalidation_0-mlogloss:2.34804\n",
            "[8]\tvalidation_0-mlogloss:2.38008\n",
            "[9]\tvalidation_0-mlogloss:2.40766\n",
            "[10]\tvalidation_0-mlogloss:2.43644\n",
            "[11]\tvalidation_0-mlogloss:2.46619\n",
            "[12]\tvalidation_0-mlogloss:2.49558\n",
            "[13]\tvalidation_0-mlogloss:2.52221\n",
            "[14]\tvalidation_0-mlogloss:2.54617\n",
            "[15]\tvalidation_0-mlogloss:2.56969\n",
            "[16]\tvalidation_0-mlogloss:2.60371\n",
            "[17]\tvalidation_0-mlogloss:2.62746\n",
            "[18]\tvalidation_0-mlogloss:2.65876\n",
            "[19]\tvalidation_0-mlogloss:2.69176\n",
            "[20]\tvalidation_0-mlogloss:2.72272\n",
            "[21]\tvalidation_0-mlogloss:2.75725\n",
            "[22]\tvalidation_0-mlogloss:2.79311\n",
            "[23]\tvalidation_0-mlogloss:2.82865\n",
            "[24]\tvalidation_0-mlogloss:2.86362\n",
            "[25]\tvalidation_0-mlogloss:2.90156\n",
            "[26]\tvalidation_0-mlogloss:2.92377\n",
            "[27]\tvalidation_0-mlogloss:2.95858\n",
            "[28]\tvalidation_0-mlogloss:2.98678\n",
            "[29]\tvalidation_0-mlogloss:3.00178\n",
            "[30]\tvalidation_0-mlogloss:3.02836\n",
            "[31]\tvalidation_0-mlogloss:3.04398\n",
            "[32]\tvalidation_0-mlogloss:3.06684\n",
            "[33]\tvalidation_0-mlogloss:3.08953\n",
            "[34]\tvalidation_0-mlogloss:3.11436\n",
            "[35]\tvalidation_0-mlogloss:3.12873\n",
            "[36]\tvalidation_0-mlogloss:3.14564\n",
            "[37]\tvalidation_0-mlogloss:3.17900\n",
            "[38]\tvalidation_0-mlogloss:3.21778\n",
            "[39]\tvalidation_0-mlogloss:3.24989\n",
            "[40]\tvalidation_0-mlogloss:3.28369\n",
            "[41]\tvalidation_0-mlogloss:3.31554\n",
            "[42]\tvalidation_0-mlogloss:3.34316\n",
            "[43]\tvalidation_0-mlogloss:3.36969\n",
            "[44]\tvalidation_0-mlogloss:3.39920\n",
            "[45]\tvalidation_0-mlogloss:3.42649\n",
            "[46]\tvalidation_0-mlogloss:3.46360\n",
            "[47]\tvalidation_0-mlogloss:3.50081\n",
            "[48]\tvalidation_0-mlogloss:3.52849\n",
            "[49]\tvalidation_0-mlogloss:3.55455\n",
            "[50]\tvalidation_0-mlogloss:3.59469\n",
            "[51]\tvalidation_0-mlogloss:3.61819\n",
            "[52]\tvalidation_0-mlogloss:3.65457\n",
            "[53]\tvalidation_0-mlogloss:3.67655\n",
            "[54]\tvalidation_0-mlogloss:3.70676\n",
            "[55]\tvalidation_0-mlogloss:3.74255\n",
            "[56]\tvalidation_0-mlogloss:3.76797\n",
            "[57]\tvalidation_0-mlogloss:3.78749\n",
            "[58]\tvalidation_0-mlogloss:3.81704\n",
            "[59]\tvalidation_0-mlogloss:3.83950\n",
            "[60]\tvalidation_0-mlogloss:3.84653\n",
            "[61]\tvalidation_0-mlogloss:3.87316\n",
            "[62]\tvalidation_0-mlogloss:3.88731\n",
            "[63]\tvalidation_0-mlogloss:3.90035\n",
            "[64]\tvalidation_0-mlogloss:3.90599\n",
            "[65]\tvalidation_0-mlogloss:3.92140\n",
            "[66]\tvalidation_0-mlogloss:3.92966\n",
            "[67]\tvalidation_0-mlogloss:3.94984\n",
            "[68]\tvalidation_0-mlogloss:3.95442\n",
            "[69]\tvalidation_0-mlogloss:3.96015\n",
            "[70]\tvalidation_0-mlogloss:3.97440\n",
            "[71]\tvalidation_0-mlogloss:3.98030\n",
            "[72]\tvalidation_0-mlogloss:3.99279\n",
            "[73]\tvalidation_0-mlogloss:3.99731\n",
            "[74]\tvalidation_0-mlogloss:4.00750\n",
            "[75]\tvalidation_0-mlogloss:4.01502\n",
            "[76]\tvalidation_0-mlogloss:4.00224\n",
            "[77]\tvalidation_0-mlogloss:3.99505\n",
            "[78]\tvalidation_0-mlogloss:3.98542\n",
            "[79]\tvalidation_0-mlogloss:3.96676\n",
            "[80]\tvalidation_0-mlogloss:3.96263\n",
            "[81]\tvalidation_0-mlogloss:3.96020\n",
            "[82]\tvalidation_0-mlogloss:3.93980\n",
            "[83]\tvalidation_0-mlogloss:3.93415\n",
            "[84]\tvalidation_0-mlogloss:3.92832\n",
            "[85]\tvalidation_0-mlogloss:3.91243\n",
            "[86]\tvalidation_0-mlogloss:3.89177\n",
            "[87]\tvalidation_0-mlogloss:3.87618\n",
            "[88]\tvalidation_0-mlogloss:3.86303\n",
            "[89]\tvalidation_0-mlogloss:3.84802\n",
            "[90]\tvalidation_0-mlogloss:3.82936\n",
            "[91]\tvalidation_0-mlogloss:3.79876\n",
            "[92]\tvalidation_0-mlogloss:3.78599\n",
            "[93]\tvalidation_0-mlogloss:3.76264\n",
            "[94]\tvalidation_0-mlogloss:3.74313\n",
            "[95]\tvalidation_0-mlogloss:3.72744\n",
            "[96]\tvalidation_0-mlogloss:3.71424\n",
            "[97]\tvalidation_0-mlogloss:3.69068\n",
            "[98]\tvalidation_0-mlogloss:3.67878\n",
            "[99]\tvalidation_0-mlogloss:3.65769\n",
            "[0]\tvalidation_0-mlogloss:2.21358\n",
            "[1]\tvalidation_0-mlogloss:2.24370\n",
            "[2]\tvalidation_0-mlogloss:2.27218\n",
            "[3]\tvalidation_0-mlogloss:2.30245\n",
            "[4]\tvalidation_0-mlogloss:2.33706\n",
            "[5]\tvalidation_0-mlogloss:2.37471\n",
            "[6]\tvalidation_0-mlogloss:2.41783\n",
            "[7]\tvalidation_0-mlogloss:2.45526\n",
            "[8]\tvalidation_0-mlogloss:2.49515\n",
            "[9]\tvalidation_0-mlogloss:2.53529\n",
            "[10]\tvalidation_0-mlogloss:2.57749\n",
            "[11]\tvalidation_0-mlogloss:2.62122\n",
            "[12]\tvalidation_0-mlogloss:2.66403\n",
            "[13]\tvalidation_0-mlogloss:2.70800\n",
            "[14]\tvalidation_0-mlogloss:2.75121\n",
            "[15]\tvalidation_0-mlogloss:2.79071\n",
            "[16]\tvalidation_0-mlogloss:2.81172\n",
            "[17]\tvalidation_0-mlogloss:2.83462\n",
            "[18]\tvalidation_0-mlogloss:2.86244\n",
            "[19]\tvalidation_0-mlogloss:2.89103\n",
            "[20]\tvalidation_0-mlogloss:2.91976\n",
            "[21]\tvalidation_0-mlogloss:2.95003\n",
            "[22]\tvalidation_0-mlogloss:2.97858\n",
            "[23]\tvalidation_0-mlogloss:3.00672\n",
            "[24]\tvalidation_0-mlogloss:3.02998\n",
            "[25]\tvalidation_0-mlogloss:3.05366\n",
            "[26]\tvalidation_0-mlogloss:3.07706\n",
            "[27]\tvalidation_0-mlogloss:3.10294\n",
            "[28]\tvalidation_0-mlogloss:3.12887\n",
            "[29]\tvalidation_0-mlogloss:3.14648\n",
            "[30]\tvalidation_0-mlogloss:3.17267\n",
            "[31]\tvalidation_0-mlogloss:3.19735\n",
            "[32]\tvalidation_0-mlogloss:3.21254\n",
            "[33]\tvalidation_0-mlogloss:3.23513\n",
            "[34]\tvalidation_0-mlogloss:3.25116\n",
            "[35]\tvalidation_0-mlogloss:3.26907\n",
            "[36]\tvalidation_0-mlogloss:3.29398\n",
            "[37]\tvalidation_0-mlogloss:3.31367\n",
            "[38]\tvalidation_0-mlogloss:3.33372\n",
            "[39]\tvalidation_0-mlogloss:3.36455\n",
            "[40]\tvalidation_0-mlogloss:3.38631\n",
            "[41]\tvalidation_0-mlogloss:3.41583\n",
            "[42]\tvalidation_0-mlogloss:3.43250\n",
            "[43]\tvalidation_0-mlogloss:3.45472\n",
            "[44]\tvalidation_0-mlogloss:3.48153\n",
            "[45]\tvalidation_0-mlogloss:3.50383\n",
            "[46]\tvalidation_0-mlogloss:3.52556\n",
            "[47]\tvalidation_0-mlogloss:3.54685\n",
            "[48]\tvalidation_0-mlogloss:3.55800\n",
            "[49]\tvalidation_0-mlogloss:3.56594\n",
            "[50]\tvalidation_0-mlogloss:3.58538\n",
            "[51]\tvalidation_0-mlogloss:3.59539\n",
            "[52]\tvalidation_0-mlogloss:3.60016\n",
            "[53]\tvalidation_0-mlogloss:3.60785\n",
            "[54]\tvalidation_0-mlogloss:3.61742\n",
            "[55]\tvalidation_0-mlogloss:3.62656\n",
            "[56]\tvalidation_0-mlogloss:3.63829\n",
            "[57]\tvalidation_0-mlogloss:3.64111\n",
            "[58]\tvalidation_0-mlogloss:3.65026\n",
            "[59]\tvalidation_0-mlogloss:3.65549\n",
            "[60]\tvalidation_0-mlogloss:3.66948\n",
            "[61]\tvalidation_0-mlogloss:3.68229\n",
            "[62]\tvalidation_0-mlogloss:3.68127\n",
            "[63]\tvalidation_0-mlogloss:3.69012\n",
            "[64]\tvalidation_0-mlogloss:3.70373\n",
            "[65]\tvalidation_0-mlogloss:3.70965\n",
            "[66]\tvalidation_0-mlogloss:3.71854\n",
            "[67]\tvalidation_0-mlogloss:3.73116\n",
            "[68]\tvalidation_0-mlogloss:3.73632\n",
            "[69]\tvalidation_0-mlogloss:3.74638\n",
            "[70]\tvalidation_0-mlogloss:3.76082\n",
            "[71]\tvalidation_0-mlogloss:3.77963\n",
            "[72]\tvalidation_0-mlogloss:3.79082\n",
            "[73]\tvalidation_0-mlogloss:3.79648\n",
            "[74]\tvalidation_0-mlogloss:3.81458\n",
            "[75]\tvalidation_0-mlogloss:3.81571\n",
            "[76]\tvalidation_0-mlogloss:3.83138\n",
            "[77]\tvalidation_0-mlogloss:3.82682\n",
            "[78]\tvalidation_0-mlogloss:3.82180\n",
            "[79]\tvalidation_0-mlogloss:3.81619\n",
            "[80]\tvalidation_0-mlogloss:3.81322\n",
            "[81]\tvalidation_0-mlogloss:3.80695\n",
            "[82]\tvalidation_0-mlogloss:3.81240\n",
            "[83]\tvalidation_0-mlogloss:3.80181\n",
            "[84]\tvalidation_0-mlogloss:3.79560\n",
            "[85]\tvalidation_0-mlogloss:3.77682\n",
            "[86]\tvalidation_0-mlogloss:3.77413\n",
            "[87]\tvalidation_0-mlogloss:3.75810\n",
            "[88]\tvalidation_0-mlogloss:3.73865\n",
            "[89]\tvalidation_0-mlogloss:3.72507\n",
            "[90]\tvalidation_0-mlogloss:3.71686\n",
            "[91]\tvalidation_0-mlogloss:3.69887\n",
            "[92]\tvalidation_0-mlogloss:3.68059\n",
            "[93]\tvalidation_0-mlogloss:3.67058\n",
            "[94]\tvalidation_0-mlogloss:3.65824\n",
            "[95]\tvalidation_0-mlogloss:3.64160\n",
            "[96]\tvalidation_0-mlogloss:3.62744\n",
            "[97]\tvalidation_0-mlogloss:3.62188\n",
            "[98]\tvalidation_0-mlogloss:3.60780\n",
            "[99]\tvalidation_0-mlogloss:3.60097\n",
            "[0]\tvalidation_0-mlogloss:2.14591\n",
            "[1]\tvalidation_0-mlogloss:2.17136\n",
            "[2]\tvalidation_0-mlogloss:2.17850\n",
            "[3]\tvalidation_0-mlogloss:2.19424\n",
            "[4]\tvalidation_0-mlogloss:2.19593\n",
            "[5]\tvalidation_0-mlogloss:2.19416\n",
            "[6]\tvalidation_0-mlogloss:2.19412\n",
            "[7]\tvalidation_0-mlogloss:2.19629\n",
            "[8]\tvalidation_0-mlogloss:2.20029\n",
            "[9]\tvalidation_0-mlogloss:2.20665\n",
            "[10]\tvalidation_0-mlogloss:2.21414\n",
            "[11]\tvalidation_0-mlogloss:2.22624\n",
            "[12]\tvalidation_0-mlogloss:2.23393\n",
            "[13]\tvalidation_0-mlogloss:2.24451\n",
            "[14]\tvalidation_0-mlogloss:2.25793\n",
            "[15]\tvalidation_0-mlogloss:2.27126\n",
            "[16]\tvalidation_0-mlogloss:2.28630\n",
            "[17]\tvalidation_0-mlogloss:2.30781\n",
            "[18]\tvalidation_0-mlogloss:2.33034\n",
            "[19]\tvalidation_0-mlogloss:2.35354\n",
            "[20]\tvalidation_0-mlogloss:2.37721\n",
            "[21]\tvalidation_0-mlogloss:2.40337\n",
            "[22]\tvalidation_0-mlogloss:2.42646\n",
            "[23]\tvalidation_0-mlogloss:2.45174\n",
            "[24]\tvalidation_0-mlogloss:2.47363\n",
            "[25]\tvalidation_0-mlogloss:2.49529\n",
            "[26]\tvalidation_0-mlogloss:2.51235\n",
            "[27]\tvalidation_0-mlogloss:2.53563\n",
            "[28]\tvalidation_0-mlogloss:2.55341\n",
            "[29]\tvalidation_0-mlogloss:2.57331\n",
            "[30]\tvalidation_0-mlogloss:2.60000\n",
            "[31]\tvalidation_0-mlogloss:2.61473\n",
            "[32]\tvalidation_0-mlogloss:2.63468\n",
            "[33]\tvalidation_0-mlogloss:2.64983\n",
            "[34]\tvalidation_0-mlogloss:2.66869\n",
            "[35]\tvalidation_0-mlogloss:2.69470\n",
            "[36]\tvalidation_0-mlogloss:2.71610\n",
            "[37]\tvalidation_0-mlogloss:2.73770\n",
            "[38]\tvalidation_0-mlogloss:2.76066\n",
            "[39]\tvalidation_0-mlogloss:2.78092\n",
            "[40]\tvalidation_0-mlogloss:2.80667\n",
            "[41]\tvalidation_0-mlogloss:2.83015\n",
            "[42]\tvalidation_0-mlogloss:2.85022\n",
            "[43]\tvalidation_0-mlogloss:2.87522\n",
            "[44]\tvalidation_0-mlogloss:2.89701\n",
            "[45]\tvalidation_0-mlogloss:2.92223\n",
            "[46]\tvalidation_0-mlogloss:2.94232\n",
            "[47]\tvalidation_0-mlogloss:2.97073\n",
            "[48]\tvalidation_0-mlogloss:2.99523\n",
            "[49]\tvalidation_0-mlogloss:3.02000\n",
            "[50]\tvalidation_0-mlogloss:3.04018\n",
            "[51]\tvalidation_0-mlogloss:3.05979\n",
            "[52]\tvalidation_0-mlogloss:3.07859\n",
            "[53]\tvalidation_0-mlogloss:3.10011\n",
            "[54]\tvalidation_0-mlogloss:3.12178\n",
            "[55]\tvalidation_0-mlogloss:3.12020\n",
            "[56]\tvalidation_0-mlogloss:3.12948\n",
            "[57]\tvalidation_0-mlogloss:3.13287\n",
            "[58]\tvalidation_0-mlogloss:3.13211\n",
            "[59]\tvalidation_0-mlogloss:3.13461\n",
            "[60]\tvalidation_0-mlogloss:3.13608\n",
            "[61]\tvalidation_0-mlogloss:3.14911\n",
            "[62]\tvalidation_0-mlogloss:3.15626\n",
            "[63]\tvalidation_0-mlogloss:3.16860\n",
            "[64]\tvalidation_0-mlogloss:3.17619\n",
            "[65]\tvalidation_0-mlogloss:3.18241\n",
            "[66]\tvalidation_0-mlogloss:3.19176\n",
            "[67]\tvalidation_0-mlogloss:3.19478\n",
            "[68]\tvalidation_0-mlogloss:3.20954\n",
            "[69]\tvalidation_0-mlogloss:3.22188\n",
            "[70]\tvalidation_0-mlogloss:3.23108\n",
            "[71]\tvalidation_0-mlogloss:3.24065\n",
            "[72]\tvalidation_0-mlogloss:3.25204\n",
            "[73]\tvalidation_0-mlogloss:3.25557\n",
            "[74]\tvalidation_0-mlogloss:3.24806\n",
            "[75]\tvalidation_0-mlogloss:3.24810\n",
            "[76]\tvalidation_0-mlogloss:3.24214\n",
            "[77]\tvalidation_0-mlogloss:3.23816\n",
            "[78]\tvalidation_0-mlogloss:3.23192\n",
            "[79]\tvalidation_0-mlogloss:3.23120\n",
            "[80]\tvalidation_0-mlogloss:3.22699\n",
            "[81]\tvalidation_0-mlogloss:3.21778\n",
            "[82]\tvalidation_0-mlogloss:3.19917\n",
            "[83]\tvalidation_0-mlogloss:3.19028\n",
            "[84]\tvalidation_0-mlogloss:3.18385\n",
            "[85]\tvalidation_0-mlogloss:3.16576\n",
            "[86]\tvalidation_0-mlogloss:3.15912\n",
            "[87]\tvalidation_0-mlogloss:3.15403\n",
            "[88]\tvalidation_0-mlogloss:3.15629\n",
            "[89]\tvalidation_0-mlogloss:3.14988\n",
            "[90]\tvalidation_0-mlogloss:3.14016\n",
            "[91]\tvalidation_0-mlogloss:3.12725\n",
            "[92]\tvalidation_0-mlogloss:3.12505\n",
            "[93]\tvalidation_0-mlogloss:3.10601\n",
            "[94]\tvalidation_0-mlogloss:3.09730\n",
            "[95]\tvalidation_0-mlogloss:3.09161\n",
            "[96]\tvalidation_0-mlogloss:3.08386\n",
            "[97]\tvalidation_0-mlogloss:3.07042\n",
            "[98]\tvalidation_0-mlogloss:3.06978\n",
            "[99]\tvalidation_0-mlogloss:3.06090\n",
            "[0]\tvalidation_0-mlogloss:2.14311\n",
            "[1]\tvalidation_0-mlogloss:2.11446\n",
            "[2]\tvalidation_0-mlogloss:2.10564\n",
            "[3]\tvalidation_0-mlogloss:2.10156\n",
            "[4]\tvalidation_0-mlogloss:2.12150\n",
            "[5]\tvalidation_0-mlogloss:2.12697\n",
            "[6]\tvalidation_0-mlogloss:2.14824\n",
            "[7]\tvalidation_0-mlogloss:2.16093\n",
            "[8]\tvalidation_0-mlogloss:2.18717\n",
            "[9]\tvalidation_0-mlogloss:2.20132\n",
            "[10]\tvalidation_0-mlogloss:2.23064\n",
            "[11]\tvalidation_0-mlogloss:2.24210\n",
            "[12]\tvalidation_0-mlogloss:2.25594\n",
            "[13]\tvalidation_0-mlogloss:2.26648\n",
            "[14]\tvalidation_0-mlogloss:2.27752\n",
            "[15]\tvalidation_0-mlogloss:2.29457\n",
            "[16]\tvalidation_0-mlogloss:2.31173\n",
            "[17]\tvalidation_0-mlogloss:2.33752\n",
            "[18]\tvalidation_0-mlogloss:2.34682\n",
            "[19]\tvalidation_0-mlogloss:2.35729\n",
            "[20]\tvalidation_0-mlogloss:2.36856\n",
            "[21]\tvalidation_0-mlogloss:2.38212\n",
            "[22]\tvalidation_0-mlogloss:2.39587\n",
            "[23]\tvalidation_0-mlogloss:2.40910\n",
            "[24]\tvalidation_0-mlogloss:2.42368\n",
            "[25]\tvalidation_0-mlogloss:2.43865\n",
            "[26]\tvalidation_0-mlogloss:2.45911\n",
            "[27]\tvalidation_0-mlogloss:2.47681\n",
            "[28]\tvalidation_0-mlogloss:2.49679\n",
            "[29]\tvalidation_0-mlogloss:2.51593\n",
            "[30]\tvalidation_0-mlogloss:2.53007\n",
            "[31]\tvalidation_0-mlogloss:2.54919\n",
            "[32]\tvalidation_0-mlogloss:2.56326\n",
            "[33]\tvalidation_0-mlogloss:2.58512\n",
            "[34]\tvalidation_0-mlogloss:2.60310\n",
            "[35]\tvalidation_0-mlogloss:2.61776\n",
            "[36]\tvalidation_0-mlogloss:2.63537\n",
            "[37]\tvalidation_0-mlogloss:2.64955\n",
            "[38]\tvalidation_0-mlogloss:2.66040\n",
            "[39]\tvalidation_0-mlogloss:2.64619\n",
            "[40]\tvalidation_0-mlogloss:2.63689\n",
            "[41]\tvalidation_0-mlogloss:2.61973\n",
            "[42]\tvalidation_0-mlogloss:2.61617\n",
            "[43]\tvalidation_0-mlogloss:2.61559\n",
            "[44]\tvalidation_0-mlogloss:2.61272\n",
            "[45]\tvalidation_0-mlogloss:2.60983\n",
            "[46]\tvalidation_0-mlogloss:2.60429\n",
            "[47]\tvalidation_0-mlogloss:2.62620\n",
            "[48]\tvalidation_0-mlogloss:2.62753\n",
            "[49]\tvalidation_0-mlogloss:2.62411\n",
            "[50]\tvalidation_0-mlogloss:2.61195\n",
            "[51]\tvalidation_0-mlogloss:2.60644\n",
            "[52]\tvalidation_0-mlogloss:2.60997\n",
            "[53]\tvalidation_0-mlogloss:2.61535\n",
            "[54]\tvalidation_0-mlogloss:2.62246\n",
            "[55]\tvalidation_0-mlogloss:2.62223\n",
            "[56]\tvalidation_0-mlogloss:2.62157\n",
            "[57]\tvalidation_0-mlogloss:2.61955\n",
            "[58]\tvalidation_0-mlogloss:2.62390\n",
            "[59]\tvalidation_0-mlogloss:2.61718\n",
            "[60]\tvalidation_0-mlogloss:2.62318\n",
            "[61]\tvalidation_0-mlogloss:2.61706\n",
            "[62]\tvalidation_0-mlogloss:2.62235\n",
            "[63]\tvalidation_0-mlogloss:2.62025\n",
            "[64]\tvalidation_0-mlogloss:2.61628\n",
            "[65]\tvalidation_0-mlogloss:2.61448\n",
            "[66]\tvalidation_0-mlogloss:2.60166\n",
            "[67]\tvalidation_0-mlogloss:2.58318\n",
            "[68]\tvalidation_0-mlogloss:2.58124\n",
            "[69]\tvalidation_0-mlogloss:2.56141\n",
            "[70]\tvalidation_0-mlogloss:2.55379\n",
            "[71]\tvalidation_0-mlogloss:2.54449\n",
            "[72]\tvalidation_0-mlogloss:2.53348\n",
            "[73]\tvalidation_0-mlogloss:2.52629\n",
            "[74]\tvalidation_0-mlogloss:2.50054\n",
            "[75]\tvalidation_0-mlogloss:2.49526\n",
            "[76]\tvalidation_0-mlogloss:2.47911\n",
            "[77]\tvalidation_0-mlogloss:2.47385\n",
            "[78]\tvalidation_0-mlogloss:2.45429\n",
            "[79]\tvalidation_0-mlogloss:2.44635\n",
            "[80]\tvalidation_0-mlogloss:2.43572\n",
            "[81]\tvalidation_0-mlogloss:2.42656\n",
            "[82]\tvalidation_0-mlogloss:2.41183\n",
            "[83]\tvalidation_0-mlogloss:2.39924\n",
            "[84]\tvalidation_0-mlogloss:2.39218\n",
            "[85]\tvalidation_0-mlogloss:2.38613\n",
            "[86]\tvalidation_0-mlogloss:2.37149\n",
            "[87]\tvalidation_0-mlogloss:2.36858\n",
            "[88]\tvalidation_0-mlogloss:2.36030\n",
            "[89]\tvalidation_0-mlogloss:2.35160\n",
            "[90]\tvalidation_0-mlogloss:2.34562\n",
            "[91]\tvalidation_0-mlogloss:2.33792\n",
            "[92]\tvalidation_0-mlogloss:2.32496\n",
            "[93]\tvalidation_0-mlogloss:2.32077\n",
            "[94]\tvalidation_0-mlogloss:2.31741\n",
            "[95]\tvalidation_0-mlogloss:2.31743\n",
            "[96]\tvalidation_0-mlogloss:2.31234\n",
            "[97]\tvalidation_0-mlogloss:2.30906\n",
            "[98]\tvalidation_0-mlogloss:2.30605\n",
            "[99]\tvalidation_0-mlogloss:2.30695\n",
            "[0]\tvalidation_0-mlogloss:2.17038\n",
            "[1]\tvalidation_0-mlogloss:2.18626\n",
            "[2]\tvalidation_0-mlogloss:2.20164\n",
            "[3]\tvalidation_0-mlogloss:2.20493\n",
            "[4]\tvalidation_0-mlogloss:2.21013\n",
            "[5]\tvalidation_0-mlogloss:2.21437\n",
            "[6]\tvalidation_0-mlogloss:2.22114\n",
            "[7]\tvalidation_0-mlogloss:2.22885\n",
            "[8]\tvalidation_0-mlogloss:2.23561\n",
            "[9]\tvalidation_0-mlogloss:2.24381\n",
            "[10]\tvalidation_0-mlogloss:2.25277\n",
            "[11]\tvalidation_0-mlogloss:2.25886\n",
            "[12]\tvalidation_0-mlogloss:2.26734\n",
            "[13]\tvalidation_0-mlogloss:2.27612\n",
            "[14]\tvalidation_0-mlogloss:2.28639\n",
            "[15]\tvalidation_0-mlogloss:2.29693\n",
            "[16]\tvalidation_0-mlogloss:2.30727\n",
            "[17]\tvalidation_0-mlogloss:2.31271\n",
            "[18]\tvalidation_0-mlogloss:2.32383\n",
            "[19]\tvalidation_0-mlogloss:2.33675\n",
            "[20]\tvalidation_0-mlogloss:2.34772\n",
            "[21]\tvalidation_0-mlogloss:2.36032\n",
            "[22]\tvalidation_0-mlogloss:2.36783\n",
            "[23]\tvalidation_0-mlogloss:2.38294\n",
            "[24]\tvalidation_0-mlogloss:2.39418\n",
            "[25]\tvalidation_0-mlogloss:2.40433\n",
            "[26]\tvalidation_0-mlogloss:2.41317\n",
            "[27]\tvalidation_0-mlogloss:2.42732\n",
            "[28]\tvalidation_0-mlogloss:2.43617\n",
            "[29]\tvalidation_0-mlogloss:2.44530\n",
            "[30]\tvalidation_0-mlogloss:2.45607\n",
            "[31]\tvalidation_0-mlogloss:2.45049\n",
            "[32]\tvalidation_0-mlogloss:2.45151\n",
            "[33]\tvalidation_0-mlogloss:2.45846\n",
            "[34]\tvalidation_0-mlogloss:2.45911\n",
            "[35]\tvalidation_0-mlogloss:2.46961\n",
            "[36]\tvalidation_0-mlogloss:2.47213\n",
            "[37]\tvalidation_0-mlogloss:2.47407\n",
            "[38]\tvalidation_0-mlogloss:2.48305\n",
            "[39]\tvalidation_0-mlogloss:2.50136\n",
            "[40]\tvalidation_0-mlogloss:2.51133\n",
            "[41]\tvalidation_0-mlogloss:2.52411\n",
            "[42]\tvalidation_0-mlogloss:2.54036\n",
            "[43]\tvalidation_0-mlogloss:2.55575\n",
            "[44]\tvalidation_0-mlogloss:2.56408\n",
            "[45]\tvalidation_0-mlogloss:2.58051\n",
            "[46]\tvalidation_0-mlogloss:2.58992\n",
            "[47]\tvalidation_0-mlogloss:2.60468\n",
            "[48]\tvalidation_0-mlogloss:2.59586\n",
            "[49]\tvalidation_0-mlogloss:2.60667\n",
            "[50]\tvalidation_0-mlogloss:2.59752\n",
            "[51]\tvalidation_0-mlogloss:2.59322\n",
            "[52]\tvalidation_0-mlogloss:2.58810\n",
            "[53]\tvalidation_0-mlogloss:2.57476\n",
            "[54]\tvalidation_0-mlogloss:2.55638\n",
            "[55]\tvalidation_0-mlogloss:2.56859\n",
            "[56]\tvalidation_0-mlogloss:2.55379\n",
            "[57]\tvalidation_0-mlogloss:2.53981\n",
            "[58]\tvalidation_0-mlogloss:2.52366\n",
            "[59]\tvalidation_0-mlogloss:2.51403\n",
            "[60]\tvalidation_0-mlogloss:2.52269\n",
            "[61]\tvalidation_0-mlogloss:2.49677\n",
            "[62]\tvalidation_0-mlogloss:2.50539\n",
            "[63]\tvalidation_0-mlogloss:2.48127\n",
            "[64]\tvalidation_0-mlogloss:2.47271\n",
            "[65]\tvalidation_0-mlogloss:2.45026\n",
            "[66]\tvalidation_0-mlogloss:2.43609\n",
            "[67]\tvalidation_0-mlogloss:2.41503\n",
            "[68]\tvalidation_0-mlogloss:2.42091\n",
            "[69]\tvalidation_0-mlogloss:2.40192\n",
            "[70]\tvalidation_0-mlogloss:2.36799\n",
            "[71]\tvalidation_0-mlogloss:2.35549\n",
            "[72]\tvalidation_0-mlogloss:2.34815\n",
            "[73]\tvalidation_0-mlogloss:2.33655\n",
            "[74]\tvalidation_0-mlogloss:2.32134\n",
            "[75]\tvalidation_0-mlogloss:2.31057\n",
            "[76]\tvalidation_0-mlogloss:2.29494\n",
            "[77]\tvalidation_0-mlogloss:2.29639\n",
            "[78]\tvalidation_0-mlogloss:2.27329\n",
            "[79]\tvalidation_0-mlogloss:2.25567\n",
            "[80]\tvalidation_0-mlogloss:2.25560\n",
            "[81]\tvalidation_0-mlogloss:2.25408\n",
            "[82]\tvalidation_0-mlogloss:2.24040\n",
            "[83]\tvalidation_0-mlogloss:2.23362\n",
            "[84]\tvalidation_0-mlogloss:2.22222\n",
            "[85]\tvalidation_0-mlogloss:2.21619\n",
            "[86]\tvalidation_0-mlogloss:2.20186\n",
            "[87]\tvalidation_0-mlogloss:2.20597\n",
            "[88]\tvalidation_0-mlogloss:2.19386\n",
            "[89]\tvalidation_0-mlogloss:2.18981\n",
            "[90]\tvalidation_0-mlogloss:2.18228\n",
            "[91]\tvalidation_0-mlogloss:2.16744\n",
            "[92]\tvalidation_0-mlogloss:2.15275\n",
            "[93]\tvalidation_0-mlogloss:2.15428\n",
            "[94]\tvalidation_0-mlogloss:2.13638\n",
            "[95]\tvalidation_0-mlogloss:2.13988\n",
            "[96]\tvalidation_0-mlogloss:2.12933\n",
            "[97]\tvalidation_0-mlogloss:2.11902\n",
            "[98]\tvalidation_0-mlogloss:2.11322\n",
            "[99]\tvalidation_0-mlogloss:2.10785\n",
            "[0]\tvalidation_0-mlogloss:2.15096\n",
            "[1]\tvalidation_0-mlogloss:2.17510\n",
            "[2]\tvalidation_0-mlogloss:2.19933\n",
            "[3]\tvalidation_0-mlogloss:2.22739\n",
            "[4]\tvalidation_0-mlogloss:2.25829\n",
            "[5]\tvalidation_0-mlogloss:2.28840\n",
            "[6]\tvalidation_0-mlogloss:2.32727\n",
            "[7]\tvalidation_0-mlogloss:2.36698\n",
            "[8]\tvalidation_0-mlogloss:2.40333\n",
            "[9]\tvalidation_0-mlogloss:2.44134\n",
            "[10]\tvalidation_0-mlogloss:2.48119\n",
            "[11]\tvalidation_0-mlogloss:2.52240\n",
            "[12]\tvalidation_0-mlogloss:2.54772\n",
            "[13]\tvalidation_0-mlogloss:2.59169\n",
            "[14]\tvalidation_0-mlogloss:2.63525\n",
            "[15]\tvalidation_0-mlogloss:2.66605\n",
            "[16]\tvalidation_0-mlogloss:2.70136\n",
            "[17]\tvalidation_0-mlogloss:2.72315\n",
            "[18]\tvalidation_0-mlogloss:2.74534\n",
            "[19]\tvalidation_0-mlogloss:2.77639\n",
            "[20]\tvalidation_0-mlogloss:2.81006\n",
            "[21]\tvalidation_0-mlogloss:2.84510\n",
            "[22]\tvalidation_0-mlogloss:2.87406\n",
            "[23]\tvalidation_0-mlogloss:2.90704\n",
            "[24]\tvalidation_0-mlogloss:2.94233\n",
            "[25]\tvalidation_0-mlogloss:2.96699\n",
            "[26]\tvalidation_0-mlogloss:2.99696\n",
            "[27]\tvalidation_0-mlogloss:3.02642\n",
            "[28]\tvalidation_0-mlogloss:3.05824\n",
            "[29]\tvalidation_0-mlogloss:3.08946\n",
            "[30]\tvalidation_0-mlogloss:3.12551\n",
            "[31]\tvalidation_0-mlogloss:3.15673\n",
            "[32]\tvalidation_0-mlogloss:3.18829\n",
            "[33]\tvalidation_0-mlogloss:3.21757\n",
            "[34]\tvalidation_0-mlogloss:3.25429\n",
            "[35]\tvalidation_0-mlogloss:3.29101\n",
            "[36]\tvalidation_0-mlogloss:3.31516\n",
            "[37]\tvalidation_0-mlogloss:3.34495\n",
            "[38]\tvalidation_0-mlogloss:3.36987\n",
            "[39]\tvalidation_0-mlogloss:3.39770\n",
            "[40]\tvalidation_0-mlogloss:3.42506\n",
            "[41]\tvalidation_0-mlogloss:3.45904\n",
            "[42]\tvalidation_0-mlogloss:3.48662\n",
            "[43]\tvalidation_0-mlogloss:3.50095\n",
            "[44]\tvalidation_0-mlogloss:3.51429\n",
            "[45]\tvalidation_0-mlogloss:3.52551\n",
            "[46]\tvalidation_0-mlogloss:3.55289\n",
            "[47]\tvalidation_0-mlogloss:3.56884\n",
            "[48]\tvalidation_0-mlogloss:3.58383\n",
            "[49]\tvalidation_0-mlogloss:3.59892\n",
            "[50]\tvalidation_0-mlogloss:3.63063\n",
            "[51]\tvalidation_0-mlogloss:3.64179\n",
            "[52]\tvalidation_0-mlogloss:3.65579\n",
            "[53]\tvalidation_0-mlogloss:3.68198\n",
            "[54]\tvalidation_0-mlogloss:3.68389\n",
            "[55]\tvalidation_0-mlogloss:3.70132\n",
            "[56]\tvalidation_0-mlogloss:3.70499\n",
            "[57]\tvalidation_0-mlogloss:3.71702\n",
            "[58]\tvalidation_0-mlogloss:3.74011\n",
            "[59]\tvalidation_0-mlogloss:3.74677\n",
            "[60]\tvalidation_0-mlogloss:3.76695\n",
            "[61]\tvalidation_0-mlogloss:3.77442\n",
            "[62]\tvalidation_0-mlogloss:3.77671\n",
            "[63]\tvalidation_0-mlogloss:3.79719\n",
            "[64]\tvalidation_0-mlogloss:3.81599\n",
            "[65]\tvalidation_0-mlogloss:3.81564\n",
            "[66]\tvalidation_0-mlogloss:3.83049\n",
            "[67]\tvalidation_0-mlogloss:3.83207\n",
            "[68]\tvalidation_0-mlogloss:3.85221\n",
            "[69]\tvalidation_0-mlogloss:3.84686\n",
            "[70]\tvalidation_0-mlogloss:3.84907\n",
            "[71]\tvalidation_0-mlogloss:3.86890\n",
            "[72]\tvalidation_0-mlogloss:3.86494\n",
            "[73]\tvalidation_0-mlogloss:3.87067\n",
            "[74]\tvalidation_0-mlogloss:3.86934\n",
            "[75]\tvalidation_0-mlogloss:3.86939\n",
            "[76]\tvalidation_0-mlogloss:3.88550\n",
            "[77]\tvalidation_0-mlogloss:3.88360\n",
            "[78]\tvalidation_0-mlogloss:3.88057\n",
            "[79]\tvalidation_0-mlogloss:3.86877\n",
            "[80]\tvalidation_0-mlogloss:3.87165\n",
            "[81]\tvalidation_0-mlogloss:3.86433\n",
            "[82]\tvalidation_0-mlogloss:3.86721\n",
            "[83]\tvalidation_0-mlogloss:3.87443\n",
            "[84]\tvalidation_0-mlogloss:3.87086\n",
            "[85]\tvalidation_0-mlogloss:3.87456\n",
            "[86]\tvalidation_0-mlogloss:3.86785\n",
            "[87]\tvalidation_0-mlogloss:3.86875\n",
            "[88]\tvalidation_0-mlogloss:3.87640\n",
            "[89]\tvalidation_0-mlogloss:3.86651\n",
            "[90]\tvalidation_0-mlogloss:3.86929\n",
            "[91]\tvalidation_0-mlogloss:3.86992\n",
            "[92]\tvalidation_0-mlogloss:3.86667\n",
            "[93]\tvalidation_0-mlogloss:3.86815\n",
            "[94]\tvalidation_0-mlogloss:3.86644\n",
            "[95]\tvalidation_0-mlogloss:3.86927\n",
            "[96]\tvalidation_0-mlogloss:3.86457\n",
            "[97]\tvalidation_0-mlogloss:3.86735\n",
            "[98]\tvalidation_0-mlogloss:3.86177\n",
            "[99]\tvalidation_0-mlogloss:3.86499\n",
            "[0]\tvalidation_0-mlogloss:2.14569\n",
            "[1]\tvalidation_0-mlogloss:2.12703\n",
            "[2]\tvalidation_0-mlogloss:2.13176\n",
            "[3]\tvalidation_0-mlogloss:2.12965\n",
            "[4]\tvalidation_0-mlogloss:2.12522\n",
            "[5]\tvalidation_0-mlogloss:2.12410\n",
            "[6]\tvalidation_0-mlogloss:2.12228\n",
            "[7]\tvalidation_0-mlogloss:2.11564\n",
            "[8]\tvalidation_0-mlogloss:2.12159\n",
            "[9]\tvalidation_0-mlogloss:2.12761\n",
            "[10]\tvalidation_0-mlogloss:2.14014\n",
            "[11]\tvalidation_0-mlogloss:2.13843\n",
            "[12]\tvalidation_0-mlogloss:2.13850\n",
            "[13]\tvalidation_0-mlogloss:2.13795\n",
            "[14]\tvalidation_0-mlogloss:2.13846\n",
            "[15]\tvalidation_0-mlogloss:2.14280\n",
            "[16]\tvalidation_0-mlogloss:2.14578\n",
            "[17]\tvalidation_0-mlogloss:2.14995\n",
            "[18]\tvalidation_0-mlogloss:2.15609\n",
            "[19]\tvalidation_0-mlogloss:2.15756\n",
            "[20]\tvalidation_0-mlogloss:2.16218\n",
            "[21]\tvalidation_0-mlogloss:2.17057\n",
            "[22]\tvalidation_0-mlogloss:2.17569\n",
            "[23]\tvalidation_0-mlogloss:2.18253\n",
            "[24]\tvalidation_0-mlogloss:2.19222\n",
            "[25]\tvalidation_0-mlogloss:2.20066\n",
            "[26]\tvalidation_0-mlogloss:2.21549\n",
            "[27]\tvalidation_0-mlogloss:2.22868\n",
            "[28]\tvalidation_0-mlogloss:2.24228\n",
            "[29]\tvalidation_0-mlogloss:2.26047\n",
            "[30]\tvalidation_0-mlogloss:2.27673\n",
            "[31]\tvalidation_0-mlogloss:2.28894\n",
            "[32]\tvalidation_0-mlogloss:2.29742\n",
            "[33]\tvalidation_0-mlogloss:2.31488\n",
            "[34]\tvalidation_0-mlogloss:2.32554\n",
            "[35]\tvalidation_0-mlogloss:2.34261\n",
            "[36]\tvalidation_0-mlogloss:2.36027\n",
            "[37]\tvalidation_0-mlogloss:2.37277\n",
            "[38]\tvalidation_0-mlogloss:2.39130\n",
            "[39]\tvalidation_0-mlogloss:2.40605\n",
            "[40]\tvalidation_0-mlogloss:2.42822\n",
            "[41]\tvalidation_0-mlogloss:2.41992\n",
            "[42]\tvalidation_0-mlogloss:2.40986\n",
            "[43]\tvalidation_0-mlogloss:2.39973\n",
            "[44]\tvalidation_0-mlogloss:2.41234\n",
            "[45]\tvalidation_0-mlogloss:2.39954\n",
            "[46]\tvalidation_0-mlogloss:2.39076\n",
            "[47]\tvalidation_0-mlogloss:2.40787\n",
            "[48]\tvalidation_0-mlogloss:2.39995\n",
            "[49]\tvalidation_0-mlogloss:2.39544\n",
            "[50]\tvalidation_0-mlogloss:2.41073\n",
            "[51]\tvalidation_0-mlogloss:2.40752\n",
            "[52]\tvalidation_0-mlogloss:2.40221\n",
            "[53]\tvalidation_0-mlogloss:2.39563\n",
            "[54]\tvalidation_0-mlogloss:2.39391\n",
            "[55]\tvalidation_0-mlogloss:2.39388\n",
            "[56]\tvalidation_0-mlogloss:2.38783\n",
            "[57]\tvalidation_0-mlogloss:2.39116\n",
            "[58]\tvalidation_0-mlogloss:2.38449\n",
            "[59]\tvalidation_0-mlogloss:2.37939\n",
            "[60]\tvalidation_0-mlogloss:2.37846\n",
            "[61]\tvalidation_0-mlogloss:2.36416\n",
            "[62]\tvalidation_0-mlogloss:2.35880\n",
            "[63]\tvalidation_0-mlogloss:2.34740\n",
            "[64]\tvalidation_0-mlogloss:2.34687\n",
            "[65]\tvalidation_0-mlogloss:2.33469\n",
            "[66]\tvalidation_0-mlogloss:2.33013\n",
            "[67]\tvalidation_0-mlogloss:2.32354\n",
            "[68]\tvalidation_0-mlogloss:2.32685\n",
            "[69]\tvalidation_0-mlogloss:2.32061\n",
            "[70]\tvalidation_0-mlogloss:2.32187\n",
            "[71]\tvalidation_0-mlogloss:2.31424\n",
            "[72]\tvalidation_0-mlogloss:2.32030\n",
            "[73]\tvalidation_0-mlogloss:2.30516\n",
            "[74]\tvalidation_0-mlogloss:2.29636\n",
            "[75]\tvalidation_0-mlogloss:2.29937\n",
            "[76]\tvalidation_0-mlogloss:2.28948\n",
            "[77]\tvalidation_0-mlogloss:2.29174\n",
            "[78]\tvalidation_0-mlogloss:2.29162\n",
            "[79]\tvalidation_0-mlogloss:2.29035\n",
            "[80]\tvalidation_0-mlogloss:2.29301\n",
            "[81]\tvalidation_0-mlogloss:2.29426\n",
            "[82]\tvalidation_0-mlogloss:2.28375\n",
            "[83]\tvalidation_0-mlogloss:2.29172\n",
            "[84]\tvalidation_0-mlogloss:2.29545\n",
            "[85]\tvalidation_0-mlogloss:2.30391\n",
            "[86]\tvalidation_0-mlogloss:2.29803\n",
            "[87]\tvalidation_0-mlogloss:2.30658\n",
            "[88]\tvalidation_0-mlogloss:2.29770\n",
            "[89]\tvalidation_0-mlogloss:2.30471\n",
            "[90]\tvalidation_0-mlogloss:2.29303\n",
            "[91]\tvalidation_0-mlogloss:2.29438\n",
            "[92]\tvalidation_0-mlogloss:2.29764\n",
            "[93]\tvalidation_0-mlogloss:2.28816\n",
            "[94]\tvalidation_0-mlogloss:2.28889\n",
            "[95]\tvalidation_0-mlogloss:2.28695\n",
            "[96]\tvalidation_0-mlogloss:2.28854\n",
            "[97]\tvalidation_0-mlogloss:2.29187\n",
            "[98]\tvalidation_0-mlogloss:2.28899\n",
            "[99]\tvalidation_0-mlogloss:2.29722\n",
            "[0]\tvalidation_0-mlogloss:2.19374\n",
            "[1]\tvalidation_0-mlogloss:2.20872\n",
            "[2]\tvalidation_0-mlogloss:2.22540\n",
            "[3]\tvalidation_0-mlogloss:2.23342\n",
            "[4]\tvalidation_0-mlogloss:2.24203\n",
            "[5]\tvalidation_0-mlogloss:2.25409\n",
            "[6]\tvalidation_0-mlogloss:2.27099\n",
            "[7]\tvalidation_0-mlogloss:2.28967\n",
            "[8]\tvalidation_0-mlogloss:2.30349\n",
            "[9]\tvalidation_0-mlogloss:2.32209\n",
            "[10]\tvalidation_0-mlogloss:2.33395\n",
            "[11]\tvalidation_0-mlogloss:2.34372\n",
            "[12]\tvalidation_0-mlogloss:2.35612\n",
            "[13]\tvalidation_0-mlogloss:2.37103\n",
            "[14]\tvalidation_0-mlogloss:2.37734\n",
            "[15]\tvalidation_0-mlogloss:2.39098\n",
            "[16]\tvalidation_0-mlogloss:2.40024\n",
            "[17]\tvalidation_0-mlogloss:2.41480\n",
            "[18]\tvalidation_0-mlogloss:2.42489\n",
            "[19]\tvalidation_0-mlogloss:2.43582\n",
            "[20]\tvalidation_0-mlogloss:2.44938\n",
            "[21]\tvalidation_0-mlogloss:2.45748\n",
            "[22]\tvalidation_0-mlogloss:2.47174\n",
            "[23]\tvalidation_0-mlogloss:2.48605\n",
            "[24]\tvalidation_0-mlogloss:2.49802\n",
            "[25]\tvalidation_0-mlogloss:2.51513\n",
            "[26]\tvalidation_0-mlogloss:2.52521\n",
            "[27]\tvalidation_0-mlogloss:2.55078\n",
            "[28]\tvalidation_0-mlogloss:2.57424\n",
            "[29]\tvalidation_0-mlogloss:2.59007\n",
            "[30]\tvalidation_0-mlogloss:2.61450\n",
            "[31]\tvalidation_0-mlogloss:2.62906\n",
            "[32]\tvalidation_0-mlogloss:2.65681\n",
            "[33]\tvalidation_0-mlogloss:2.68142\n",
            "[34]\tvalidation_0-mlogloss:2.71114\n",
            "[35]\tvalidation_0-mlogloss:2.73488\n",
            "[36]\tvalidation_0-mlogloss:2.75395\n",
            "[37]\tvalidation_0-mlogloss:2.77980\n",
            "[38]\tvalidation_0-mlogloss:2.80260\n",
            "[39]\tvalidation_0-mlogloss:2.83300\n",
            "[40]\tvalidation_0-mlogloss:2.85198\n",
            "[41]\tvalidation_0-mlogloss:2.88563\n",
            "[42]\tvalidation_0-mlogloss:2.90420\n",
            "[43]\tvalidation_0-mlogloss:2.92479\n",
            "[44]\tvalidation_0-mlogloss:2.94910\n",
            "[45]\tvalidation_0-mlogloss:2.95660\n",
            "[46]\tvalidation_0-mlogloss:2.97253\n",
            "[47]\tvalidation_0-mlogloss:2.99348\n",
            "[48]\tvalidation_0-mlogloss:3.00438\n",
            "[49]\tvalidation_0-mlogloss:3.01722\n",
            "[50]\tvalidation_0-mlogloss:3.03330\n",
            "[51]\tvalidation_0-mlogloss:3.05521\n",
            "[52]\tvalidation_0-mlogloss:3.06994\n",
            "[53]\tvalidation_0-mlogloss:3.05756\n",
            "[54]\tvalidation_0-mlogloss:3.05790\n",
            "[55]\tvalidation_0-mlogloss:3.03813\n",
            "[56]\tvalidation_0-mlogloss:3.05979\n",
            "[57]\tvalidation_0-mlogloss:3.03792\n",
            "[58]\tvalidation_0-mlogloss:3.03142\n",
            "[59]\tvalidation_0-mlogloss:3.04648\n",
            "[60]\tvalidation_0-mlogloss:3.04194\n",
            "[61]\tvalidation_0-mlogloss:3.02246\n",
            "[62]\tvalidation_0-mlogloss:3.01362\n",
            "[63]\tvalidation_0-mlogloss:3.02460\n",
            "[64]\tvalidation_0-mlogloss:3.03851\n",
            "[65]\tvalidation_0-mlogloss:3.02543\n",
            "[66]\tvalidation_0-mlogloss:3.04151\n",
            "[67]\tvalidation_0-mlogloss:3.03181\n",
            "[68]\tvalidation_0-mlogloss:3.05454\n",
            "[69]\tvalidation_0-mlogloss:3.04015\n",
            "[70]\tvalidation_0-mlogloss:3.05329\n",
            "[71]\tvalidation_0-mlogloss:3.07669\n",
            "[72]\tvalidation_0-mlogloss:3.07363\n",
            "[73]\tvalidation_0-mlogloss:3.06125\n",
            "[74]\tvalidation_0-mlogloss:3.04618\n",
            "[75]\tvalidation_0-mlogloss:3.03401\n",
            "[76]\tvalidation_0-mlogloss:3.01513\n",
            "[77]\tvalidation_0-mlogloss:3.00336\n",
            "[78]\tvalidation_0-mlogloss:2.99579\n",
            "[79]\tvalidation_0-mlogloss:2.97251\n",
            "[80]\tvalidation_0-mlogloss:2.95947\n",
            "[81]\tvalidation_0-mlogloss:2.94684\n",
            "[82]\tvalidation_0-mlogloss:2.93016\n",
            "[83]\tvalidation_0-mlogloss:2.92256\n",
            "[84]\tvalidation_0-mlogloss:2.91373\n",
            "[85]\tvalidation_0-mlogloss:2.89673\n",
            "[86]\tvalidation_0-mlogloss:2.89000\n",
            "[87]\tvalidation_0-mlogloss:2.87608\n",
            "[88]\tvalidation_0-mlogloss:2.85792\n",
            "[89]\tvalidation_0-mlogloss:2.85926\n",
            "[90]\tvalidation_0-mlogloss:2.84166\n",
            "[91]\tvalidation_0-mlogloss:2.82439\n",
            "[92]\tvalidation_0-mlogloss:2.81736\n",
            "[93]\tvalidation_0-mlogloss:2.80961\n",
            "[94]\tvalidation_0-mlogloss:2.80167\n",
            "[95]\tvalidation_0-mlogloss:2.78519\n",
            "[96]\tvalidation_0-mlogloss:2.77486\n",
            "[97]\tvalidation_0-mlogloss:2.76340\n",
            "[98]\tvalidation_0-mlogloss:2.75399\n",
            "[99]\tvalidation_0-mlogloss:2.73947\n",
            "[0]\tvalidation_0-mlogloss:2.18815\n",
            "[1]\tvalidation_0-mlogloss:2.21253\n",
            "[2]\tvalidation_0-mlogloss:2.24468\n",
            "[3]\tvalidation_0-mlogloss:2.27130\n",
            "[4]\tvalidation_0-mlogloss:2.29190\n",
            "[5]\tvalidation_0-mlogloss:2.31666\n",
            "[6]\tvalidation_0-mlogloss:2.33549\n",
            "[7]\tvalidation_0-mlogloss:2.35537\n",
            "[8]\tvalidation_0-mlogloss:2.37737\n",
            "[9]\tvalidation_0-mlogloss:2.40225\n",
            "[10]\tvalidation_0-mlogloss:2.41321\n",
            "[11]\tvalidation_0-mlogloss:2.41994\n",
            "[12]\tvalidation_0-mlogloss:2.44066\n",
            "[13]\tvalidation_0-mlogloss:2.45081\n",
            "[14]\tvalidation_0-mlogloss:2.46561\n",
            "[15]\tvalidation_0-mlogloss:2.49762\n",
            "[16]\tvalidation_0-mlogloss:2.50534\n",
            "[17]\tvalidation_0-mlogloss:2.52249\n",
            "[18]\tvalidation_0-mlogloss:2.55262\n",
            "[19]\tvalidation_0-mlogloss:2.57358\n",
            "[20]\tvalidation_0-mlogloss:2.58143\n",
            "[21]\tvalidation_0-mlogloss:2.61293\n",
            "[22]\tvalidation_0-mlogloss:2.63330\n",
            "[23]\tvalidation_0-mlogloss:2.64660\n",
            "[24]\tvalidation_0-mlogloss:2.66274\n",
            "[25]\tvalidation_0-mlogloss:2.67722\n",
            "[26]\tvalidation_0-mlogloss:2.69054\n",
            "[27]\tvalidation_0-mlogloss:2.69898\n",
            "[28]\tvalidation_0-mlogloss:2.70785\n",
            "[29]\tvalidation_0-mlogloss:2.72731\n",
            "[30]\tvalidation_0-mlogloss:2.74745\n",
            "[31]\tvalidation_0-mlogloss:2.75182\n",
            "[32]\tvalidation_0-mlogloss:2.76310\n",
            "[33]\tvalidation_0-mlogloss:2.77747\n",
            "[34]\tvalidation_0-mlogloss:2.77861\n",
            "[35]\tvalidation_0-mlogloss:2.79948\n",
            "[36]\tvalidation_0-mlogloss:2.80083\n",
            "[37]\tvalidation_0-mlogloss:2.82429\n",
            "[38]\tvalidation_0-mlogloss:2.83301\n",
            "[39]\tvalidation_0-mlogloss:2.85638\n",
            "[40]\tvalidation_0-mlogloss:2.86565\n",
            "[41]\tvalidation_0-mlogloss:2.88086\n",
            "[42]\tvalidation_0-mlogloss:2.89270\n",
            "[43]\tvalidation_0-mlogloss:2.90851\n",
            "[44]\tvalidation_0-mlogloss:2.92388\n",
            "[45]\tvalidation_0-mlogloss:2.93346\n",
            "[46]\tvalidation_0-mlogloss:2.94189\n",
            "[47]\tvalidation_0-mlogloss:2.94947\n",
            "[48]\tvalidation_0-mlogloss:2.95910\n",
            "[49]\tvalidation_0-mlogloss:2.96692\n",
            "[50]\tvalidation_0-mlogloss:2.97676\n",
            "[51]\tvalidation_0-mlogloss:2.99620\n",
            "[52]\tvalidation_0-mlogloss:3.01320\n",
            "[53]\tvalidation_0-mlogloss:3.03022\n",
            "[54]\tvalidation_0-mlogloss:3.04825\n",
            "[55]\tvalidation_0-mlogloss:3.05663\n",
            "[56]\tvalidation_0-mlogloss:3.07519\n",
            "[57]\tvalidation_0-mlogloss:3.09552\n",
            "[58]\tvalidation_0-mlogloss:3.11197\n",
            "[59]\tvalidation_0-mlogloss:3.12041\n",
            "[60]\tvalidation_0-mlogloss:3.14484\n",
            "[61]\tvalidation_0-mlogloss:3.12950\n",
            "[62]\tvalidation_0-mlogloss:3.15406\n",
            "[63]\tvalidation_0-mlogloss:3.13571\n",
            "[64]\tvalidation_0-mlogloss:3.14850\n",
            "[65]\tvalidation_0-mlogloss:3.15188\n",
            "[66]\tvalidation_0-mlogloss:3.17073\n",
            "[67]\tvalidation_0-mlogloss:3.19070\n",
            "[68]\tvalidation_0-mlogloss:3.20275\n",
            "[69]\tvalidation_0-mlogloss:3.21683\n",
            "[70]\tvalidation_0-mlogloss:3.20469\n",
            "[71]\tvalidation_0-mlogloss:3.22327\n",
            "[72]\tvalidation_0-mlogloss:3.21540\n",
            "[73]\tvalidation_0-mlogloss:3.20305\n",
            "[74]\tvalidation_0-mlogloss:3.19346\n",
            "[75]\tvalidation_0-mlogloss:3.18197\n",
            "[76]\tvalidation_0-mlogloss:3.15415\n",
            "[77]\tvalidation_0-mlogloss:3.14227\n",
            "[78]\tvalidation_0-mlogloss:3.12396\n",
            "[79]\tvalidation_0-mlogloss:3.09239\n",
            "[80]\tvalidation_0-mlogloss:3.08285\n",
            "[81]\tvalidation_0-mlogloss:3.05922\n",
            "[82]\tvalidation_0-mlogloss:3.04137\n",
            "[83]\tvalidation_0-mlogloss:3.01198\n",
            "[84]\tvalidation_0-mlogloss:2.99618\n",
            "[85]\tvalidation_0-mlogloss:2.98407\n",
            "[86]\tvalidation_0-mlogloss:2.96299\n",
            "[87]\tvalidation_0-mlogloss:2.93187\n",
            "[88]\tvalidation_0-mlogloss:2.91654\n",
            "[89]\tvalidation_0-mlogloss:2.90336\n",
            "[90]\tvalidation_0-mlogloss:2.87726\n",
            "[91]\tvalidation_0-mlogloss:2.85534\n",
            "[92]\tvalidation_0-mlogloss:2.84673\n",
            "[93]\tvalidation_0-mlogloss:2.83121\n",
            "[94]\tvalidation_0-mlogloss:2.81558\n",
            "[95]\tvalidation_0-mlogloss:2.80579\n",
            "[96]\tvalidation_0-mlogloss:2.79147\n",
            "[97]\tvalidation_0-mlogloss:2.78173\n",
            "[98]\tvalidation_0-mlogloss:2.76923\n",
            "[99]\tvalidation_0-mlogloss:2.76384\n",
            "[0]\tvalidation_0-mlogloss:2.21845\n",
            "[1]\tvalidation_0-mlogloss:2.24770\n",
            "[2]\tvalidation_0-mlogloss:2.24891\n",
            "[3]\tvalidation_0-mlogloss:2.25283\n",
            "[4]\tvalidation_0-mlogloss:2.25725\n",
            "[5]\tvalidation_0-mlogloss:2.26088\n",
            "[6]\tvalidation_0-mlogloss:2.27212\n",
            "[7]\tvalidation_0-mlogloss:2.28395\n",
            "[8]\tvalidation_0-mlogloss:2.29877\n",
            "[9]\tvalidation_0-mlogloss:2.31282\n",
            "[10]\tvalidation_0-mlogloss:2.32966\n",
            "[11]\tvalidation_0-mlogloss:2.34617\n",
            "[12]\tvalidation_0-mlogloss:2.36515\n",
            "[13]\tvalidation_0-mlogloss:2.37588\n",
            "[14]\tvalidation_0-mlogloss:2.38572\n",
            "[15]\tvalidation_0-mlogloss:2.39658\n",
            "[16]\tvalidation_0-mlogloss:2.40695\n",
            "[17]\tvalidation_0-mlogloss:2.41729\n",
            "[18]\tvalidation_0-mlogloss:2.42655\n",
            "[19]\tvalidation_0-mlogloss:2.43727\n",
            "[20]\tvalidation_0-mlogloss:2.44820\n",
            "[21]\tvalidation_0-mlogloss:2.45681\n",
            "[22]\tvalidation_0-mlogloss:2.46560\n",
            "[23]\tvalidation_0-mlogloss:2.46062\n",
            "[24]\tvalidation_0-mlogloss:2.47545\n",
            "[25]\tvalidation_0-mlogloss:2.48386\n",
            "[26]\tvalidation_0-mlogloss:2.48940\n",
            "[27]\tvalidation_0-mlogloss:2.48607\n",
            "[28]\tvalidation_0-mlogloss:2.48489\n",
            "[29]\tvalidation_0-mlogloss:2.48215\n",
            "[30]\tvalidation_0-mlogloss:2.48968\n",
            "[31]\tvalidation_0-mlogloss:2.48833\n",
            "[32]\tvalidation_0-mlogloss:2.49749\n",
            "[33]\tvalidation_0-mlogloss:2.50803\n",
            "[34]\tvalidation_0-mlogloss:2.52259\n",
            "[35]\tvalidation_0-mlogloss:2.52262\n",
            "[36]\tvalidation_0-mlogloss:2.52064\n",
            "[37]\tvalidation_0-mlogloss:2.52451\n",
            "[38]\tvalidation_0-mlogloss:2.54028\n",
            "[39]\tvalidation_0-mlogloss:2.54791\n",
            "[40]\tvalidation_0-mlogloss:2.57167\n",
            "[41]\tvalidation_0-mlogloss:2.58903\n",
            "[42]\tvalidation_0-mlogloss:2.59884\n",
            "[43]\tvalidation_0-mlogloss:2.60581\n",
            "[44]\tvalidation_0-mlogloss:2.62117\n",
            "[45]\tvalidation_0-mlogloss:2.63165\n",
            "[46]\tvalidation_0-mlogloss:2.64271\n",
            "[47]\tvalidation_0-mlogloss:2.66033\n",
            "[48]\tvalidation_0-mlogloss:2.64930\n",
            "[49]\tvalidation_0-mlogloss:2.63765\n",
            "[50]\tvalidation_0-mlogloss:2.61841\n",
            "[51]\tvalidation_0-mlogloss:2.60551\n",
            "[52]\tvalidation_0-mlogloss:2.61992\n",
            "[53]\tvalidation_0-mlogloss:2.61128\n",
            "[54]\tvalidation_0-mlogloss:2.59481\n",
            "[55]\tvalidation_0-mlogloss:2.60658\n",
            "[56]\tvalidation_0-mlogloss:2.60030\n",
            "[57]\tvalidation_0-mlogloss:2.61133\n",
            "[58]\tvalidation_0-mlogloss:2.60738\n",
            "[59]\tvalidation_0-mlogloss:2.59642\n",
            "[60]\tvalidation_0-mlogloss:2.59116\n",
            "[61]\tvalidation_0-mlogloss:2.60150\n",
            "[62]\tvalidation_0-mlogloss:2.59428\n",
            "[63]\tvalidation_0-mlogloss:2.58771\n",
            "[64]\tvalidation_0-mlogloss:2.60498\n",
            "[65]\tvalidation_0-mlogloss:2.59520\n",
            "[66]\tvalidation_0-mlogloss:2.57930\n",
            "[67]\tvalidation_0-mlogloss:2.55840\n",
            "[68]\tvalidation_0-mlogloss:2.57013\n",
            "[69]\tvalidation_0-mlogloss:2.55026\n",
            "[70]\tvalidation_0-mlogloss:2.54493\n",
            "[71]\tvalidation_0-mlogloss:2.55125\n",
            "[72]\tvalidation_0-mlogloss:2.51966\n",
            "[73]\tvalidation_0-mlogloss:2.51632\n",
            "[74]\tvalidation_0-mlogloss:2.48768\n",
            "[75]\tvalidation_0-mlogloss:2.48685\n",
            "[76]\tvalidation_0-mlogloss:2.47299\n",
            "[77]\tvalidation_0-mlogloss:2.46044\n",
            "[78]\tvalidation_0-mlogloss:2.44633\n",
            "[79]\tvalidation_0-mlogloss:2.42741\n",
            "[80]\tvalidation_0-mlogloss:2.42589\n",
            "[81]\tvalidation_0-mlogloss:2.41313\n",
            "[82]\tvalidation_0-mlogloss:2.39714\n",
            "[83]\tvalidation_0-mlogloss:2.39603\n",
            "[84]\tvalidation_0-mlogloss:2.38597\n",
            "[85]\tvalidation_0-mlogloss:2.37456\n",
            "[86]\tvalidation_0-mlogloss:2.36647\n",
            "[87]\tvalidation_0-mlogloss:2.35745\n",
            "[88]\tvalidation_0-mlogloss:2.35466\n",
            "[89]\tvalidation_0-mlogloss:2.33527\n",
            "[90]\tvalidation_0-mlogloss:2.32554\n",
            "[91]\tvalidation_0-mlogloss:2.31628\n",
            "[92]\tvalidation_0-mlogloss:2.30760\n",
            "[93]\tvalidation_0-mlogloss:2.30150\n",
            "[94]\tvalidation_0-mlogloss:2.29840\n",
            "[95]\tvalidation_0-mlogloss:2.28908\n",
            "[96]\tvalidation_0-mlogloss:2.28634\n",
            "[97]\tvalidation_0-mlogloss:2.28911\n",
            "[98]\tvalidation_0-mlogloss:2.27837\n",
            "[99]\tvalidation_0-mlogloss:2.28170\n",
            "[0]\tvalidation_0-mlogloss:2.21250\n",
            "[1]\tvalidation_0-mlogloss:2.22839\n",
            "[2]\tvalidation_0-mlogloss:2.24426\n",
            "[3]\tvalidation_0-mlogloss:2.25700\n",
            "[4]\tvalidation_0-mlogloss:2.26779\n",
            "[5]\tvalidation_0-mlogloss:2.28560\n",
            "[6]\tvalidation_0-mlogloss:2.30454\n",
            "[7]\tvalidation_0-mlogloss:2.32403\n",
            "[8]\tvalidation_0-mlogloss:2.34354\n",
            "[9]\tvalidation_0-mlogloss:2.36243\n",
            "[10]\tvalidation_0-mlogloss:2.38025\n",
            "[11]\tvalidation_0-mlogloss:2.39017\n",
            "[12]\tvalidation_0-mlogloss:2.39986\n",
            "[13]\tvalidation_0-mlogloss:2.41014\n",
            "[14]\tvalidation_0-mlogloss:2.42012\n",
            "[15]\tvalidation_0-mlogloss:2.43141\n",
            "[16]\tvalidation_0-mlogloss:2.42861\n",
            "[17]\tvalidation_0-mlogloss:2.42584\n",
            "[18]\tvalidation_0-mlogloss:2.42696\n",
            "[19]\tvalidation_0-mlogloss:2.42709\n",
            "[20]\tvalidation_0-mlogloss:2.42919\n",
            "[21]\tvalidation_0-mlogloss:2.43161\n",
            "[22]\tvalidation_0-mlogloss:2.43457\n",
            "[23]\tvalidation_0-mlogloss:2.44038\n",
            "[24]\tvalidation_0-mlogloss:2.44514\n",
            "[25]\tvalidation_0-mlogloss:2.45369\n",
            "[26]\tvalidation_0-mlogloss:2.46092\n",
            "[27]\tvalidation_0-mlogloss:2.47858\n",
            "[28]\tvalidation_0-mlogloss:2.50088\n",
            "[29]\tvalidation_0-mlogloss:2.50923\n",
            "[30]\tvalidation_0-mlogloss:2.52919\n",
            "[31]\tvalidation_0-mlogloss:2.54288\n",
            "[32]\tvalidation_0-mlogloss:2.56362\n",
            "[33]\tvalidation_0-mlogloss:2.57698\n",
            "[34]\tvalidation_0-mlogloss:2.59300\n",
            "[35]\tvalidation_0-mlogloss:2.60317\n",
            "[36]\tvalidation_0-mlogloss:2.61112\n",
            "[37]\tvalidation_0-mlogloss:2.63228\n",
            "[38]\tvalidation_0-mlogloss:2.64507\n",
            "[39]\tvalidation_0-mlogloss:2.66379\n",
            "[40]\tvalidation_0-mlogloss:2.68343\n",
            "[41]\tvalidation_0-mlogloss:2.70307\n",
            "[42]\tvalidation_0-mlogloss:2.72300\n",
            "[43]\tvalidation_0-mlogloss:2.71642\n",
            "[44]\tvalidation_0-mlogloss:2.70823\n",
            "[45]\tvalidation_0-mlogloss:2.73151\n",
            "[46]\tvalidation_0-mlogloss:2.71593\n",
            "[47]\tvalidation_0-mlogloss:2.70907\n",
            "[48]\tvalidation_0-mlogloss:2.69535\n",
            "[49]\tvalidation_0-mlogloss:2.71518\n",
            "[50]\tvalidation_0-mlogloss:2.69961\n",
            "[51]\tvalidation_0-mlogloss:2.72094\n",
            "[52]\tvalidation_0-mlogloss:2.73403\n",
            "[53]\tvalidation_0-mlogloss:2.72592\n",
            "[54]\tvalidation_0-mlogloss:2.74525\n",
            "[55]\tvalidation_0-mlogloss:2.74052\n",
            "[56]\tvalidation_0-mlogloss:2.75362\n",
            "[57]\tvalidation_0-mlogloss:2.74697\n",
            "[58]\tvalidation_0-mlogloss:2.76770\n",
            "[59]\tvalidation_0-mlogloss:2.75908\n",
            "[60]\tvalidation_0-mlogloss:2.77763\n",
            "[61]\tvalidation_0-mlogloss:2.76085\n",
            "[62]\tvalidation_0-mlogloss:2.77073\n",
            "[63]\tvalidation_0-mlogloss:2.76960\n",
            "[64]\tvalidation_0-mlogloss:2.77212\n",
            "[65]\tvalidation_0-mlogloss:2.76785\n",
            "[66]\tvalidation_0-mlogloss:2.76755\n",
            "[67]\tvalidation_0-mlogloss:2.75836\n",
            "[68]\tvalidation_0-mlogloss:2.75232\n",
            "[69]\tvalidation_0-mlogloss:2.77075\n",
            "[70]\tvalidation_0-mlogloss:2.74311\n",
            "[71]\tvalidation_0-mlogloss:2.73280\n",
            "[72]\tvalidation_0-mlogloss:2.74150\n",
            "[73]\tvalidation_0-mlogloss:2.72458\n",
            "[74]\tvalidation_0-mlogloss:2.69580\n",
            "[75]\tvalidation_0-mlogloss:2.71039\n",
            "[76]\tvalidation_0-mlogloss:2.70017\n",
            "[77]\tvalidation_0-mlogloss:2.68730\n",
            "[78]\tvalidation_0-mlogloss:2.66850\n",
            "[79]\tvalidation_0-mlogloss:2.65312\n",
            "[80]\tvalidation_0-mlogloss:2.67303\n",
            "[81]\tvalidation_0-mlogloss:2.65100\n",
            "[82]\tvalidation_0-mlogloss:2.64954\n",
            "[83]\tvalidation_0-mlogloss:2.63387\n",
            "[84]\tvalidation_0-mlogloss:2.62675\n",
            "[85]\tvalidation_0-mlogloss:2.61255\n",
            "[86]\tvalidation_0-mlogloss:2.60460\n",
            "[87]\tvalidation_0-mlogloss:2.59273\n",
            "[88]\tvalidation_0-mlogloss:2.57868\n",
            "[89]\tvalidation_0-mlogloss:2.57087\n",
            "[90]\tvalidation_0-mlogloss:2.56496\n",
            "[91]\tvalidation_0-mlogloss:2.54943\n",
            "[92]\tvalidation_0-mlogloss:2.53854\n",
            "[93]\tvalidation_0-mlogloss:2.53412\n",
            "[94]\tvalidation_0-mlogloss:2.52136\n",
            "[95]\tvalidation_0-mlogloss:2.51388\n",
            "[96]\tvalidation_0-mlogloss:2.50780\n",
            "[97]\tvalidation_0-mlogloss:2.50200\n",
            "[98]\tvalidation_0-mlogloss:2.49409\n",
            "[99]\tvalidation_0-mlogloss:2.49093\n",
            "[0]\tvalidation_0-mlogloss:2.19781\n",
            "[1]\tvalidation_0-mlogloss:2.21217\n",
            "[2]\tvalidation_0-mlogloss:2.21341\n",
            "[3]\tvalidation_0-mlogloss:2.21990\n",
            "[4]\tvalidation_0-mlogloss:2.22921\n",
            "[5]\tvalidation_0-mlogloss:2.24963\n",
            "[6]\tvalidation_0-mlogloss:2.26573\n",
            "[7]\tvalidation_0-mlogloss:2.28548\n",
            "[8]\tvalidation_0-mlogloss:2.29760\n",
            "[9]\tvalidation_0-mlogloss:2.31385\n",
            "[10]\tvalidation_0-mlogloss:2.32031\n",
            "[11]\tvalidation_0-mlogloss:2.32811\n",
            "[12]\tvalidation_0-mlogloss:2.34055\n",
            "[13]\tvalidation_0-mlogloss:2.35256\n",
            "[14]\tvalidation_0-mlogloss:2.36147\n",
            "[15]\tvalidation_0-mlogloss:2.37290\n",
            "[16]\tvalidation_0-mlogloss:2.38545\n",
            "[17]\tvalidation_0-mlogloss:2.39523\n",
            "[18]\tvalidation_0-mlogloss:2.39431\n",
            "[19]\tvalidation_0-mlogloss:2.39208\n",
            "[20]\tvalidation_0-mlogloss:2.39189\n",
            "[21]\tvalidation_0-mlogloss:2.39266\n",
            "[22]\tvalidation_0-mlogloss:2.38990\n",
            "[23]\tvalidation_0-mlogloss:2.39552\n",
            "[24]\tvalidation_0-mlogloss:2.39773\n",
            "[25]\tvalidation_0-mlogloss:2.40485\n",
            "[26]\tvalidation_0-mlogloss:2.40807\n",
            "[27]\tvalidation_0-mlogloss:2.42161\n",
            "[28]\tvalidation_0-mlogloss:2.42898\n",
            "[29]\tvalidation_0-mlogloss:2.43630\n",
            "[30]\tvalidation_0-mlogloss:2.45050\n",
            "[31]\tvalidation_0-mlogloss:2.46199\n",
            "[32]\tvalidation_0-mlogloss:2.47135\n",
            "[33]\tvalidation_0-mlogloss:2.48671\n",
            "[34]\tvalidation_0-mlogloss:2.49938\n",
            "[35]\tvalidation_0-mlogloss:2.51380\n",
            "[36]\tvalidation_0-mlogloss:2.52623\n",
            "[37]\tvalidation_0-mlogloss:2.54046\n",
            "[38]\tvalidation_0-mlogloss:2.56568\n",
            "[39]\tvalidation_0-mlogloss:2.58064\n",
            "[40]\tvalidation_0-mlogloss:2.60652\n",
            "[41]\tvalidation_0-mlogloss:2.62633\n",
            "[42]\tvalidation_0-mlogloss:2.64237\n",
            "[43]\tvalidation_0-mlogloss:2.66720\n",
            "[44]\tvalidation_0-mlogloss:2.69150\n",
            "[45]\tvalidation_0-mlogloss:2.71307\n",
            "[46]\tvalidation_0-mlogloss:2.73440\n",
            "[47]\tvalidation_0-mlogloss:2.75962\n",
            "[48]\tvalidation_0-mlogloss:2.75033\n",
            "[49]\tvalidation_0-mlogloss:2.77246\n",
            "[50]\tvalidation_0-mlogloss:2.78316\n",
            "[51]\tvalidation_0-mlogloss:2.78282\n",
            "[52]\tvalidation_0-mlogloss:2.80639\n",
            "[53]\tvalidation_0-mlogloss:2.79979\n",
            "[54]\tvalidation_0-mlogloss:2.82513\n",
            "[55]\tvalidation_0-mlogloss:2.82513\n",
            "[56]\tvalidation_0-mlogloss:2.84975\n",
            "[57]\tvalidation_0-mlogloss:2.84984\n",
            "[58]\tvalidation_0-mlogloss:2.83755\n",
            "[59]\tvalidation_0-mlogloss:2.86575\n",
            "[60]\tvalidation_0-mlogloss:2.88243\n",
            "[61]\tvalidation_0-mlogloss:2.89914\n",
            "[62]\tvalidation_0-mlogloss:2.90656\n",
            "[63]\tvalidation_0-mlogloss:2.92098\n",
            "[64]\tvalidation_0-mlogloss:2.93158\n",
            "[65]\tvalidation_0-mlogloss:2.92746\n",
            "[66]\tvalidation_0-mlogloss:2.94985\n",
            "[67]\tvalidation_0-mlogloss:2.95349\n",
            "[68]\tvalidation_0-mlogloss:2.93708\n",
            "[69]\tvalidation_0-mlogloss:2.93955\n",
            "[70]\tvalidation_0-mlogloss:2.93997\n",
            "[71]\tvalidation_0-mlogloss:2.94176\n",
            "[72]\tvalidation_0-mlogloss:2.92794\n",
            "[73]\tvalidation_0-mlogloss:2.93724\n",
            "[74]\tvalidation_0-mlogloss:2.93246\n",
            "[75]\tvalidation_0-mlogloss:2.93571\n",
            "[76]\tvalidation_0-mlogloss:2.94534\n",
            "[77]\tvalidation_0-mlogloss:2.92892\n",
            "[78]\tvalidation_0-mlogloss:2.94093\n",
            "[79]\tvalidation_0-mlogloss:2.93803\n",
            "[80]\tvalidation_0-mlogloss:2.92746\n",
            "[81]\tvalidation_0-mlogloss:2.91425\n",
            "[82]\tvalidation_0-mlogloss:2.90411\n",
            "[83]\tvalidation_0-mlogloss:2.89031\n",
            "[84]\tvalidation_0-mlogloss:2.88048\n",
            "[85]\tvalidation_0-mlogloss:2.87213\n",
            "[86]\tvalidation_0-mlogloss:2.85146\n",
            "[87]\tvalidation_0-mlogloss:2.84744\n",
            "[88]\tvalidation_0-mlogloss:2.83253\n",
            "[89]\tvalidation_0-mlogloss:2.82490\n",
            "[90]\tvalidation_0-mlogloss:2.81130\n",
            "[91]\tvalidation_0-mlogloss:2.79885\n",
            "[92]\tvalidation_0-mlogloss:2.78262\n",
            "[93]\tvalidation_0-mlogloss:2.76949\n",
            "[94]\tvalidation_0-mlogloss:2.76479\n",
            "[95]\tvalidation_0-mlogloss:2.75770\n",
            "[96]\tvalidation_0-mlogloss:2.74587\n",
            "[97]\tvalidation_0-mlogloss:2.73595\n",
            "[98]\tvalidation_0-mlogloss:2.72951\n",
            "[99]\tvalidation_0-mlogloss:2.72042\n",
            "[0]\tvalidation_0-mlogloss:2.13430\n",
            "[1]\tvalidation_0-mlogloss:2.09878\n",
            "[2]\tvalidation_0-mlogloss:2.08402\n",
            "[3]\tvalidation_0-mlogloss:2.09032\n",
            "[4]\tvalidation_0-mlogloss:2.09461\n",
            "[5]\tvalidation_0-mlogloss:2.10526\n",
            "[6]\tvalidation_0-mlogloss:2.12055\n",
            "[7]\tvalidation_0-mlogloss:2.13761\n",
            "[8]\tvalidation_0-mlogloss:2.15737\n",
            "[9]\tvalidation_0-mlogloss:2.17954\n",
            "[10]\tvalidation_0-mlogloss:2.20434\n",
            "[11]\tvalidation_0-mlogloss:2.23757\n",
            "[12]\tvalidation_0-mlogloss:2.27175\n",
            "[13]\tvalidation_0-mlogloss:2.30617\n",
            "[14]\tvalidation_0-mlogloss:2.34289\n",
            "[15]\tvalidation_0-mlogloss:2.38060\n",
            "[16]\tvalidation_0-mlogloss:2.41811\n",
            "[17]\tvalidation_0-mlogloss:2.44798\n",
            "[18]\tvalidation_0-mlogloss:2.47869\n",
            "[19]\tvalidation_0-mlogloss:2.50742\n",
            "[20]\tvalidation_0-mlogloss:2.53810\n",
            "[21]\tvalidation_0-mlogloss:2.56976\n",
            "[22]\tvalidation_0-mlogloss:2.59519\n",
            "[23]\tvalidation_0-mlogloss:2.62343\n",
            "[24]\tvalidation_0-mlogloss:2.65145\n",
            "[25]\tvalidation_0-mlogloss:2.68965\n",
            "[26]\tvalidation_0-mlogloss:2.72880\n",
            "[27]\tvalidation_0-mlogloss:2.76836\n",
            "[28]\tvalidation_0-mlogloss:2.78928\n",
            "[29]\tvalidation_0-mlogloss:2.81298\n",
            "[30]\tvalidation_0-mlogloss:2.85178\n",
            "[31]\tvalidation_0-mlogloss:2.87471\n",
            "[32]\tvalidation_0-mlogloss:2.92061\n",
            "[33]\tvalidation_0-mlogloss:2.96272\n",
            "[34]\tvalidation_0-mlogloss:2.99758\n",
            "[35]\tvalidation_0-mlogloss:3.01518\n",
            "[36]\tvalidation_0-mlogloss:3.05207\n",
            "[37]\tvalidation_0-mlogloss:3.06839\n",
            "[38]\tvalidation_0-mlogloss:3.10502\n",
            "[39]\tvalidation_0-mlogloss:3.13508\n",
            "[40]\tvalidation_0-mlogloss:3.16217\n",
            "[41]\tvalidation_0-mlogloss:3.18913\n",
            "[42]\tvalidation_0-mlogloss:3.21676\n",
            "[43]\tvalidation_0-mlogloss:3.24982\n",
            "[44]\tvalidation_0-mlogloss:3.26231\n",
            "[45]\tvalidation_0-mlogloss:3.29048\n",
            "[46]\tvalidation_0-mlogloss:3.31788\n",
            "[47]\tvalidation_0-mlogloss:3.34828\n",
            "[48]\tvalidation_0-mlogloss:3.35534\n",
            "[49]\tvalidation_0-mlogloss:3.38362\n",
            "[50]\tvalidation_0-mlogloss:3.40927\n",
            "[51]\tvalidation_0-mlogloss:3.42661\n",
            "[52]\tvalidation_0-mlogloss:3.45739\n",
            "[53]\tvalidation_0-mlogloss:3.48719\n",
            "[54]\tvalidation_0-mlogloss:3.51010\n",
            "[55]\tvalidation_0-mlogloss:3.53946\n",
            "[56]\tvalidation_0-mlogloss:3.56583\n",
            "[57]\tvalidation_0-mlogloss:3.54905\n",
            "[58]\tvalidation_0-mlogloss:3.56958\n",
            "[59]\tvalidation_0-mlogloss:3.53979\n",
            "[60]\tvalidation_0-mlogloss:3.55058\n",
            "[61]\tvalidation_0-mlogloss:3.53698\n",
            "[62]\tvalidation_0-mlogloss:3.54944\n",
            "[63]\tvalidation_0-mlogloss:3.57601\n",
            "[64]\tvalidation_0-mlogloss:3.58519\n",
            "[65]\tvalidation_0-mlogloss:3.57480\n",
            "[66]\tvalidation_0-mlogloss:3.58601\n",
            "[67]\tvalidation_0-mlogloss:3.57278\n",
            "[68]\tvalidation_0-mlogloss:3.55876\n",
            "[69]\tvalidation_0-mlogloss:3.57075\n",
            "[70]\tvalidation_0-mlogloss:3.54471\n",
            "[71]\tvalidation_0-mlogloss:3.50814\n",
            "[72]\tvalidation_0-mlogloss:3.50213\n",
            "[73]\tvalidation_0-mlogloss:3.45521\n",
            "[74]\tvalidation_0-mlogloss:3.45461\n",
            "[75]\tvalidation_0-mlogloss:3.43430\n",
            "[76]\tvalidation_0-mlogloss:3.41120\n",
            "[77]\tvalidation_0-mlogloss:3.38555\n",
            "[78]\tvalidation_0-mlogloss:3.37023\n",
            "[79]\tvalidation_0-mlogloss:3.33746\n",
            "[80]\tvalidation_0-mlogloss:3.32047\n",
            "[81]\tvalidation_0-mlogloss:3.31076\n",
            "[82]\tvalidation_0-mlogloss:3.28978\n",
            "[83]\tvalidation_0-mlogloss:3.26718\n",
            "[84]\tvalidation_0-mlogloss:3.25395\n",
            "[85]\tvalidation_0-mlogloss:3.23779\n",
            "[86]\tvalidation_0-mlogloss:3.23244\n",
            "[87]\tvalidation_0-mlogloss:3.21252\n",
            "[88]\tvalidation_0-mlogloss:3.21084\n",
            "[89]\tvalidation_0-mlogloss:3.19014\n",
            "[90]\tvalidation_0-mlogloss:3.17956\n",
            "[91]\tvalidation_0-mlogloss:3.15399\n",
            "[92]\tvalidation_0-mlogloss:3.13200\n",
            "[93]\tvalidation_0-mlogloss:3.10938\n",
            "[94]\tvalidation_0-mlogloss:3.08803\n",
            "[95]\tvalidation_0-mlogloss:3.08168\n",
            "[96]\tvalidation_0-mlogloss:3.06330\n",
            "[97]\tvalidation_0-mlogloss:3.04866\n",
            "[98]\tvalidation_0-mlogloss:3.03354\n",
            "[99]\tvalidation_0-mlogloss:3.01367\n",
            "[0]\tvalidation_0-mlogloss:2.17904\n",
            "[1]\tvalidation_0-mlogloss:2.16590\n",
            "[2]\tvalidation_0-mlogloss:2.16980\n",
            "[3]\tvalidation_0-mlogloss:2.18183\n",
            "[4]\tvalidation_0-mlogloss:2.19656\n",
            "[5]\tvalidation_0-mlogloss:2.20353\n",
            "[6]\tvalidation_0-mlogloss:2.20346\n",
            "[7]\tvalidation_0-mlogloss:2.20512\n",
            "[8]\tvalidation_0-mlogloss:2.20964\n",
            "[9]\tvalidation_0-mlogloss:2.21613\n",
            "[10]\tvalidation_0-mlogloss:2.22672\n",
            "[11]\tvalidation_0-mlogloss:2.23545\n",
            "[12]\tvalidation_0-mlogloss:2.24471\n",
            "[13]\tvalidation_0-mlogloss:2.25177\n",
            "[14]\tvalidation_0-mlogloss:2.26008\n",
            "[15]\tvalidation_0-mlogloss:2.26953\n",
            "[16]\tvalidation_0-mlogloss:2.27981\n",
            "[17]\tvalidation_0-mlogloss:2.28743\n",
            "[18]\tvalidation_0-mlogloss:2.29561\n",
            "[19]\tvalidation_0-mlogloss:2.30624\n",
            "[20]\tvalidation_0-mlogloss:2.31909\n",
            "[21]\tvalidation_0-mlogloss:2.33140\n",
            "[22]\tvalidation_0-mlogloss:2.34432\n",
            "[23]\tvalidation_0-mlogloss:2.35462\n",
            "[24]\tvalidation_0-mlogloss:2.37049\n",
            "[25]\tvalidation_0-mlogloss:2.38126\n",
            "[26]\tvalidation_0-mlogloss:2.39623\n",
            "[27]\tvalidation_0-mlogloss:2.41323\n",
            "[28]\tvalidation_0-mlogloss:2.43298\n",
            "[29]\tvalidation_0-mlogloss:2.45290\n",
            "[30]\tvalidation_0-mlogloss:2.46792\n",
            "[31]\tvalidation_0-mlogloss:2.48191\n",
            "[32]\tvalidation_0-mlogloss:2.50262\n",
            "[33]\tvalidation_0-mlogloss:2.51979\n",
            "[34]\tvalidation_0-mlogloss:2.53143\n",
            "[35]\tvalidation_0-mlogloss:2.55027\n",
            "[36]\tvalidation_0-mlogloss:2.56769\n",
            "[37]\tvalidation_0-mlogloss:2.58272\n",
            "[38]\tvalidation_0-mlogloss:2.59968\n",
            "[39]\tvalidation_0-mlogloss:2.61709\n",
            "[40]\tvalidation_0-mlogloss:2.63277\n",
            "[41]\tvalidation_0-mlogloss:2.65856\n",
            "[42]\tvalidation_0-mlogloss:2.68025\n",
            "[43]\tvalidation_0-mlogloss:2.70739\n",
            "[44]\tvalidation_0-mlogloss:2.72734\n",
            "[45]\tvalidation_0-mlogloss:2.74554\n",
            "[46]\tvalidation_0-mlogloss:2.75910\n",
            "[47]\tvalidation_0-mlogloss:2.78283\n",
            "[48]\tvalidation_0-mlogloss:2.78370\n",
            "[49]\tvalidation_0-mlogloss:2.80991\n",
            "[50]\tvalidation_0-mlogloss:2.79557\n",
            "[51]\tvalidation_0-mlogloss:2.78450\n",
            "[52]\tvalidation_0-mlogloss:2.80360\n",
            "[53]\tvalidation_0-mlogloss:2.78674\n",
            "[54]\tvalidation_0-mlogloss:2.77175\n",
            "[55]\tvalidation_0-mlogloss:2.78839\n",
            "[56]\tvalidation_0-mlogloss:2.77438\n",
            "[57]\tvalidation_0-mlogloss:2.75714\n",
            "[58]\tvalidation_0-mlogloss:2.77587\n",
            "[59]\tvalidation_0-mlogloss:2.76409\n",
            "[60]\tvalidation_0-mlogloss:2.75889\n",
            "[61]\tvalidation_0-mlogloss:2.77497\n",
            "[62]\tvalidation_0-mlogloss:2.76996\n",
            "[63]\tvalidation_0-mlogloss:2.77583\n",
            "[64]\tvalidation_0-mlogloss:2.79669\n",
            "[65]\tvalidation_0-mlogloss:2.78496\n",
            "[66]\tvalidation_0-mlogloss:2.80049\n",
            "[67]\tvalidation_0-mlogloss:2.81018\n",
            "[68]\tvalidation_0-mlogloss:2.78734\n",
            "[69]\tvalidation_0-mlogloss:2.78278\n",
            "[70]\tvalidation_0-mlogloss:2.76576\n",
            "[71]\tvalidation_0-mlogloss:2.76109\n",
            "[72]\tvalidation_0-mlogloss:2.76963\n",
            "[73]\tvalidation_0-mlogloss:2.77090\n",
            "[74]\tvalidation_0-mlogloss:2.77123\n",
            "[75]\tvalidation_0-mlogloss:2.76921\n",
            "[76]\tvalidation_0-mlogloss:2.77628\n",
            "[77]\tvalidation_0-mlogloss:2.76189\n",
            "[78]\tvalidation_0-mlogloss:2.74838\n",
            "[79]\tvalidation_0-mlogloss:2.74131\n",
            "[80]\tvalidation_0-mlogloss:2.72720\n",
            "[81]\tvalidation_0-mlogloss:2.72251\n",
            "[82]\tvalidation_0-mlogloss:2.70954\n",
            "[83]\tvalidation_0-mlogloss:2.69973\n",
            "[84]\tvalidation_0-mlogloss:2.69350\n",
            "[85]\tvalidation_0-mlogloss:2.68433\n",
            "[86]\tvalidation_0-mlogloss:2.67867\n",
            "[87]\tvalidation_0-mlogloss:2.67258\n",
            "[88]\tvalidation_0-mlogloss:2.67111\n",
            "[89]\tvalidation_0-mlogloss:2.65801\n",
            "[90]\tvalidation_0-mlogloss:2.64842\n",
            "[91]\tvalidation_0-mlogloss:2.64291\n",
            "[92]\tvalidation_0-mlogloss:2.63745\n",
            "[93]\tvalidation_0-mlogloss:2.62923\n",
            "[94]\tvalidation_0-mlogloss:2.62161\n",
            "[95]\tvalidation_0-mlogloss:2.62299\n",
            "[96]\tvalidation_0-mlogloss:2.60943\n",
            "[97]\tvalidation_0-mlogloss:2.60248\n",
            "[98]\tvalidation_0-mlogloss:2.60001\n",
            "[99]\tvalidation_0-mlogloss:2.59562\n",
            "[0]\tvalidation_0-mlogloss:2.18502\n",
            "[1]\tvalidation_0-mlogloss:2.18718\n",
            "[2]\tvalidation_0-mlogloss:2.19299\n",
            "[3]\tvalidation_0-mlogloss:2.20147\n",
            "[4]\tvalidation_0-mlogloss:2.21214\n",
            "[5]\tvalidation_0-mlogloss:2.22428\n",
            "[6]\tvalidation_0-mlogloss:2.23932\n",
            "[7]\tvalidation_0-mlogloss:2.25167\n",
            "[8]\tvalidation_0-mlogloss:2.26486\n",
            "[9]\tvalidation_0-mlogloss:2.27735\n",
            "[10]\tvalidation_0-mlogloss:2.29073\n",
            "[11]\tvalidation_0-mlogloss:2.30547\n",
            "[12]\tvalidation_0-mlogloss:2.30830\n",
            "[13]\tvalidation_0-mlogloss:2.32438\n",
            "[14]\tvalidation_0-mlogloss:2.32373\n",
            "[15]\tvalidation_0-mlogloss:2.33370\n",
            "[16]\tvalidation_0-mlogloss:2.33631\n",
            "[17]\tvalidation_0-mlogloss:2.33894\n",
            "[18]\tvalidation_0-mlogloss:2.35099\n",
            "[19]\tvalidation_0-mlogloss:2.35810\n",
            "[20]\tvalidation_0-mlogloss:2.36439\n",
            "[21]\tvalidation_0-mlogloss:2.36923\n",
            "[22]\tvalidation_0-mlogloss:2.37151\n",
            "[23]\tvalidation_0-mlogloss:2.37851\n",
            "[24]\tvalidation_0-mlogloss:2.39325\n",
            "[25]\tvalidation_0-mlogloss:2.39271\n",
            "[26]\tvalidation_0-mlogloss:2.38650\n",
            "[27]\tvalidation_0-mlogloss:2.38196\n",
            "[28]\tvalidation_0-mlogloss:2.37939\n",
            "[29]\tvalidation_0-mlogloss:2.37433\n",
            "[30]\tvalidation_0-mlogloss:2.37514\n",
            "[31]\tvalidation_0-mlogloss:2.37010\n",
            "[32]\tvalidation_0-mlogloss:2.37183\n",
            "[33]\tvalidation_0-mlogloss:2.37227\n",
            "[34]\tvalidation_0-mlogloss:2.37257\n",
            "[35]\tvalidation_0-mlogloss:2.38176\n",
            "[36]\tvalidation_0-mlogloss:2.38582\n",
            "[37]\tvalidation_0-mlogloss:2.38873\n",
            "[38]\tvalidation_0-mlogloss:2.39289\n",
            "[39]\tvalidation_0-mlogloss:2.39961\n",
            "[40]\tvalidation_0-mlogloss:2.41370\n",
            "[41]\tvalidation_0-mlogloss:2.42244\n",
            "[42]\tvalidation_0-mlogloss:2.43529\n",
            "[43]\tvalidation_0-mlogloss:2.42687\n",
            "[44]\tvalidation_0-mlogloss:2.41882\n",
            "[45]\tvalidation_0-mlogloss:2.41097\n",
            "[46]\tvalidation_0-mlogloss:2.42696\n",
            "[47]\tvalidation_0-mlogloss:2.41978\n",
            "[48]\tvalidation_0-mlogloss:2.41127\n",
            "[49]\tvalidation_0-mlogloss:2.40170\n",
            "[50]\tvalidation_0-mlogloss:2.40102\n",
            "[51]\tvalidation_0-mlogloss:2.42174\n",
            "[52]\tvalidation_0-mlogloss:2.42555\n",
            "[53]\tvalidation_0-mlogloss:2.42051\n",
            "[54]\tvalidation_0-mlogloss:2.42609\n",
            "[55]\tvalidation_0-mlogloss:2.44660\n",
            "[56]\tvalidation_0-mlogloss:2.44821\n",
            "[57]\tvalidation_0-mlogloss:2.43346\n",
            "[58]\tvalidation_0-mlogloss:2.45478\n",
            "[59]\tvalidation_0-mlogloss:2.44290\n",
            "[60]\tvalidation_0-mlogloss:2.43880\n",
            "[61]\tvalidation_0-mlogloss:2.42128\n",
            "[62]\tvalidation_0-mlogloss:2.44415\n",
            "[63]\tvalidation_0-mlogloss:2.42936\n",
            "[64]\tvalidation_0-mlogloss:2.41046\n",
            "[65]\tvalidation_0-mlogloss:2.40814\n",
            "[66]\tvalidation_0-mlogloss:2.39530\n",
            "[67]\tvalidation_0-mlogloss:2.41249\n",
            "[68]\tvalidation_0-mlogloss:2.39924\n",
            "[69]\tvalidation_0-mlogloss:2.39373\n",
            "[70]\tvalidation_0-mlogloss:2.38522\n",
            "[71]\tvalidation_0-mlogloss:2.38551\n",
            "[72]\tvalidation_0-mlogloss:2.37336\n",
            "[73]\tvalidation_0-mlogloss:2.38896\n",
            "[74]\tvalidation_0-mlogloss:2.37211\n",
            "[75]\tvalidation_0-mlogloss:2.38028\n",
            "[76]\tvalidation_0-mlogloss:2.36921\n",
            "[77]\tvalidation_0-mlogloss:2.36992\n",
            "[78]\tvalidation_0-mlogloss:2.37485\n",
            "[79]\tvalidation_0-mlogloss:2.36292\n",
            "[80]\tvalidation_0-mlogloss:2.36246\n",
            "[81]\tvalidation_0-mlogloss:2.35248\n",
            "[82]\tvalidation_0-mlogloss:2.35385\n",
            "[83]\tvalidation_0-mlogloss:2.34987\n",
            "[84]\tvalidation_0-mlogloss:2.34387\n",
            "[85]\tvalidation_0-mlogloss:2.34755\n",
            "[86]\tvalidation_0-mlogloss:2.33569\n",
            "[87]\tvalidation_0-mlogloss:2.33544\n",
            "[88]\tvalidation_0-mlogloss:2.33450\n",
            "[89]\tvalidation_0-mlogloss:2.33629\n",
            "[90]\tvalidation_0-mlogloss:2.33016\n",
            "[91]\tvalidation_0-mlogloss:2.33078\n",
            "[92]\tvalidation_0-mlogloss:2.32742\n",
            "[93]\tvalidation_0-mlogloss:2.32579\n",
            "[94]\tvalidation_0-mlogloss:2.32123\n",
            "[95]\tvalidation_0-mlogloss:2.32169\n",
            "[96]\tvalidation_0-mlogloss:2.32445\n",
            "[97]\tvalidation_0-mlogloss:2.32796\n",
            "[98]\tvalidation_0-mlogloss:2.32966\n",
            "[99]\tvalidation_0-mlogloss:2.32183\n",
            "[0]\tvalidation_0-mlogloss:2.14000\n",
            "[1]\tvalidation_0-mlogloss:2.15055\n",
            "[2]\tvalidation_0-mlogloss:2.16418\n",
            "[3]\tvalidation_0-mlogloss:2.17107\n",
            "[4]\tvalidation_0-mlogloss:2.18415\n",
            "[5]\tvalidation_0-mlogloss:2.17509\n",
            "[6]\tvalidation_0-mlogloss:2.18937\n",
            "[7]\tvalidation_0-mlogloss:2.17741\n",
            "[8]\tvalidation_0-mlogloss:2.16722\n",
            "[9]\tvalidation_0-mlogloss:2.16095\n",
            "[10]\tvalidation_0-mlogloss:2.15775\n",
            "[11]\tvalidation_0-mlogloss:2.15663\n",
            "[12]\tvalidation_0-mlogloss:2.15596\n",
            "[13]\tvalidation_0-mlogloss:2.15642\n",
            "[14]\tvalidation_0-mlogloss:2.15828\n",
            "[15]\tvalidation_0-mlogloss:2.16199\n",
            "[16]\tvalidation_0-mlogloss:2.16978\n",
            "[17]\tvalidation_0-mlogloss:2.17500\n",
            "[18]\tvalidation_0-mlogloss:2.18314\n",
            "[19]\tvalidation_0-mlogloss:2.18924\n",
            "[20]\tvalidation_0-mlogloss:2.19578\n",
            "[21]\tvalidation_0-mlogloss:2.20294\n",
            "[22]\tvalidation_0-mlogloss:2.21567\n",
            "[23]\tvalidation_0-mlogloss:2.22901\n",
            "[24]\tvalidation_0-mlogloss:2.23718\n",
            "[25]\tvalidation_0-mlogloss:2.25275\n",
            "[26]\tvalidation_0-mlogloss:2.26659\n",
            "[27]\tvalidation_0-mlogloss:2.27603\n",
            "[28]\tvalidation_0-mlogloss:2.29064\n",
            "[29]\tvalidation_0-mlogloss:2.30708\n",
            "[30]\tvalidation_0-mlogloss:2.32228\n",
            "[31]\tvalidation_0-mlogloss:2.34552\n",
            "[32]\tvalidation_0-mlogloss:2.35942\n",
            "[33]\tvalidation_0-mlogloss:2.38211\n",
            "[34]\tvalidation_0-mlogloss:2.39139\n",
            "[35]\tvalidation_0-mlogloss:2.40616\n",
            "[36]\tvalidation_0-mlogloss:2.41965\n",
            "[37]\tvalidation_0-mlogloss:2.43768\n",
            "[38]\tvalidation_0-mlogloss:2.45265\n",
            "[39]\tvalidation_0-mlogloss:2.46710\n",
            "[40]\tvalidation_0-mlogloss:2.48648\n",
            "[41]\tvalidation_0-mlogloss:2.49964\n",
            "[42]\tvalidation_0-mlogloss:2.51921\n",
            "[43]\tvalidation_0-mlogloss:2.54063\n",
            "[44]\tvalidation_0-mlogloss:2.56317\n",
            "[45]\tvalidation_0-mlogloss:2.58549\n",
            "[46]\tvalidation_0-mlogloss:2.59547\n",
            "[47]\tvalidation_0-mlogloss:2.58454\n",
            "[48]\tvalidation_0-mlogloss:2.59583\n",
            "[49]\tvalidation_0-mlogloss:2.58736\n",
            "[50]\tvalidation_0-mlogloss:2.61454\n",
            "[51]\tvalidation_0-mlogloss:2.59799\n",
            "[52]\tvalidation_0-mlogloss:2.62457\n",
            "[53]\tvalidation_0-mlogloss:2.62334\n",
            "[54]\tvalidation_0-mlogloss:2.64471\n",
            "[55]\tvalidation_0-mlogloss:2.63716\n",
            "[56]\tvalidation_0-mlogloss:2.63570\n",
            "[57]\tvalidation_0-mlogloss:2.66155\n",
            "[58]\tvalidation_0-mlogloss:2.64829\n",
            "[59]\tvalidation_0-mlogloss:2.64433\n",
            "[60]\tvalidation_0-mlogloss:2.66371\n",
            "[61]\tvalidation_0-mlogloss:2.65747\n",
            "[62]\tvalidation_0-mlogloss:2.65760\n",
            "[63]\tvalidation_0-mlogloss:2.64253\n",
            "[64]\tvalidation_0-mlogloss:2.61325\n",
            "[65]\tvalidation_0-mlogloss:2.59920\n",
            "[66]\tvalidation_0-mlogloss:2.60467\n",
            "[67]\tvalidation_0-mlogloss:2.57367\n",
            "[68]\tvalidation_0-mlogloss:2.59178\n",
            "[69]\tvalidation_0-mlogloss:2.56227\n",
            "[70]\tvalidation_0-mlogloss:2.54873\n",
            "[71]\tvalidation_0-mlogloss:2.53133\n",
            "[72]\tvalidation_0-mlogloss:2.52063\n",
            "[73]\tvalidation_0-mlogloss:2.50341\n",
            "[74]\tvalidation_0-mlogloss:2.48286\n",
            "[75]\tvalidation_0-mlogloss:2.46593\n",
            "[76]\tvalidation_0-mlogloss:2.45783\n",
            "[77]\tvalidation_0-mlogloss:2.43375\n",
            "[78]\tvalidation_0-mlogloss:2.43620\n",
            "[79]\tvalidation_0-mlogloss:2.42063\n",
            "[80]\tvalidation_0-mlogloss:2.41422\n",
            "[81]\tvalidation_0-mlogloss:2.40470\n",
            "[82]\tvalidation_0-mlogloss:2.38948\n",
            "[83]\tvalidation_0-mlogloss:2.38794\n",
            "[84]\tvalidation_0-mlogloss:2.36900\n",
            "[85]\tvalidation_0-mlogloss:2.36878\n",
            "[86]\tvalidation_0-mlogloss:2.35772\n",
            "[87]\tvalidation_0-mlogloss:2.35379\n",
            "[88]\tvalidation_0-mlogloss:2.33667\n",
            "[89]\tvalidation_0-mlogloss:2.33204\n",
            "[90]\tvalidation_0-mlogloss:2.32606\n",
            "[91]\tvalidation_0-mlogloss:2.31622\n",
            "[92]\tvalidation_0-mlogloss:2.31056\n",
            "[93]\tvalidation_0-mlogloss:2.30871\n",
            "[94]\tvalidation_0-mlogloss:2.30487\n",
            "[95]\tvalidation_0-mlogloss:2.29480\n",
            "[96]\tvalidation_0-mlogloss:2.28873\n",
            "[97]\tvalidation_0-mlogloss:2.29072\n",
            "[98]\tvalidation_0-mlogloss:2.28441\n",
            "[99]\tvalidation_0-mlogloss:2.28017\n",
            "[0]\tvalidation_0-mlogloss:2.17665\n",
            "[1]\tvalidation_0-mlogloss:2.12544\n",
            "[2]\tvalidation_0-mlogloss:2.08974\n",
            "[3]\tvalidation_0-mlogloss:2.06119\n",
            "[4]\tvalidation_0-mlogloss:2.04010\n",
            "[5]\tvalidation_0-mlogloss:2.05342\n",
            "[6]\tvalidation_0-mlogloss:2.06592\n",
            "[7]\tvalidation_0-mlogloss:2.07607\n",
            "[8]\tvalidation_0-mlogloss:2.09356\n",
            "[9]\tvalidation_0-mlogloss:2.10737\n",
            "[10]\tvalidation_0-mlogloss:2.12708\n",
            "[11]\tvalidation_0-mlogloss:2.14566\n",
            "[12]\tvalidation_0-mlogloss:2.16437\n",
            "[13]\tvalidation_0-mlogloss:2.18530\n",
            "[14]\tvalidation_0-mlogloss:2.19402\n",
            "[15]\tvalidation_0-mlogloss:2.21556\n",
            "[16]\tvalidation_0-mlogloss:2.22607\n",
            "[17]\tvalidation_0-mlogloss:2.24104\n",
            "[18]\tvalidation_0-mlogloss:2.26328\n",
            "[19]\tvalidation_0-mlogloss:2.28962\n",
            "[20]\tvalidation_0-mlogloss:2.30054\n",
            "[21]\tvalidation_0-mlogloss:2.31513\n",
            "[22]\tvalidation_0-mlogloss:2.33552\n",
            "[23]\tvalidation_0-mlogloss:2.34938\n",
            "[24]\tvalidation_0-mlogloss:2.36590\n",
            "[25]\tvalidation_0-mlogloss:2.38585\n",
            "[26]\tvalidation_0-mlogloss:2.39955\n",
            "[27]\tvalidation_0-mlogloss:2.40401\n",
            "[28]\tvalidation_0-mlogloss:2.41713\n",
            "[29]\tvalidation_0-mlogloss:2.44484\n",
            "[30]\tvalidation_0-mlogloss:2.46395\n",
            "[31]\tvalidation_0-mlogloss:2.48290\n",
            "[32]\tvalidation_0-mlogloss:2.49163\n",
            "[33]\tvalidation_0-mlogloss:2.50245\n",
            "[34]\tvalidation_0-mlogloss:2.51987\n",
            "[35]\tvalidation_0-mlogloss:2.52408\n",
            "[36]\tvalidation_0-mlogloss:2.52749\n",
            "[37]\tvalidation_0-mlogloss:2.54323\n",
            "[38]\tvalidation_0-mlogloss:2.55923\n",
            "[39]\tvalidation_0-mlogloss:2.58553\n",
            "[40]\tvalidation_0-mlogloss:2.60780\n",
            "[41]\tvalidation_0-mlogloss:2.63489\n",
            "[42]\tvalidation_0-mlogloss:2.65158\n",
            "[43]\tvalidation_0-mlogloss:2.66664\n",
            "[44]\tvalidation_0-mlogloss:2.69122\n",
            "[45]\tvalidation_0-mlogloss:2.71741\n",
            "[46]\tvalidation_0-mlogloss:2.73917\n",
            "[47]\tvalidation_0-mlogloss:2.76267\n",
            "[48]\tvalidation_0-mlogloss:2.78839\n",
            "[49]\tvalidation_0-mlogloss:2.81094\n",
            "[50]\tvalidation_0-mlogloss:2.83111\n",
            "[51]\tvalidation_0-mlogloss:2.85233\n",
            "[52]\tvalidation_0-mlogloss:2.87775\n",
            "[53]\tvalidation_0-mlogloss:2.90063\n",
            "[54]\tvalidation_0-mlogloss:2.91587\n",
            "[55]\tvalidation_0-mlogloss:2.94121\n",
            "[56]\tvalidation_0-mlogloss:2.95697\n",
            "[57]\tvalidation_0-mlogloss:2.97606\n",
            "[58]\tvalidation_0-mlogloss:3.00349\n",
            "[59]\tvalidation_0-mlogloss:3.00722\n",
            "[60]\tvalidation_0-mlogloss:3.01923\n",
            "[61]\tvalidation_0-mlogloss:3.03553\n",
            "[62]\tvalidation_0-mlogloss:3.03888\n",
            "[63]\tvalidation_0-mlogloss:3.04360\n",
            "[64]\tvalidation_0-mlogloss:3.05933\n",
            "[65]\tvalidation_0-mlogloss:3.04009\n",
            "[66]\tvalidation_0-mlogloss:3.02405\n",
            "[67]\tvalidation_0-mlogloss:3.03392\n",
            "[68]\tvalidation_0-mlogloss:3.02102\n",
            "[69]\tvalidation_0-mlogloss:3.00389\n",
            "[70]\tvalidation_0-mlogloss:3.02170\n",
            "[71]\tvalidation_0-mlogloss:2.99278\n",
            "[72]\tvalidation_0-mlogloss:2.97296\n",
            "[73]\tvalidation_0-mlogloss:2.94287\n",
            "[74]\tvalidation_0-mlogloss:2.93745\n",
            "[75]\tvalidation_0-mlogloss:2.92053\n",
            "[76]\tvalidation_0-mlogloss:2.89532\n",
            "[77]\tvalidation_0-mlogloss:2.88536\n",
            "[78]\tvalidation_0-mlogloss:2.87103\n",
            "[79]\tvalidation_0-mlogloss:2.85157\n",
            "[80]\tvalidation_0-mlogloss:2.83831\n",
            "[81]\tvalidation_0-mlogloss:2.82380\n",
            "[82]\tvalidation_0-mlogloss:2.80825\n",
            "[83]\tvalidation_0-mlogloss:2.80793\n",
            "[84]\tvalidation_0-mlogloss:2.79184\n",
            "[85]\tvalidation_0-mlogloss:2.76800\n",
            "[86]\tvalidation_0-mlogloss:2.75997\n",
            "[87]\tvalidation_0-mlogloss:2.73930\n",
            "[88]\tvalidation_0-mlogloss:2.72407\n",
            "[89]\tvalidation_0-mlogloss:2.70967\n",
            "[90]\tvalidation_0-mlogloss:2.68440\n",
            "[91]\tvalidation_0-mlogloss:2.67389\n",
            "[92]\tvalidation_0-mlogloss:2.65511\n",
            "[93]\tvalidation_0-mlogloss:2.64215\n",
            "[94]\tvalidation_0-mlogloss:2.62484\n",
            "[95]\tvalidation_0-mlogloss:2.61703\n",
            "[96]\tvalidation_0-mlogloss:2.60174\n",
            "[97]\tvalidation_0-mlogloss:2.58561\n",
            "[98]\tvalidation_0-mlogloss:2.56631\n",
            "[99]\tvalidation_0-mlogloss:2.55217\n",
            "[0]\tvalidation_0-mlogloss:2.18565\n",
            "[1]\tvalidation_0-mlogloss:2.18945\n",
            "[2]\tvalidation_0-mlogloss:2.19549\n",
            "[3]\tvalidation_0-mlogloss:2.19491\n",
            "[4]\tvalidation_0-mlogloss:2.19617\n",
            "[5]\tvalidation_0-mlogloss:2.20026\n",
            "[6]\tvalidation_0-mlogloss:2.20546\n",
            "[7]\tvalidation_0-mlogloss:2.19626\n",
            "[8]\tvalidation_0-mlogloss:2.18953\n",
            "[9]\tvalidation_0-mlogloss:2.17736\n",
            "[10]\tvalidation_0-mlogloss:2.16535\n",
            "[11]\tvalidation_0-mlogloss:2.15466\n",
            "[12]\tvalidation_0-mlogloss:2.14528\n",
            "[13]\tvalidation_0-mlogloss:2.13718\n",
            "[14]\tvalidation_0-mlogloss:2.13070\n",
            "[15]\tvalidation_0-mlogloss:2.12481\n",
            "[16]\tvalidation_0-mlogloss:2.12012\n",
            "[17]\tvalidation_0-mlogloss:2.11625\n",
            "[18]\tvalidation_0-mlogloss:2.11204\n",
            "[19]\tvalidation_0-mlogloss:2.10874\n",
            "[20]\tvalidation_0-mlogloss:2.10608\n",
            "[21]\tvalidation_0-mlogloss:2.10447\n",
            "[22]\tvalidation_0-mlogloss:2.10217\n",
            "[23]\tvalidation_0-mlogloss:2.10555\n",
            "[24]\tvalidation_0-mlogloss:2.10797\n",
            "[25]\tvalidation_0-mlogloss:2.11345\n",
            "[26]\tvalidation_0-mlogloss:2.11241\n",
            "[27]\tvalidation_0-mlogloss:2.11791\n",
            "[28]\tvalidation_0-mlogloss:2.12349\n",
            "[29]\tvalidation_0-mlogloss:2.13196\n",
            "[30]\tvalidation_0-mlogloss:2.13983\n",
            "[31]\tvalidation_0-mlogloss:2.15059\n",
            "[32]\tvalidation_0-mlogloss:2.16257\n",
            "[33]\tvalidation_0-mlogloss:2.17374\n",
            "[34]\tvalidation_0-mlogloss:2.18755\n",
            "[35]\tvalidation_0-mlogloss:2.20067\n",
            "[36]\tvalidation_0-mlogloss:2.21342\n",
            "[37]\tvalidation_0-mlogloss:2.22603\n",
            "[38]\tvalidation_0-mlogloss:2.24207\n",
            "[39]\tvalidation_0-mlogloss:2.25746\n",
            "[40]\tvalidation_0-mlogloss:2.27474\n",
            "[41]\tvalidation_0-mlogloss:2.29147\n",
            "[42]\tvalidation_0-mlogloss:2.31341\n",
            "[43]\tvalidation_0-mlogloss:2.33005\n",
            "[44]\tvalidation_0-mlogloss:2.35519\n",
            "[45]\tvalidation_0-mlogloss:2.37689\n",
            "[46]\tvalidation_0-mlogloss:2.39565\n",
            "[47]\tvalidation_0-mlogloss:2.40914\n",
            "[48]\tvalidation_0-mlogloss:2.42763\n",
            "[49]\tvalidation_0-mlogloss:2.44262\n",
            "[50]\tvalidation_0-mlogloss:2.46135\n",
            "[51]\tvalidation_0-mlogloss:2.47600\n",
            "[52]\tvalidation_0-mlogloss:2.49547\n",
            "[53]\tvalidation_0-mlogloss:2.50815\n",
            "[54]\tvalidation_0-mlogloss:2.52782\n",
            "[55]\tvalidation_0-mlogloss:2.54146\n",
            "[56]\tvalidation_0-mlogloss:2.55748\n",
            "[57]\tvalidation_0-mlogloss:2.57444\n",
            "[58]\tvalidation_0-mlogloss:2.59507\n",
            "[59]\tvalidation_0-mlogloss:2.60739\n",
            "[60]\tvalidation_0-mlogloss:2.62361\n",
            "[61]\tvalidation_0-mlogloss:2.62077\n",
            "[62]\tvalidation_0-mlogloss:2.62487\n",
            "[63]\tvalidation_0-mlogloss:2.58672\n",
            "[64]\tvalidation_0-mlogloss:2.59911\n",
            "[65]\tvalidation_0-mlogloss:2.59500\n",
            "[66]\tvalidation_0-mlogloss:2.56125\n",
            "[67]\tvalidation_0-mlogloss:2.56243\n",
            "[68]\tvalidation_0-mlogloss:2.54038\n",
            "[69]\tvalidation_0-mlogloss:2.52831\n",
            "[70]\tvalidation_0-mlogloss:2.50881\n",
            "[71]\tvalidation_0-mlogloss:2.47743\n",
            "[72]\tvalidation_0-mlogloss:2.47097\n",
            "[73]\tvalidation_0-mlogloss:2.43536\n",
            "[74]\tvalidation_0-mlogloss:2.42333\n",
            "[75]\tvalidation_0-mlogloss:2.39254\n",
            "[76]\tvalidation_0-mlogloss:2.37455\n",
            "[77]\tvalidation_0-mlogloss:2.34911\n",
            "[78]\tvalidation_0-mlogloss:2.33658\n",
            "[79]\tvalidation_0-mlogloss:2.30826\n",
            "[80]\tvalidation_0-mlogloss:2.30079\n",
            "[81]\tvalidation_0-mlogloss:2.27868\n",
            "[82]\tvalidation_0-mlogloss:2.26388\n",
            "[83]\tvalidation_0-mlogloss:2.24482\n",
            "[84]\tvalidation_0-mlogloss:2.24060\n",
            "[85]\tvalidation_0-mlogloss:2.21729\n",
            "[86]\tvalidation_0-mlogloss:2.21216\n",
            "[87]\tvalidation_0-mlogloss:2.19135\n",
            "[88]\tvalidation_0-mlogloss:2.18520\n",
            "[89]\tvalidation_0-mlogloss:2.16895\n",
            "[90]\tvalidation_0-mlogloss:2.14764\n",
            "[91]\tvalidation_0-mlogloss:2.14660\n",
            "[92]\tvalidation_0-mlogloss:2.12709\n",
            "[93]\tvalidation_0-mlogloss:2.12054\n",
            "[94]\tvalidation_0-mlogloss:2.10980\n",
            "[95]\tvalidation_0-mlogloss:2.09716\n",
            "[96]\tvalidation_0-mlogloss:2.08760\n",
            "[97]\tvalidation_0-mlogloss:2.07662\n",
            "[98]\tvalidation_0-mlogloss:2.06866\n",
            "[99]\tvalidation_0-mlogloss:2.05932\n",
            "[0]\tvalidation_0-mlogloss:2.15135\n",
            "[1]\tvalidation_0-mlogloss:2.12939\n",
            "[2]\tvalidation_0-mlogloss:2.12240\n",
            "[3]\tvalidation_0-mlogloss:2.12612\n",
            "[4]\tvalidation_0-mlogloss:2.13426\n",
            "[5]\tvalidation_0-mlogloss:2.14618\n",
            "[6]\tvalidation_0-mlogloss:2.16517\n",
            "[7]\tvalidation_0-mlogloss:2.18312\n",
            "[8]\tvalidation_0-mlogloss:2.19948\n",
            "[9]\tvalidation_0-mlogloss:2.22333\n",
            "[10]\tvalidation_0-mlogloss:2.22967\n",
            "[11]\tvalidation_0-mlogloss:2.24389\n",
            "[12]\tvalidation_0-mlogloss:2.26927\n",
            "[13]\tvalidation_0-mlogloss:2.29494\n",
            "[14]\tvalidation_0-mlogloss:2.30424\n",
            "[15]\tvalidation_0-mlogloss:2.32506\n",
            "[16]\tvalidation_0-mlogloss:2.34797\n",
            "[17]\tvalidation_0-mlogloss:2.37366\n",
            "[18]\tvalidation_0-mlogloss:2.39854\n",
            "[19]\tvalidation_0-mlogloss:2.42561\n",
            "[20]\tvalidation_0-mlogloss:2.45203\n",
            "[21]\tvalidation_0-mlogloss:2.47911\n",
            "[22]\tvalidation_0-mlogloss:2.50825\n",
            "[23]\tvalidation_0-mlogloss:2.53683\n",
            "[24]\tvalidation_0-mlogloss:2.55266\n",
            "[25]\tvalidation_0-mlogloss:2.56842\n",
            "[26]\tvalidation_0-mlogloss:2.60281\n",
            "[27]\tvalidation_0-mlogloss:2.61855\n",
            "[28]\tvalidation_0-mlogloss:2.63395\n",
            "[29]\tvalidation_0-mlogloss:2.64797\n",
            "[30]\tvalidation_0-mlogloss:2.66125\n",
            "[31]\tvalidation_0-mlogloss:2.67397\n",
            "[32]\tvalidation_0-mlogloss:2.68954\n",
            "[33]\tvalidation_0-mlogloss:2.70495\n",
            "[34]\tvalidation_0-mlogloss:2.71794\n",
            "[35]\tvalidation_0-mlogloss:2.73382\n",
            "[36]\tvalidation_0-mlogloss:2.75203\n",
            "[37]\tvalidation_0-mlogloss:2.76678\n",
            "[38]\tvalidation_0-mlogloss:2.78245\n",
            "[39]\tvalidation_0-mlogloss:2.79121\n",
            "[40]\tvalidation_0-mlogloss:2.80609\n",
            "[41]\tvalidation_0-mlogloss:2.81837\n",
            "[42]\tvalidation_0-mlogloss:2.82979\n",
            "[43]\tvalidation_0-mlogloss:2.83898\n",
            "[44]\tvalidation_0-mlogloss:2.85435\n",
            "[45]\tvalidation_0-mlogloss:2.86752\n",
            "[46]\tvalidation_0-mlogloss:2.87579\n",
            "[47]\tvalidation_0-mlogloss:2.88209\n",
            "[48]\tvalidation_0-mlogloss:2.89167\n",
            "[49]\tvalidation_0-mlogloss:2.90337\n",
            "[50]\tvalidation_0-mlogloss:2.91447\n",
            "[51]\tvalidation_0-mlogloss:2.92665\n",
            "[52]\tvalidation_0-mlogloss:2.93709\n",
            "[53]\tvalidation_0-mlogloss:2.94731\n",
            "[54]\tvalidation_0-mlogloss:2.95354\n",
            "[55]\tvalidation_0-mlogloss:2.92376\n",
            "[56]\tvalidation_0-mlogloss:2.93033\n",
            "[57]\tvalidation_0-mlogloss:2.92955\n",
            "[58]\tvalidation_0-mlogloss:2.93684\n",
            "[59]\tvalidation_0-mlogloss:2.93866\n",
            "[60]\tvalidation_0-mlogloss:2.94549\n",
            "[61]\tvalidation_0-mlogloss:2.94689\n",
            "[62]\tvalidation_0-mlogloss:2.94684\n",
            "[63]\tvalidation_0-mlogloss:2.93033\n",
            "[64]\tvalidation_0-mlogloss:2.93298\n",
            "[65]\tvalidation_0-mlogloss:2.91460\n",
            "[66]\tvalidation_0-mlogloss:2.89377\n",
            "[67]\tvalidation_0-mlogloss:2.90123\n",
            "[68]\tvalidation_0-mlogloss:2.88673\n",
            "[69]\tvalidation_0-mlogloss:2.86620\n",
            "[70]\tvalidation_0-mlogloss:2.83844\n",
            "[71]\tvalidation_0-mlogloss:2.81868\n",
            "[72]\tvalidation_0-mlogloss:2.79126\n",
            "[73]\tvalidation_0-mlogloss:2.79905\n",
            "[74]\tvalidation_0-mlogloss:2.76870\n",
            "[75]\tvalidation_0-mlogloss:2.75507\n",
            "[76]\tvalidation_0-mlogloss:2.72938\n",
            "[77]\tvalidation_0-mlogloss:2.71687\n",
            "[78]\tvalidation_0-mlogloss:2.69452\n",
            "[79]\tvalidation_0-mlogloss:2.68884\n",
            "[80]\tvalidation_0-mlogloss:2.66726\n",
            "[81]\tvalidation_0-mlogloss:2.65668\n",
            "[82]\tvalidation_0-mlogloss:2.63919\n",
            "[83]\tvalidation_0-mlogloss:2.61827\n",
            "[84]\tvalidation_0-mlogloss:2.60819\n",
            "[85]\tvalidation_0-mlogloss:2.58743\n",
            "[86]\tvalidation_0-mlogloss:2.56998\n",
            "[87]\tvalidation_0-mlogloss:2.55569\n",
            "[88]\tvalidation_0-mlogloss:2.54100\n",
            "[89]\tvalidation_0-mlogloss:2.53280\n",
            "[90]\tvalidation_0-mlogloss:2.51489\n",
            "[91]\tvalidation_0-mlogloss:2.50796\n",
            "[92]\tvalidation_0-mlogloss:2.49539\n",
            "[93]\tvalidation_0-mlogloss:2.47664\n",
            "[94]\tvalidation_0-mlogloss:2.46670\n",
            "[95]\tvalidation_0-mlogloss:2.45436\n",
            "[96]\tvalidation_0-mlogloss:2.44062\n",
            "[97]\tvalidation_0-mlogloss:2.43383\n",
            "[98]\tvalidation_0-mlogloss:2.42749\n",
            "[99]\tvalidation_0-mlogloss:2.41802\n",
            "[0]\tvalidation_0-mlogloss:2.19931\n",
            "[1]\tvalidation_0-mlogloss:2.19748\n",
            "[2]\tvalidation_0-mlogloss:2.19903\n",
            "[3]\tvalidation_0-mlogloss:2.21032\n",
            "[4]\tvalidation_0-mlogloss:2.22460\n",
            "[5]\tvalidation_0-mlogloss:2.23882\n",
            "[6]\tvalidation_0-mlogloss:2.24829\n",
            "[7]\tvalidation_0-mlogloss:2.25643\n",
            "[8]\tvalidation_0-mlogloss:2.26863\n",
            "[9]\tvalidation_0-mlogloss:2.28016\n",
            "[10]\tvalidation_0-mlogloss:2.29229\n",
            "[11]\tvalidation_0-mlogloss:2.29911\n",
            "[12]\tvalidation_0-mlogloss:2.30667\n",
            "[13]\tvalidation_0-mlogloss:2.31511\n",
            "[14]\tvalidation_0-mlogloss:2.32881\n",
            "[15]\tvalidation_0-mlogloss:2.33867\n",
            "[16]\tvalidation_0-mlogloss:2.34921\n",
            "[17]\tvalidation_0-mlogloss:2.36238\n",
            "[18]\tvalidation_0-mlogloss:2.37497\n",
            "[19]\tvalidation_0-mlogloss:2.39173\n",
            "[20]\tvalidation_0-mlogloss:2.40986\n",
            "[21]\tvalidation_0-mlogloss:2.42705\n",
            "[22]\tvalidation_0-mlogloss:2.44564\n",
            "[23]\tvalidation_0-mlogloss:2.46492\n",
            "[24]\tvalidation_0-mlogloss:2.48367\n",
            "[25]\tvalidation_0-mlogloss:2.48989\n",
            "[26]\tvalidation_0-mlogloss:2.49984\n",
            "[27]\tvalidation_0-mlogloss:2.50464\n",
            "[28]\tvalidation_0-mlogloss:2.51910\n",
            "[29]\tvalidation_0-mlogloss:2.53926\n",
            "[30]\tvalidation_0-mlogloss:2.56300\n",
            "[31]\tvalidation_0-mlogloss:2.57343\n",
            "[32]\tvalidation_0-mlogloss:2.59744\n",
            "[33]\tvalidation_0-mlogloss:2.60887\n",
            "[34]\tvalidation_0-mlogloss:2.63326\n",
            "[35]\tvalidation_0-mlogloss:2.65711\n",
            "[36]\tvalidation_0-mlogloss:2.66933\n",
            "[37]\tvalidation_0-mlogloss:2.68689\n",
            "[38]\tvalidation_0-mlogloss:2.71552\n",
            "[39]\tvalidation_0-mlogloss:2.74141\n",
            "[40]\tvalidation_0-mlogloss:2.75884\n",
            "[41]\tvalidation_0-mlogloss:2.76702\n",
            "[42]\tvalidation_0-mlogloss:2.77907\n",
            "[43]\tvalidation_0-mlogloss:2.79849\n",
            "[44]\tvalidation_0-mlogloss:2.80957\n",
            "[45]\tvalidation_0-mlogloss:2.83279\n",
            "[46]\tvalidation_0-mlogloss:2.83866\n",
            "[47]\tvalidation_0-mlogloss:2.85407\n",
            "[48]\tvalidation_0-mlogloss:2.85853\n",
            "[49]\tvalidation_0-mlogloss:2.82411\n",
            "[50]\tvalidation_0-mlogloss:2.81659\n",
            "[51]\tvalidation_0-mlogloss:2.78089\n",
            "[52]\tvalidation_0-mlogloss:2.75101\n",
            "[53]\tvalidation_0-mlogloss:2.74434\n",
            "[54]\tvalidation_0-mlogloss:2.71423\n",
            "[55]\tvalidation_0-mlogloss:2.71473\n",
            "[56]\tvalidation_0-mlogloss:2.69983\n",
            "[57]\tvalidation_0-mlogloss:2.69128\n",
            "[58]\tvalidation_0-mlogloss:2.65204\n",
            "[59]\tvalidation_0-mlogloss:2.62677\n",
            "[60]\tvalidation_0-mlogloss:2.58931\n",
            "[61]\tvalidation_0-mlogloss:2.60275\n",
            "[62]\tvalidation_0-mlogloss:2.56777\n",
            "[63]\tvalidation_0-mlogloss:2.55565\n",
            "[64]\tvalidation_0-mlogloss:2.50948\n",
            "[65]\tvalidation_0-mlogloss:2.49238\n",
            "[66]\tvalidation_0-mlogloss:2.47791\n",
            "[67]\tvalidation_0-mlogloss:2.44541\n",
            "[68]\tvalidation_0-mlogloss:2.44739\n",
            "[69]\tvalidation_0-mlogloss:2.44354\n",
            "[70]\tvalidation_0-mlogloss:2.40813\n",
            "[71]\tvalidation_0-mlogloss:2.41754\n",
            "[72]\tvalidation_0-mlogloss:2.38457\n",
            "[73]\tvalidation_0-mlogloss:2.37858\n",
            "[74]\tvalidation_0-mlogloss:2.35155\n",
            "[75]\tvalidation_0-mlogloss:2.34764\n",
            "[76]\tvalidation_0-mlogloss:2.34137\n",
            "[77]\tvalidation_0-mlogloss:2.33222\n",
            "[78]\tvalidation_0-mlogloss:2.32426\n",
            "[79]\tvalidation_0-mlogloss:2.30873\n",
            "[80]\tvalidation_0-mlogloss:2.30173\n",
            "[81]\tvalidation_0-mlogloss:2.28686\n",
            "[82]\tvalidation_0-mlogloss:2.27048\n",
            "[83]\tvalidation_0-mlogloss:2.25443\n",
            "[84]\tvalidation_0-mlogloss:2.24152\n",
            "[85]\tvalidation_0-mlogloss:2.23519\n",
            "[86]\tvalidation_0-mlogloss:2.21867\n",
            "[87]\tvalidation_0-mlogloss:2.20238\n",
            "[88]\tvalidation_0-mlogloss:2.19867\n",
            "[89]\tvalidation_0-mlogloss:2.17876\n",
            "[90]\tvalidation_0-mlogloss:2.16319\n",
            "[91]\tvalidation_0-mlogloss:2.15375\n",
            "[92]\tvalidation_0-mlogloss:2.13666\n",
            "[93]\tvalidation_0-mlogloss:2.13196\n",
            "[94]\tvalidation_0-mlogloss:2.11330\n",
            "[95]\tvalidation_0-mlogloss:2.09541\n",
            "[96]\tvalidation_0-mlogloss:2.08922\n",
            "[97]\tvalidation_0-mlogloss:2.08009\n",
            "[98]\tvalidation_0-mlogloss:2.07067\n",
            "[99]\tvalidation_0-mlogloss:2.05747\n",
            "[0]\tvalidation_0-mlogloss:2.18763\n",
            "[1]\tvalidation_0-mlogloss:2.18872\n",
            "[2]\tvalidation_0-mlogloss:2.20146\n",
            "[3]\tvalidation_0-mlogloss:2.21277\n",
            "[4]\tvalidation_0-mlogloss:2.22400\n",
            "[5]\tvalidation_0-mlogloss:2.24496\n",
            "[6]\tvalidation_0-mlogloss:2.26715\n",
            "[7]\tvalidation_0-mlogloss:2.29008\n",
            "[8]\tvalidation_0-mlogloss:2.31722\n",
            "[9]\tvalidation_0-mlogloss:2.34277\n",
            "[10]\tvalidation_0-mlogloss:2.36550\n",
            "[11]\tvalidation_0-mlogloss:2.38759\n",
            "[12]\tvalidation_0-mlogloss:2.41267\n",
            "[13]\tvalidation_0-mlogloss:2.43635\n",
            "[14]\tvalidation_0-mlogloss:2.46248\n",
            "[15]\tvalidation_0-mlogloss:2.47653\n",
            "[16]\tvalidation_0-mlogloss:2.48814\n",
            "[17]\tvalidation_0-mlogloss:2.50227\n",
            "[18]\tvalidation_0-mlogloss:2.51431\n",
            "[19]\tvalidation_0-mlogloss:2.53109\n",
            "[20]\tvalidation_0-mlogloss:2.54443\n",
            "[21]\tvalidation_0-mlogloss:2.56351\n",
            "[22]\tvalidation_0-mlogloss:2.58124\n",
            "[23]\tvalidation_0-mlogloss:2.60048\n",
            "[24]\tvalidation_0-mlogloss:2.60704\n",
            "[25]\tvalidation_0-mlogloss:2.62757\n",
            "[26]\tvalidation_0-mlogloss:2.64580\n",
            "[27]\tvalidation_0-mlogloss:2.66798\n",
            "[28]\tvalidation_0-mlogloss:2.68741\n",
            "[29]\tvalidation_0-mlogloss:2.70898\n",
            "[30]\tvalidation_0-mlogloss:2.71748\n",
            "[31]\tvalidation_0-mlogloss:2.72700\n",
            "[32]\tvalidation_0-mlogloss:2.74642\n",
            "[33]\tvalidation_0-mlogloss:2.75528\n",
            "[34]\tvalidation_0-mlogloss:2.77192\n",
            "[35]\tvalidation_0-mlogloss:2.77975\n",
            "[36]\tvalidation_0-mlogloss:2.79085\n",
            "[37]\tvalidation_0-mlogloss:2.80935\n",
            "[38]\tvalidation_0-mlogloss:2.82464\n",
            "[39]\tvalidation_0-mlogloss:2.85078\n",
            "[40]\tvalidation_0-mlogloss:2.85308\n",
            "[41]\tvalidation_0-mlogloss:2.82473\n",
            "[42]\tvalidation_0-mlogloss:2.82063\n",
            "[43]\tvalidation_0-mlogloss:2.78682\n",
            "[44]\tvalidation_0-mlogloss:2.78441\n",
            "[45]\tvalidation_0-mlogloss:2.78522\n",
            "[46]\tvalidation_0-mlogloss:2.75591\n",
            "[47]\tvalidation_0-mlogloss:2.75639\n",
            "[48]\tvalidation_0-mlogloss:2.76773\n",
            "[49]\tvalidation_0-mlogloss:2.73793\n",
            "[50]\tvalidation_0-mlogloss:2.74106\n",
            "[51]\tvalidation_0-mlogloss:2.75651\n",
            "[52]\tvalidation_0-mlogloss:2.72617\n",
            "[53]\tvalidation_0-mlogloss:2.73328\n",
            "[54]\tvalidation_0-mlogloss:2.70878\n",
            "[55]\tvalidation_0-mlogloss:2.69863\n",
            "[56]\tvalidation_0-mlogloss:2.70401\n",
            "[57]\tvalidation_0-mlogloss:2.66904\n",
            "[58]\tvalidation_0-mlogloss:2.67340\n",
            "[59]\tvalidation_0-mlogloss:2.63909\n",
            "[60]\tvalidation_0-mlogloss:2.62068\n",
            "[61]\tvalidation_0-mlogloss:2.58922\n",
            "[62]\tvalidation_0-mlogloss:2.57540\n",
            "[63]\tvalidation_0-mlogloss:2.54861\n",
            "[64]\tvalidation_0-mlogloss:2.53469\n",
            "[65]\tvalidation_0-mlogloss:2.51268\n",
            "[66]\tvalidation_0-mlogloss:2.49957\n",
            "[67]\tvalidation_0-mlogloss:2.47586\n",
            "[68]\tvalidation_0-mlogloss:2.44735\n",
            "[69]\tvalidation_0-mlogloss:2.42898\n",
            "[70]\tvalidation_0-mlogloss:2.43776\n",
            "[71]\tvalidation_0-mlogloss:2.42019\n",
            "[72]\tvalidation_0-mlogloss:2.40457\n",
            "[73]\tvalidation_0-mlogloss:2.40940\n",
            "[74]\tvalidation_0-mlogloss:2.39846\n",
            "[75]\tvalidation_0-mlogloss:2.37863\n",
            "[76]\tvalidation_0-mlogloss:2.36877\n",
            "[77]\tvalidation_0-mlogloss:2.37147\n",
            "[78]\tvalidation_0-mlogloss:2.34922\n",
            "[79]\tvalidation_0-mlogloss:2.35446\n",
            "[80]\tvalidation_0-mlogloss:2.34567\n",
            "[81]\tvalidation_0-mlogloss:2.33018\n",
            "[82]\tvalidation_0-mlogloss:2.33607\n",
            "[83]\tvalidation_0-mlogloss:2.32982\n",
            "[84]\tvalidation_0-mlogloss:2.31529\n",
            "[85]\tvalidation_0-mlogloss:2.30893\n",
            "[86]\tvalidation_0-mlogloss:2.29016\n",
            "[87]\tvalidation_0-mlogloss:2.28947\n",
            "[88]\tvalidation_0-mlogloss:2.27755\n",
            "[89]\tvalidation_0-mlogloss:2.27106\n",
            "[90]\tvalidation_0-mlogloss:2.26097\n",
            "[91]\tvalidation_0-mlogloss:2.25476\n",
            "[92]\tvalidation_0-mlogloss:2.24839\n",
            "[93]\tvalidation_0-mlogloss:2.24760\n",
            "[94]\tvalidation_0-mlogloss:2.23895\n",
            "[95]\tvalidation_0-mlogloss:2.23939\n",
            "[96]\tvalidation_0-mlogloss:2.23593\n",
            "[97]\tvalidation_0-mlogloss:2.22610\n",
            "[98]\tvalidation_0-mlogloss:2.22111\n",
            "[99]\tvalidation_0-mlogloss:2.21766\n",
            "Test Accuracy: 0.003622116211992653\n"
          ]
        }
      ],
      "source": [
        "# from xgboost import XGBClassifier\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# class TimeAwareGenerator:\n",
        "#     def __init__(self, X, y, chunk_size=50000):\n",
        "#         self.X = X\n",
        "#         self.y = y\n",
        "#         self.chunk_size = chunk_size\n",
        "#         self.unique_classes = np.unique(y)\n",
        "\n",
        "#     def generate_chunks(self):\n",
        "#         for start_idx in range(0, len(self.X), self.chunk_size):\n",
        "#             end_idx = min(start_idx + self.chunk_size, len(self.X))\n",
        "#             chunk_X = self.X[start_idx:end_idx]  # chunk_X is now a DataFrame\n",
        "#             chunk_y = self.y[start_idx:end_idx]\n",
        "\n",
        "#             # Ensure chunk contains all classes\n",
        "#             missing_classes = set(self.unique_classes) - set(np.unique(chunk_y))\n",
        "#             if missing_classes:\n",
        "#                 for class_val in missing_classes:\n",
        "#                     # Find indices for missing class\n",
        "#                     class_indices = np.where(self.y == class_val)[0]\n",
        "#                     if len(class_indices) > 0:\n",
        "#                         # Add samples from missing class, keeping it as DataFrame\n",
        "#                         sample_idx = np.random.choice(class_indices, min(100, len(class_indices)))\n",
        "#                         chunk_X = pd.concat([chunk_X, self.X.iloc[sample_idx]])\n",
        "#                         chunk_y = pd.concat([chunk_y, self.y.iloc[sample_idx]])\n",
        "\n",
        "#             yield chunk_X, chunk_y\n",
        "\n",
        "\n",
        "# # Train XGBoost\n",
        "# model = XGBClassifier(\n",
        "#    max_depth=6,\n",
        "#    learning_rate=0.1,\n",
        "#    n_estimators=100,\n",
        "#    objective='multi:softmax',\n",
        "#    num_class=9,\n",
        "#    tree_method='gpu_hist'\n",
        "# )\n",
        "\n",
        "# # Training with chunks\n",
        "# train_gen = TimeAwareGenerator(X_train, y_train)\n",
        "# for chunk_X, chunk_y in train_gen.generate_chunks():\n",
        "#    model.fit(chunk_X, chunk_y,\n",
        "#              eval_set=[(X_valid, y_valid)],\n",
        "#             #  early_stopping_rounds=5,\n",
        "#              verbose=True)\n",
        "\n",
        "\n",
        "# # Evaluate\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "IiKL2CmwlK_I",
        "outputId": "3c004920-b005-4f52-ad01-c88efae7a701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training pipeline...\n",
            "Training set shape: (35635659, 25)\n",
            "\n",
            "Initial class distribution in training set:\n",
            "Class 0: 10712409 samples\n",
            "Class 1: 73930 samples\n",
            "Class 2: 105003 samples\n",
            "Class 3: 4834079 samples\n",
            "Class 4: 2292363 samples\n",
            "Class 5: 12059906 samples\n",
            "Class 6: 5436997 samples\n",
            "Class 7: 38817 samples\n",
            "Class 8: 82155 samples\n",
            "\n",
            "Computing class weights...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "object too deep for desired array",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2738239b3e8e>\u001b[0m in \u001b[0;36m<cell line: 159>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m# Initialize and train classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeriesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;31m# Get feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2738239b3e8e>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, X_train, y_train, X_val, y_val, X_test, y_test)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Compute class weights from full training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nComputing class weights...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_class_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2738239b3e8e>\u001b[0m in \u001b[0;36mcompute_class_weights\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m\"\"\"Compute balanced class weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Count class frequencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_train = pd.DataFrame(X_train_scaled)\n",
        "X_val = pd.DataFrame(X_val_scaled)\n",
        "X_test = pd.DataFrame(X_test_scaled)\n",
        "\n",
        "y_val = pd.DataFrame(y_val)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "\n",
        "class TimeSeriesClassifier:\n",
        "    def __init__(self, n_classes=9, chunk_size=500000):\n",
        "        self.n_classes = n_classes\n",
        "        self.chunk_size = chunk_size\n",
        "        self.model = None\n",
        "        self.class_weights = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def compute_class_weights(self, y):\n",
        "        \"\"\"Compute balanced class weights.\"\"\"\n",
        "        # Count class frequencies\n",
        "        class_counts = np.bincount(y.astype(int))\n",
        "        total_samples = len(y)\n",
        "\n",
        "        # Compute balanced weights\n",
        "        weights = {}\n",
        "        for i in range(len(class_counts)):\n",
        "            if class_counts[i] > 0:  # Only compute for classes that exist in the data\n",
        "                weights[i] = total_samples / (len(class_counts) * class_counts[i])\n",
        "\n",
        "        return weights\n",
        "\n",
        "    def create_model(self, class_weights):\n",
        "        \"\"\"Initialize LightGBM model with appropriate parameters.\"\"\"\n",
        "        return LGBMClassifier(\n",
        "            n_estimators=200,\n",
        "            learning_rate=0.01,\n",
        "            num_leaves=31,\n",
        "            class_weight=class_weights,\n",
        "            device='gpu',\n",
        "            objective='multiclass',\n",
        "            num_class=self.n_classes,\n",
        "            feature_fraction=0.8,\n",
        "            bagging_fraction=0.8,\n",
        "            bagging_freq=5,\n",
        "            min_child_samples=20,\n",
        "            verbose=-1\n",
        "        )\n",
        "\n",
        "    def evaluate_chunk(self, X, y):\n",
        "        \"\"\"Evaluate model performance on a chunk of data.\"\"\"\n",
        "        predictions = self.model.predict(X)\n",
        "        print(\"\\nChunk Performance Metrics:\")\n",
        "        print(\"Balanced Accuracy:\", balanced_accuracy_score(y, predictions))\n",
        "        print(\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y, predictions))\n",
        "\n",
        "        # Print class distribution in predictions\n",
        "        unique, counts = np.unique(predictions, return_counts=True)\n",
        "        print(\"\\nPredicted class distribution:\")\n",
        "        for u, c in zip(unique, counts):\n",
        "            print(f\"Class {u}: {c} samples\")\n",
        "\n",
        "    def train_and_evaluate(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "        \"\"\"Main training and evaluation pipeline.\"\"\"\n",
        "        print(\"Starting training pipeline...\")\n",
        "        print(f\"Training set shape: {X_train.shape}\")\n",
        "\n",
        "        # Convert all targets to integer type\n",
        "        y_train = y_train.astype(int)\n",
        "        y_val = y_val.astype(int)\n",
        "        y_test = y_test.astype(int)\n",
        "\n",
        "        # Print initial class distribution\n",
        "        print(\"\\nInitial class distribution in training set:\")\n",
        "        unique, counts = np.unique(y_train, return_counts=True)\n",
        "        for u, c in zip(unique, counts):\n",
        "            print(f\"Class {u}: {c} samples\")\n",
        "\n",
        "        # Compute class weights from full training set\n",
        "        print(\"\\nComputing class weights...\")\n",
        "        self.class_weights = self.compute_class_weights(y_train)\n",
        "        print(\"Class weights:\", self.class_weights)\n",
        "\n",
        "        # Initialize model\n",
        "        print(\"\\nInitializing model...\")\n",
        "        self.model = self.create_model(self.class_weights)\n",
        "\n",
        "        # Train on chunks while maintaining temporal order\n",
        "        n_chunks = int(np.ceil(len(X_train) / self.chunk_size))\n",
        "        print(f\"\\nTraining on {n_chunks} chunks...\")\n",
        "\n",
        "        for chunk_idx in range(n_chunks):\n",
        "            start_idx = chunk_idx * self.chunk_size\n",
        "            end_idx = min((chunk_idx + 1) * self.chunk_size, len(X_train))\n",
        "\n",
        "            print(f\"\\nProcessing chunk {chunk_idx + 1}/{n_chunks}\")\n",
        "            print(f\"Chunk size: {end_idx - start_idx} samples\")\n",
        "\n",
        "            # Get current chunk\n",
        "            chunk_X = X_train[start_idx:end_idx]\n",
        "            chunk_y = y_train[start_idx:end_idx]\n",
        "\n",
        "            # Print chunk class distribution\n",
        "            unique, counts = np.unique(chunk_y, return_counts=True)\n",
        "            print(\"\\nChunk class distribution:\")\n",
        "            for u, c in zip(unique, counts):\n",
        "                print(f\"Class {u}: {c} samples\")\n",
        "\n",
        "            # Train on chunk\n",
        "            self.model.fit(\n",
        "                chunk_X, chunk_y,\n",
        "                eval_set=[(X_val, y_val)],\n",
        "                eval_metric='multi_logloss',\n",
        "                # early_stopping_rounds=10,\n",
        "                # verbose=50  # Reduced verbosity\n",
        "            )\n",
        "\n",
        "            # Evaluate on validation set periodically\n",
        "            if (chunk_idx + 1) % 5 == 0 or chunk_idx == n_chunks - 1:\n",
        "                print(\"\\nValidation set evaluation:\")\n",
        "                self.evaluate_chunk(X_val, y_val)\n",
        "\n",
        "        # Final evaluation on test set\n",
        "        print(\"\\nFinal Test Set Evaluation:\")\n",
        "        self.evaluate_chunk(X_test, y_test)\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def get_feature_importance(self, feature_names=None):\n",
        "        \"\"\"Get and display feature importance.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model hasn't been trained yet!\")\n",
        "\n",
        "        importance = self.model.feature_importances_\n",
        "        if feature_names is None:\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importance))]\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Importance': importance\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        return importance_df\n",
        "\n",
        "# Usage\n",
        "\n",
        "\n",
        "# Initialize and train classifier\n",
        "classifier = TimeSeriesClassifier(n_classes=9, chunk_size=500000)\n",
        "model = classifier.train_and_evaluate(X_train.values, y_train.values, X_val.values, y_val.values, X_test.values, y_test.values)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = classifier.get_feature_importance()\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V17vqyO6sTc6"
      },
      "source": [
        "----------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4cc887ed825947f592afd389c82df81b",
            "e426be0f6d6d4ffc8e3a34a604191efa",
            "53e54d4bddf44aeaae6a0c8416ace3ec",
            "7338a84c12f3488f9ef70d371e51918f",
            "3d85a9cc8ecf44c98a5cf69526926734",
            "dce7e7bf41c440f09abc6d17fc1c819a",
            "65b3db6c9960402083a952b08cec39c3",
            "3fcadc390db34970ba824bf383ac13c3",
            "2aa3dbe47d014793a2861797fee308fe",
            "f307543f3b34487ab5a3a2b85d98daf8",
            "c9a6b4d0982a4883a58ab4c3377d630a",
            "0799dde977794570ae6ced597ed6232a",
            "fa36e44799064ab19ee854e5ddce75a1",
            "4daa52d61b074086a053884ffefb4eaa",
            "83083aab9bf94ab4afd72ba20010b2e7",
            "56c80ef472414cdc81307c9b020c9f52",
            "99074d25cb2c495c9b368bdee8473dba",
            "a8d567a2b0ce44eab6f29db7ed3ed25d",
            "4f0beabbb6c94ccd8f49e2a7ff8835d7",
            "7cda686e128b42d5acd66613024c39e5",
            "401cc07be90c47cb9b61875d964dcead",
            "97dd2b41be314ae5ad7e8d4e459b827e",
            "44722a91ea904e25bd925aa2a1cf12b7",
            "79a03859f0804bcb80ca448f9bc41304",
            "b737a4ba69c0493dafc7df263e7ec2ae",
            "1ca84fb66bfa4a95a0bfbb2773af3ac8",
            "faeb936c4ba9400bafe02364d3b11809",
            "04130cc1477e4cb98a87b5b01d446168",
            "523debe973cf4e279d80b3c99005d454",
            "5034deb9123e4d60a94818719fda3967",
            "11fa24e361ed44ec8ff3ecd33c0df729",
            "e0dbcd9d38434923807fdb9ff55bf02e",
            "7aff1cd57379407091bbf9ff5f95fc00",
            "0a47bf7838e34543afff6a1e83914147",
            "6ab2ae31d56846bd93222f71427bf4a8",
            "754fb852a9a54368a4d8f624644df648",
            "9247336da73b45939a7b2fb3be6f9bd7",
            "6aa65ac8f29743249499400028939954",
            "624234dbd00f4511b612d9372c78fa64",
            "3096be9e00334b25b7f6892d08006af1",
            "f4a42eb9e5814c7b84e3038e31446e4f",
            "c2dd2f53f6f8409f87cd097123a9fd85",
            "71fd336f870f4f60a6a93db1c9cb86bf",
            "084ea8cad2fc48f29678ac4f0bcecc68",
            "405ae45f7e2944d5b9a75bedfa074568",
            "20e739100e294999ae1a62c78673d0eb",
            "f14cb7562d0c4da2b6da0e6aa1703553",
            "896de6c5a8c04dd8901acad058498552",
            "502e633fbece4dd5a5dd6cb91301382b",
            "c1fe619f2b4f4edebdcf9a502da6e43b",
            "bae61afff7da412995bc9297c0a59dc3",
            "17320ccb913344f082a53850df9069bf",
            "3c737b9db52341c99acb121d821e5314",
            "ba63c6e170e8456da9a104eea4561597",
            "10ff56722d3e4ec583e185bca4351a11",
            "4816871ecf854acaade2fda04d07fb39",
            "a1b3a2a28829469dbb0d3cba35a9c88a",
            "5c51262d186d4d4bb62f59ab131dbeaf",
            "d594cc5b09f74857ab9e6de2602aa8e2",
            "40f1122fcef84bea8a4d18579c79fbe7",
            "b782b4461e6543f08a01011e6fc09657",
            "449b2406522a4762ab47b747db6de4b1",
            "8c86f36d45204b08804b00d1c767a343",
            "0fd652cfa29b4b838117a644743fe774",
            "ee45a9e2d6cf40ccba55bd72144af286",
            "64380778d36d4202b633b2464a0a66ed",
            "a09c98de081d4575ae1ce7c3df2f1755",
            "b9e8f269edeb4592b7c86324677a41b2",
            "f4fe1fd4446545c68d2d8418c068b2eb",
            "672ea167ff7c4b989efa887971c39480",
            "abd279529f034c718d032a38829d1811",
            "613bd8b102504b02a41debc02af9327f",
            "2d38af2d709b4b0a9688214c4d17f870",
            "424c5c94fb444e209b518f143803e4f6",
            "ef726e69e5cb4592800c3c73b74b8086",
            "c48f26e3a1ab43d6ab6e6c8d26fe43cb",
            "9ce039a16dc6433ca1c746cb8472cbc9",
            "74cbaf71633d4bf29d054b4801191536",
            "670d70a3f4be4f75a6bfbe263f4c9c82",
            "7762ed8e5ec9486aabbb9b35a8b84b4c",
            "457d8d8e39b8438b8464dd7123451185",
            "6d8b164bfd5245b18c3a9cd6fd47da4f",
            "6b3b6bdd46b846a99f8f318ab49224a8",
            "90a0ba2c058449e2bd320d7d5849a4f9",
            "6838970765354ac3b76d9f132922fcd4",
            "7d50721957c343a088dde71fff9ae7dd",
            "bc59c013a46d471483e00a72b4c4f51a",
            "f875b293881b4a8b8be8cbed30237656",
            "58970ebedacb4b0f9ac6d24ee4182969",
            "7fbecfc43c4d4d879890cbf97fbd280e",
            "2b6f71ae61e24704ab0cf9f23472ae6d",
            "6609fc9219474f2382d7ab6eea67d02e",
            "00bc662fce7345f3add1c4cdad65a5ec",
            "9054fc0c92024ce9b2a33ee778e0ee5e",
            "3b0227f6090344558fc98319aa51cbed",
            "e3f50cba787b45a3842d81ec63fcb35e",
            "7542477d26db4594b7e147139ec6d731",
            "3ebab28ae6c64d81a6c43fe542d4185a",
            "9cb6290a57774c169b522754d8e05b6a"
          ]
        },
        "id": "s2BVt0t75Cw2",
        "outputId": "046896d9-3e81-49e4-e056-4f4c4f5af3dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cc887ed825947f592afd389c82df81b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 0:   0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0799dde977794570ae6ced597ed6232a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 1:   0%|          | 0/129 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44722a91ea904e25bd925aa2a1cf12b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 2:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a47bf7838e34543afff6a1e83914147",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 3:   0%|          | 0/106 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "405ae45f7e2944d5b9a75bedfa074568",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 4:   0%|          | 0/344 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4816871ecf854acaade2fda04d07fb39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 5:   0%|          | 0/451 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a09c98de081d4575ae1ce7c3df2f1755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 6:   0%|          | 0/221 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74cbaf71633d4bf29d054b4801191536",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 7:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58970ebedacb4b0f9ac6d24ee4182969",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing folder 8:   0%|          | 0/84 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== class Analysis Summary ===\n",
            "Total files with issues: 937\n",
            "\n",
            "Files with multiple class values:\n",
            "Count: 935\n",
            "\n",
            "Files with NaN values:\n",
            "Count: 50\n",
            "\n",
            "Files with invalid classes:\n",
            "Count: 937\n",
            "\n",
            "Proposed class value mapping:\n",
            "101.0 -> 1.0\n",
            "102 -> 2\n",
            "105 -> 5\n",
            "106 -> 6\n",
            "107 -> 7\n",
            "108 -> 8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def analyze_file_classes(base_dir):\n",
        "    \"\"\"\n",
        "    Analyze files to identify those with mixed or invalid classes\n",
        "    \"\"\"\n",
        "    file_analysis = []\n",
        "\n",
        "    for folder in range(9):\n",
        "        folder_path = os.path.join(base_dir, str(folder))\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "\n",
        "        files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
        "\n",
        "        for file in tqdm(files, desc=f'Analyzing folder {folder}'):\n",
        "            try:\n",
        "                df = pd.read_csv(file, usecols=['class'])\n",
        "                unique_classes = df['class'].unique()\n",
        "\n",
        "                # Analyze class values in this file\n",
        "                invalid_classes = [c for c in unique_classes if pd.notna(c) and c not in range(9)]\n",
        "                nan_count = df['class'].isna().sum()\n",
        "\n",
        "                if len(unique_classes) > 1 or invalid_classes or nan_count > 0:\n",
        "                    file_analysis.append({\n",
        "                        'file': file,\n",
        "                        'folder': folder,\n",
        "                        'unique_classes': unique_classes,\n",
        "                        'invalid_classes': invalid_classes,\n",
        "                        'nan_count': nan_count,\n",
        "                        'total_rows': len(df),\n",
        "                        'class_counts': df['class'].value_counts().to_dict()\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file}: {str(e)}\")\n",
        "\n",
        "    return pd.DataFrame(file_analysis)\n",
        "\n",
        "def map_anomalous_classes(class_value):\n",
        "    \"\"\"\n",
        "    Map anomalous class values to correct ones based on patterns\n",
        "    101 -> 1, 102 -> 2, etc.\n",
        "    \"\"\"\n",
        "    if pd.isna(class_value):\n",
        "        return np.nan\n",
        "\n",
        "    if class_value >= 100:\n",
        "        return class_value % 100\n",
        "\n",
        "    return class_value\n",
        "\n",
        "def print_analysis_summary(analysis_df):\n",
        "    \"\"\"\n",
        "    Print summary of the analysis\n",
        "    \"\"\"\n",
        "    print(\"\\n=== class Analysis Summary ===\")\n",
        "    print(f\"Total files with issues: {len(analysis_df)}\")\n",
        "    print(\"\\nFiles with multiple class values:\")\n",
        "    print(f\"Count: {len(analysis_df[analysis_df['unique_classes'].apply(len) > 1])}\")\n",
        "\n",
        "    print(\"\\nFiles with NaN values:\")\n",
        "    print(f\"Count: {len(analysis_df[analysis_df['nan_count'] > 0])}\")\n",
        "\n",
        "    print(\"\\nFiles with invalid classes:\")\n",
        "    print(f\"Count: {len(analysis_df[analysis_df['invalid_classes'].apply(len) > 0])}\")\n",
        "\n",
        "    # Create mapping suggestion\n",
        "    print(\"\\nProposed class value mapping:\")\n",
        "    for old_val in sorted(set([x for lst in analysis_df['invalid_classes'].tolist() for x in lst])):\n",
        "        print(f\"{old_val} -> {map_anomalous_classes(old_val)}\")\n",
        "\n",
        "# Run analysis\n",
        "analysis_df = analyze_file_classes(BASE_DIR)\n",
        "print_analysis_summary(analysis_df)\n",
        "\n",
        "# Visualize distribution of problematic files across folders\n",
        "plt.figure(figsize=(12, 6))\n",
        "analysis_df['folder'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.title('Distribution of Files with class Issues by Folder')\n",
        "plt.xlabel('Folder')\n",
        "plt.ylabel('Number of Files')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00bc662fce7345f3add1c4cdad65a5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04130cc1477e4cb98a87b5b01d446168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0799dde977794570ae6ced597ed6232a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa36e44799064ab19ee854e5ddce75a1",
              "IPY_MODEL_4daa52d61b074086a053884ffefb4eaa",
              "IPY_MODEL_83083aab9bf94ab4afd72ba20010b2e7"
            ],
            "layout": "IPY_MODEL_56c80ef472414cdc81307c9b020c9f52"
          }
        },
        "084ea8cad2fc48f29678ac4f0bcecc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a47bf7838e34543afff6a1e83914147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab2ae31d56846bd93222f71427bf4a8",
              "IPY_MODEL_754fb852a9a54368a4d8f624644df648",
              "IPY_MODEL_9247336da73b45939a7b2fb3be6f9bd7"
            ],
            "layout": "IPY_MODEL_6aa65ac8f29743249499400028939954"
          }
        },
        "0fd652cfa29b4b838117a644743fe774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10ff56722d3e4ec583e185bca4351a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11fa24e361ed44ec8ff3ecd33c0df729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17320ccb913344f082a53850df9069bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca84fb66bfa4a95a0bfbb2773af3ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0dbcd9d38434923807fdb9ff55bf02e",
            "placeholder": "​",
            "style": "IPY_MODEL_7aff1cd57379407091bbf9ff5f95fc00",
            "value": " 38/38 [00:01&lt;00:00, 53.63it/s]"
          }
        },
        "20e739100e294999ae1a62c78673d0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1fe619f2b4f4edebdcf9a502da6e43b",
            "placeholder": "​",
            "style": "IPY_MODEL_bae61afff7da412995bc9297c0a59dc3",
            "value": "Analyzing folder 4: 100%"
          }
        },
        "2aa3dbe47d014793a2861797fee308fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b6f71ae61e24704ab0cf9f23472ae6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f50cba787b45a3842d81ec63fcb35e",
            "max": 84,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7542477d26db4594b7e147139ec6d731",
            "value": 84
          }
        },
        "2d38af2d709b4b0a9688214c4d17f870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3096be9e00334b25b7f6892d08006af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0227f6090344558fc98319aa51cbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c737b9db52341c99acb121d821e5314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d85a9cc8ecf44c98a5cf69526926734": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ebab28ae6c64d81a6c43fe542d4185a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fcadc390db34970ba824bf383ac13c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401cc07be90c47cb9b61875d964dcead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405ae45f7e2944d5b9a75bedfa074568": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20e739100e294999ae1a62c78673d0eb",
              "IPY_MODEL_f14cb7562d0c4da2b6da0e6aa1703553",
              "IPY_MODEL_896de6c5a8c04dd8901acad058498552"
            ],
            "layout": "IPY_MODEL_502e633fbece4dd5a5dd6cb91301382b"
          }
        },
        "40f1122fcef84bea8a4d18579c79fbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424c5c94fb444e209b518f143803e4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44722a91ea904e25bd925aa2a1cf12b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79a03859f0804bcb80ca448f9bc41304",
              "IPY_MODEL_b737a4ba69c0493dafc7df263e7ec2ae",
              "IPY_MODEL_1ca84fb66bfa4a95a0bfbb2773af3ac8"
            ],
            "layout": "IPY_MODEL_faeb936c4ba9400bafe02364d3b11809"
          }
        },
        "449b2406522a4762ab47b747db6de4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457d8d8e39b8438b8464dd7123451185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc59c013a46d471483e00a72b4c4f51a",
            "placeholder": "​",
            "style": "IPY_MODEL_f875b293881b4a8b8be8cbed30237656",
            "value": " 14/14 [00:03&lt;00:00,  5.43it/s]"
          }
        },
        "4816871ecf854acaade2fda04d07fb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1b3a2a28829469dbb0d3cba35a9c88a",
              "IPY_MODEL_5c51262d186d4d4bb62f59ab131dbeaf",
              "IPY_MODEL_d594cc5b09f74857ab9e6de2602aa8e2"
            ],
            "layout": "IPY_MODEL_40f1122fcef84bea8a4d18579c79fbe7"
          }
        },
        "4cc887ed825947f592afd389c82df81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e426be0f6d6d4ffc8e3a34a604191efa",
              "IPY_MODEL_53e54d4bddf44aeaae6a0c8416ace3ec",
              "IPY_MODEL_7338a84c12f3488f9ef70d371e51918f"
            ],
            "layout": "IPY_MODEL_3d85a9cc8ecf44c98a5cf69526926734"
          }
        },
        "4daa52d61b074086a053884ffefb4eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0beabbb6c94ccd8f49e2a7ff8835d7",
            "max": 129,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cda686e128b42d5acd66613024c39e5",
            "value": 129
          }
        },
        "4f0beabbb6c94ccd8f49e2a7ff8835d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502e633fbece4dd5a5dd6cb91301382b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5034deb9123e4d60a94818719fda3967": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "523debe973cf4e279d80b3c99005d454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e54d4bddf44aeaae6a0c8416ace3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcadc390db34970ba824bf383ac13c3",
            "max": 597,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aa3dbe47d014793a2861797fee308fe",
            "value": 597
          }
        },
        "56c80ef472414cdc81307c9b020c9f52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58970ebedacb4b0f9ac6d24ee4182969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fbecfc43c4d4d879890cbf97fbd280e",
              "IPY_MODEL_2b6f71ae61e24704ab0cf9f23472ae6d",
              "IPY_MODEL_6609fc9219474f2382d7ab6eea67d02e"
            ],
            "layout": "IPY_MODEL_00bc662fce7345f3add1c4cdad65a5ec"
          }
        },
        "5c51262d186d4d4bb62f59ab131dbeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c86f36d45204b08804b00d1c767a343",
            "max": 451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fd652cfa29b4b838117a644743fe774",
            "value": 451
          }
        },
        "613bd8b102504b02a41debc02af9327f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624234dbd00f4511b612d9372c78fa64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64380778d36d4202b633b2464a0a66ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65b3db6c9960402083a952b08cec39c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6609fc9219474f2382d7ab6eea67d02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ebab28ae6c64d81a6c43fe542d4185a",
            "placeholder": "​",
            "style": "IPY_MODEL_9cb6290a57774c169b522754d8e05b6a",
            "value": " 84/84 [00:05&lt;00:00, 14.28it/s]"
          }
        },
        "670d70a3f4be4f75a6bfbe263f4c9c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b3b6bdd46b846a99f8f318ab49224a8",
            "placeholder": "​",
            "style": "IPY_MODEL_90a0ba2c058449e2bd320d7d5849a4f9",
            "value": "Analyzing folder 7: 100%"
          }
        },
        "672ea167ff7c4b989efa887971c39480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48f26e3a1ab43d6ab6e6c8d26fe43cb",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce039a16dc6433ca1c746cb8472cbc9",
            "value": " 221/221 [00:09&lt;00:00, 29.30it/s]"
          }
        },
        "6838970765354ac3b76d9f132922fcd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa65ac8f29743249499400028939954": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab2ae31d56846bd93222f71427bf4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624234dbd00f4511b612d9372c78fa64",
            "placeholder": "​",
            "style": "IPY_MODEL_3096be9e00334b25b7f6892d08006af1",
            "value": "Analyzing folder 3: 100%"
          }
        },
        "6b3b6bdd46b846a99f8f318ab49224a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8b164bfd5245b18c3a9cd6fd47da4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fd336f870f4f60a6a93db1c9cb86bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7338a84c12f3488f9ef70d371e51918f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f307543f3b34487ab5a3a2b85d98daf8",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a6b4d0982a4883a58ab4c3377d630a",
            "value": " 597/597 [00:21&lt;00:00, 40.47it/s]"
          }
        },
        "74cbaf71633d4bf29d054b4801191536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_670d70a3f4be4f75a6bfbe263f4c9c82",
              "IPY_MODEL_7762ed8e5ec9486aabbb9b35a8b84b4c",
              "IPY_MODEL_457d8d8e39b8438b8464dd7123451185"
            ],
            "layout": "IPY_MODEL_6d8b164bfd5245b18c3a9cd6fd47da4f"
          }
        },
        "7542477d26db4594b7e147139ec6d731": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "754fb852a9a54368a4d8f624644df648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a42eb9e5814c7b84e3038e31446e4f",
            "max": 106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2dd2f53f6f8409f87cd097123a9fd85",
            "value": 106
          }
        },
        "7762ed8e5ec9486aabbb9b35a8b84b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6838970765354ac3b76d9f132922fcd4",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d50721957c343a088dde71fff9ae7dd",
            "value": 14
          }
        },
        "79a03859f0804bcb80ca448f9bc41304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04130cc1477e4cb98a87b5b01d446168",
            "placeholder": "​",
            "style": "IPY_MODEL_523debe973cf4e279d80b3c99005d454",
            "value": "Analyzing folder 2: 100%"
          }
        },
        "7aff1cd57379407091bbf9ff5f95fc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cda686e128b42d5acd66613024c39e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d50721957c343a088dde71fff9ae7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fbecfc43c4d4d879890cbf97fbd280e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9054fc0c92024ce9b2a33ee778e0ee5e",
            "placeholder": "​",
            "style": "IPY_MODEL_3b0227f6090344558fc98319aa51cbed",
            "value": "Analyzing folder 8: 100%"
          }
        },
        "83083aab9bf94ab4afd72ba20010b2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401cc07be90c47cb9b61875d964dcead",
            "placeholder": "​",
            "style": "IPY_MODEL_97dd2b41be314ae5ad7e8d4e459b827e",
            "value": " 129/129 [00:16&lt;00:00,  7.42it/s]"
          }
        },
        "896de6c5a8c04dd8901acad058498552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba63c6e170e8456da9a104eea4561597",
            "placeholder": "​",
            "style": "IPY_MODEL_10ff56722d3e4ec583e185bca4351a11",
            "value": " 344/344 [00:07&lt;00:00, 43.39it/s]"
          }
        },
        "8c86f36d45204b08804b00d1c767a343": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9054fc0c92024ce9b2a33ee778e0ee5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a0ba2c058449e2bd320d7d5849a4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9247336da73b45939a7b2fb3be6f9bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71fd336f870f4f60a6a93db1c9cb86bf",
            "placeholder": "​",
            "style": "IPY_MODEL_084ea8cad2fc48f29678ac4f0bcecc68",
            "value": " 106/106 [00:09&lt;00:00, 26.73it/s]"
          }
        },
        "97dd2b41be314ae5ad7e8d4e459b827e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99074d25cb2c495c9b368bdee8473dba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb6290a57774c169b522754d8e05b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ce039a16dc6433ca1c746cb8472cbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09c98de081d4575ae1ce7c3df2f1755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9e8f269edeb4592b7c86324677a41b2",
              "IPY_MODEL_f4fe1fd4446545c68d2d8418c068b2eb",
              "IPY_MODEL_672ea167ff7c4b989efa887971c39480"
            ],
            "layout": "IPY_MODEL_abd279529f034c718d032a38829d1811"
          }
        },
        "a1b3a2a28829469dbb0d3cba35a9c88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b782b4461e6543f08a01011e6fc09657",
            "placeholder": "​",
            "style": "IPY_MODEL_449b2406522a4762ab47b747db6de4b1",
            "value": "Analyzing folder 5: 100%"
          }
        },
        "a8d567a2b0ce44eab6f29db7ed3ed25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd279529f034c718d032a38829d1811": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b737a4ba69c0493dafc7df263e7ec2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5034deb9123e4d60a94818719fda3967",
            "max": 38,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11fa24e361ed44ec8ff3ecd33c0df729",
            "value": 38
          }
        },
        "b782b4461e6543f08a01011e6fc09657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e8f269edeb4592b7c86324677a41b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613bd8b102504b02a41debc02af9327f",
            "placeholder": "​",
            "style": "IPY_MODEL_2d38af2d709b4b0a9688214c4d17f870",
            "value": "Analyzing folder 6: 100%"
          }
        },
        "ba63c6e170e8456da9a104eea4561597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae61afff7da412995bc9297c0a59dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc59c013a46d471483e00a72b4c4f51a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fe619f2b4f4edebdcf9a502da6e43b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2dd2f53f6f8409f87cd097123a9fd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c48f26e3a1ab43d6ab6e6c8d26fe43cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a6b4d0982a4883a58ab4c3377d630a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d594cc5b09f74857ab9e6de2602aa8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee45a9e2d6cf40ccba55bd72144af286",
            "placeholder": "​",
            "style": "IPY_MODEL_64380778d36d4202b633b2464a0a66ed",
            "value": " 451/451 [00:32&lt;00:00, 13.36it/s]"
          }
        },
        "dce7e7bf41c440f09abc6d17fc1c819a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dbcd9d38434923807fdb9ff55bf02e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f50cba787b45a3842d81ec63fcb35e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e426be0f6d6d4ffc8e3a34a604191efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce7e7bf41c440f09abc6d17fc1c819a",
            "placeholder": "​",
            "style": "IPY_MODEL_65b3db6c9960402083a952b08cec39c3",
            "value": "Analyzing folder 0: 100%"
          }
        },
        "ee45a9e2d6cf40ccba55bd72144af286": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef726e69e5cb4592800c3c73b74b8086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14cb7562d0c4da2b6da0e6aa1703553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17320ccb913344f082a53850df9069bf",
            "max": 344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c737b9db52341c99acb121d821e5314",
            "value": 344
          }
        },
        "f307543f3b34487ab5a3a2b85d98daf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a42eb9e5814c7b84e3038e31446e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fe1fd4446545c68d2d8418c068b2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_424c5c94fb444e209b518f143803e4f6",
            "max": 221,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef726e69e5cb4592800c3c73b74b8086",
            "value": 221
          }
        },
        "f875b293881b4a8b8be8cbed30237656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa36e44799064ab19ee854e5ddce75a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99074d25cb2c495c9b368bdee8473dba",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d567a2b0ce44eab6f29db7ed3ed25d",
            "value": "Analyzing folder 1: 100%"
          }
        },
        "faeb936c4ba9400bafe02364d3b11809": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}